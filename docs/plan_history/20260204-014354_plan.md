# Plan

This repo contains the free-form draft in `plan.md`. This document is the **canonical, actionable plan** (machine-friendly) derived from that draft.

## Items
- [x] P0001: Bootstrap AVS codebase scaffold
  - Summary: Create a minimal Python package + CLI + smoke test entrypoints for the AVS (Audio-Visual Synchronizer) pipeline.
  - Rationale: Enables incremental implementation and verifiable progress instead of a free-form writeup.
  - Scope: `avs/`, `scripts/`, `tests/`, `requirements.txt` (or `pyproject.toml`)
  - Acceptance: `python -m avs.cli --help` works; a smoke command runs end-to-end on synthetic data.
  - Verification: `python -m avs.smoke`
  - Outputs: `avs/` package, runnable smoke output under `runs/`

- [x] P0002: Define AVE dataset IO + splits parsing
  - Summary: Implement AVE metadata parsing (splits + labels) and a dataset interface with a documented on-disk layout.
  - Rationale: All later steps (preprocess/train/eval) depend on deterministic data indexing (10 seconds → 10 segments).
  - Scope: `avs/datasets/ave.py`, `avs/datasets/layout.py`, docs in `docs/`
  - Acceptance: Dataset can load a video id and return 10 segment labels; missing files give clear errors.
  - Verification: `python -m avs.smoke ave_meta`
  - Outputs: AVE metadata under `data/AVE/meta/`

- [x] P0003: Implement deterministic preprocessing (audio + per-second frames)
  - Summary: Given raw AVE videos, extract 16kHz mono wav and one middle-frame JPG per second (10 total).
  - Rationale: Makes the “per-second” experimental protocol reproducible and speeds iteration.
  - Scope: `avs/preprocess/ave_extract.py`, `scripts/ave_extract.sh`
  - Acceptance: For a single video, produces `{clip_id}/audio.wav` and `{clip_id}/frames/{0..9}.jpg` with stable timestamps.
  - Verification: `python -m avs.smoke preprocess_one`
  - Outputs: `data/AVE/processed/<clip_id>/audio.wav`, `data/AVE/processed/<clip_id>/frames/*.jpg`

- [x] P0004: Implement audio eventness → anchors + Recall@K
  - Summary: Implement `s(t)` (eventness) and Top-K anchor generation, plus Recall@K (and optional ±Δ dilation).
  - Rationale: Verifies the key premise: audio provides sparse time proposals better than random.
  - Scope: `avs/audio/eventness.py`, `avs/metrics/anchors.py`
  - Acceptance: Produces anchors for 10 segments; Recall@K works on synthetic or real labels.
  - Verification: `python -m avs.smoke anchors`
  - Outputs: Anchor JSON under `runs/<run_id>/anchors.json`

- [x] P0005: Implement token-budgeted sampling plans (Uniform vs Anchored)
  - Summary: Generate per-second resolution plans with strict equal token budget (e.g., `2×448 + 8×112 == 10×224` for ViT/16).
  - Rationale: This is the “knife edge” of the method: same budget, better allocation.
  - Scope: `avs/sampling/token_budget.py`, `avs/sampling/plans.py`
  - Acceptance: For any anchor set, outputs a 10-step plan whose total tokens exactly matches the target.
  - Verification: `python -m avs.smoke sampling_plan`
  - Outputs: `runs/<run_id>/plan.json`

- [x] P0006: Implement a variable-resolution CLIP/Vision encoder wrapper
  - Summary: Use a ViT/16 vision backbone that accepts 112/224/448 inputs via positional embedding interpolation and returns per-frame embeddings.
  - Rationale: Needed to realize the “more tokens near anchors” design while keeping the same backbone.
  - Scope: `avs/vision/clip_vit.py`
  - Acceptance: Encodes the same image at 112/224/448 and returns embeddings with consistent dim; batch inference works on CPU.
  - Verification: `python -m avs.smoke vision_encoder`
  - Outputs: Cached features under `runs/<run_id>/features/` (optional)

- [x] P0007: Implement AVE per-second classifier + training/eval loop
  - Summary: Train a lightweight head (MLP; optional 1D temporal module) on top of frozen vision features; evaluate segment-level accuracy.
  - Rationale: Enables the main claim to be tested under controlled conditions.
  - Scope: `avs/models/`, `avs/train/`
  - Acceptance: A short smoke training run completes; evaluation produces segment-acc for baseline/ours on synthetic data.
  - Verification: `python -m avs.smoke train_smoke`
  - Outputs: `runs/<run_id>/metrics.json`, `runs/<run_id>/ckpt.pt`

- [x] P0008: Generate per-clip plan.jsonl from audio eventness (dataset-wide)
  - Summary: For a set of processed clips, compute `s(t)` → Top-K anchors → equal-budget sampling plan, and write `plan.jsonl`.
  - Rationale: Matches `plan.md`’s requirement to make sampling reproducible and audit-friendly.
  - Scope: `avs/pipeline/plan_generation.py`
  - Acceptance: Produces a valid JSONL (1 line/clip) with `clip_id`, `anchors`, `scores`, and `plan.total_tokens`.
  - Verification: `python -m avs.smoke plan_jsonl`
  - Outputs: `runs/<run_id>/plan.jsonl`

- [x] P0009: Provide dataset-level preprocessing CLI (multi-clip)
  - Summary: Preprocess multiple raw clips into `{clip_id}/audio.wav` + `{clip_id}/frames/*.jpg`.
  - Rationale: Needed to scale Phase 1 from single-clip demo to dataset subset runs.
  - Scope: `avs/preprocess/ave_dataset.py`
  - Acceptance: Given `--raw-videos-dir` and `--video-id ...`, produces outputs for each requested clip id.
  - Verification: `python -m avs.smoke preprocess_dataset`
  - Outputs: `data/AVE/processed/<clip_id>/...`

- [x] P0010: Add AudioSet classifier-based eventness (AST) as a probe option
  - Summary: Provide an eventness backend that uses a pretrained audio classifier (AST on AudioSet) to compute `s(t)` per second.
  - Rationale: `plan.md` suggests using a lightweight pretrained audio model (e.g., PANNs/AudioMAE); AST is an easily swappable first implementation.
  - Scope: `avs/audio/ast_probe.py` (new), `avs/audio/eventness.py`
  - Acceptance: Can compute a length-10 `s(t)` from a 10s wav; supports `--pretrained` and a random-weight fallback.
  - Verification: `python -m avs.smoke ast_eventness`
  - Outputs: `runs/<run_id>/ast_eventness.json`

- [x] P0011: Add dataset-wide anchor quality evaluation (Recall@K / Recall@K,Δ)
  - Summary: Evaluate anchors vs GT segments across a split and report Recall@K, plus dilation robustness for Δ∈{0,1,2}.
  - Rationale: Separates “anchor quality” from “visual budget allocation” as required by `plan.md`.
  - Scope: `avs/experiments/ave_anchor_eval.py` (new)
  - Acceptance: Produces `anchors_metrics.json` with Recall@K and Recall@K,Δ; includes a random anchor baseline.
  - Verification: `python -m avs.smoke anchors_dataset`
  - Outputs: `runs/<run_id>/anchors_metrics.json`

- [x] P0012: Add multi-resolution feature cache for processed frames
  - Summary: Precompute and cache CLIP embeddings for each clip at {112,224,448} to make P0 training fast and comparable across baselines.
  - Rationale: Needed to run Uniform/Random/Anchored/Oracle without recomputing embeddings for each variant.
  - Scope: `avs/vision/feature_cache.py` (new), `avs/experiments/ave_build_cache.py` (new)
  - Acceptance: Given a processed clip dir, creates an `.npz` with arrays for each resolution.
  - Verification: `python -m avs.smoke feature_cache`
  - Outputs: `runs/<run_id>/features_cache/*.npz`

- [x] P0013: Implement AVE-P0 runner on cached features (Uniform/Random/Anchored/Oracle)
  - Summary: Train a per-segment classifier on cached features and evaluate segment-level accuracy for each baseline under equal token budget.
  - Rationale: This is the core “same tokens, better allocation” claim in `plan.md`.
  - Scope: `avs/experiments/ave_p0.py` (new)
  - Acceptance: Writes `metrics.json` with per-baseline accuracy and token budget confirmation; supports `--seeds 0,1,2`.
  - Verification: `python -m avs.smoke ave_p0_toy`
  - Outputs: `runs/AVE_P0/*/metrics.json`

- [x] P0014: Add Audio-Feature Concat baseline (fusion, not indexing)
  - Summary: Add a baseline that concatenates a per-second audio feature into the classifier input while keeping visual sampling Uniform-224.
  - Rationale: Required by `plan.md` to disentangle “audio adds information” vs “audio acts as an index”.
  - Scope: `avs/experiments/ave_p0.py`
  - Acceptance: `audio_concat_uniform` appears in `metrics.json` and runs end-to-end on cached features.
  - Verification: `python -m avs.smoke ave_p0_toy`
  - Outputs: `runs/AVE_P0/*/metrics.json`

- [x] P0015: Add qualitative visualization (s(t) + anchors + GT + sampled resolutions)
  - Summary: For a clip, plot `s(t)` with anchors, GT event segments, and the sampling plan’s per-second resolutions.
  - Rationale: Provides the qualitative evidence requested in `plan.md` Stage 6.
  - Scope: `avs/visualize/anchors_plot.py` (new)
  - Acceptance: Generates a PNG for a synthetic clip.
  - Verification: `python -m avs.smoke viz`
  - Outputs: `runs/<run_id>/viz.png`

- [x] P0016: Add AVE raw-video acquisition helper (local copy / yt-dlp)
  - Summary: Provide a utility to materialize `data/AVE/raw/videos/<video_id>.mp4` either by copying from a local directory or by downloading via `yt-dlp`.
  - Rationale: `plan.md` Phase 1 requires raw videos to run real AVE-P0 beyond synthetic smoke tests.
  - Note: For the *official full* AVE dataset (4143 clips), prefer `bash scripts/ave_install_official.sh` which downloads `AVE_Dataset.zip` and installs videos under `data/AVE/raw/videos/`. `yt-dlp` mode is best-effort and may miss many videos.
  - Scope: `avs/datasets/ave_download.py` (new), `scripts/ave_download.sh`
  - Acceptance: Can fetch a requested `--video-id` into the raw videos dir; “local” mode works without network.
  - Verification: `python -m avs.smoke ave_download`
  - Outputs: `data/AVE/raw/videos/*.mp4`

- [x] P0017: Add AVE-P0 end-to-end runner (raw → preprocess → cache → metrics)
  - Summary: Provide a single CLI that runs AVE-P0 on a small subset given local raw videos (or download mode), producing caches and `metrics.json`.
  - Rationale: The original `plan.md` is written as a strict stage-by-stage pipeline; this makes it runnable and reproducible.
  - Scope: `avs/pipeline/ave_p0_end2end.py` (new)
  - Acceptance: Running with `--mode local --src-dir ... --limit-train N --limit-eval M` produces `metrics.json`.
  - Extra: `--cache-only` builds caches only (download/preprocess/cache) for large-scale reuse before running training/eval sweeps.
  - Verification: `python -m avs.smoke ave_p0_end2end`
  - Outputs: `runs/<run_id>/ave_p0_end2end/metrics.json`

- [x] P0018: Add PANNs (AudioSet) eventness probe backend
  - Summary: Add a PANNs Cnn14 AudioSet probe (optional pretrained weights) to compute per-second `s(t)` and support it as an `eventness_method` in anchor eval + AVE-P0.
  - Rationale: Root `plan.md` proposes PANNs/AudioMAE as a strong “zero-training” audio probe; adding PANNs makes anchor quality evaluation more realistic than pure energy.
  - Scope: `avs/audio/panns_probe.py`, `avs/experiments/ave_anchor_eval.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/pipeline/plan_generation.py`, `requirements.txt`
  - Acceptance: `eventness_method=panns` runs on a 10s wav (random weights for smoke; optional pretrained via checkpoint) and returns 10 scores; no implicit weight downloads.
  - Verification: `python -m avs.smoke panns_eventness`
  - Outputs: `runs/<run_id>/panns_eventness.json` (smoke), plus optional real-run artifacts when used in experiments.

- [x] P0019: Add EPIC-SOUNDS annotation IO scaffold
  - Summary: Implement EPIC-SOUNDS annotations parsing (train/val/test timestamps + non-categorised), including timestamp parsing and video_id indexing.
  - Rationale: Root `plan.md` proposes EPIC-SOUNDS as the next step after AVE to validate the “long video redundancy filtering” story; we need reliable metadata IO before any anchor-quality or sampling experiments.
  - Scope: `avs/datasets/epic_sounds.py`, `avs/datasets/layout.py`, smoke checks, docs.
  - Acceptance: Can load small sample CSVs (same schema as official EPIC-SOUNDS annotations) into an index and query segments by `video_id`.
  - Verification: `python -m avs.smoke epic_sounds_meta`
  - Outputs: `runs/<run_id>/epic_sounds_meta.json`

- [x] P0020: Add AVQA annotation IO + contrastive prompting templates
  - Summary: Implement AVQA (train/val) QA annotations parsing and a prompt builder for “contrastive prompting” constrained to audio-anchor windows.
  - Rationale: Root `plan.md` proposes AVQA/Pano-AVQA as the cleanest way to test contrastive prompting; we need deterministic QA IO and prompt templates before connecting to any VLM.
  - Scope: `avs/datasets/avqa.py`, `avs/prompts/contrastive.py` (new), `avs/smoke*.py`, docs.
  - Acceptance: Can parse a small sample AVQA JSON into QA items and generate a prompt that includes anchor windows and multiple-choice options.
  - Verification: `python -m avs.smoke avqa_meta`
  - Outputs: `runs/<run_id>/avqa_meta.json`

- [x] P0021: Add anchor robustness knobs (shift + fallback) for AVE
  - Summary: Support a configurable anchor index shift (to model A/V misalignment) and an anchor-confidence fallback (uniform sampling) in anchored baselines.
  - Rationale: Root `plan.md` calls out “扩窗 + 兜底均匀采样” and “可调时延对齐偏移” as required robustness mechanisms.
  - Scope: `avs/audio/eventness.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/pipeline/plan_generation.py`, smoke checks.
  - Acceptance: Anchored sampling can be run with `--anchor-shift` and `--anchor-std-threshold`; when fallback triggers, anchored plan becomes Uniform-224.
  - Verification: `python -m avs.smoke anchor_knobs`
  - Outputs: `runs/<run_id>/anchor_knobs.json`

- [x] P0022: Add VGGSound metadata IO scaffold
  - Summary: Implement VGGSound CSV parsing and an index that can list clips by split and label.
  - Rationale: Root `plan.md` suggests using VGGSound-style timestamped audio events as an additional source for audio probes; we need deterministic metadata IO first.
  - Scope: `avs/datasets/vggsound.py`, `avs/datasets/layout.py`, smoke checks.
  - Acceptance: Can parse a small sample VGGSound CSV (YouTubeID,start_sec,label,split) and build `by_split` indexing.
  - Verification: `python -m avs.smoke vggsound_meta`
  - Outputs: `runs/<run_id>/vggsound_meta.json`

- [x] P0023: Add EPIC-SOUNDS anchor quality eval (Recall@K / Recall@K,Δ)
  - Summary: Evaluate whether audio-derived anchors have higher Recall@K than random anchors on EPIC-SOUNDS (given local per-video audio wavs).
  - Rationale: Root `plan.md` proposes EPIC-SOUNDS as the “long video redundancy filtering” step; this is the first measurable metric (anchor quality) before any VLM/QA integration.
  - Scope: `avs/experiments/epic_sounds_anchor_eval.py` (new), `avs/datasets/epic_sounds.py`, `avs/metrics/anchors.py`, smoke checks.
  - Acceptance: Given a small synthetic EPIC-SOUNDS-style clip list, the eval reports `ours_mean_recall > random_mean_recall` for at least one Δ.
  - Verification: `python -m avs.smoke epic_sounds_anchor_eval`
  - Outputs: `runs/<run_id>/epic_sounds_anchor_eval.json`

- [x] P0024: Add AudioMAE-like eventness probe backend
  - Summary: Add an AudioMAE-style ViT encoder probe (random weights for smoke; optional checkpoint) that returns per-segment `s(t)` and can be selected as `eventness_method=audiomae`.
  - Rationale: Root `plan.md` explicitly proposes “AudioMAE + linear probe” as a stronger audio eventness option; this backend is required before training/probing.
  - Scope: `avs/audio/audiomae_probe.py`, plumbing in `avs/experiments/ave_anchor_eval.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/pipeline/plan_generation.py`, `avs/experiments/epic_sounds_anchor_eval.py`, smoke checks, `requirements.txt`.
  - Acceptance: `eventness_method=audiomae` runs on a 10s wav (random weights for smoke; optional checkpoint) and returns `num_segments` scores; no implicit weight downloads.
  - Verification: `python -m avs.smoke audiomae_eventness`
  - Outputs: `runs/<run_id>/audiomae_eventness.json`

- [x] P0025: Add EPIC-SOUNDS audio extraction helper (untrimmed)
  - Summary: Provide a CLI to extract per-video untrimmed mono 16kHz wavs from EPIC-KITCHENS videos, saved as `<video_id>.wav`.
  - Rationale: EPIC-SOUNDS anchor evaluation requires local untrimmed audio; root `plan.md` calls out this preprocessing step explicitly.
  - Scope: `avs/preprocess/epic_sounds_audio.py` (new), smoke checks.
  - Acceptance: Given `--videos-dir` and `--video-id`, writes `<out-audio-dir>/<video_id>.wav` at 16kHz mono.
  - Verification: `python -m avs.smoke epic_sounds_audio`
  - Outputs: `runs/<run_id>/epic_sounds_audio.json`

- [x] P0026: Add lightweight temporal head option (1D conv)
  - Summary: Add an optional temporal modeling head (1D Conv across time) for per-segment classification, and allow selecting it in AVE-P0 runs.
  - Rationale: Root `plan.md` Phase 4 suggests upgrading the per-second head with lightweight temporal modeling (1D-Conv/Transformer) to improve robustness without changing the vision backbone.
  - Scope: `avs/models/temporal_conv.py` (new), `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, smoke checks.
  - Acceptance: `--head temporal_conv` trains/evals end-to-end on cached features (toy + e2e smoke), producing valid `metrics.json`.
  - Verification: `python -m avs.smoke temporal_head`
  - Outputs: `runs/<run_id>/temporal_head.json`

- [x] P0027: Add Uniform-112 low-token baseline for efficiency curve
  - Summary: Add a `uniform_low` baseline that uses `low_res` (112) uniformly across time, producing fewer tokens than Uniform-224.
  - Rationale: Root `plan.md` Phase 5 requires a cheaper uniform baseline to draw an accuracy–token/latency curve (efficiency story).
  - Scope: `avs/experiments/ave_p0.py`, smoke checks.
  - Acceptance: `uniform_low` appears in `metrics.json` and reports a smaller `token_budget` than `uniform`.
  - Verification: `python -m avs.smoke ave_p0_uniform_low`
  - Outputs: `runs/<run_id>/ave_p0_uniform_low.json`

- [x] P0028: Add vision wall-clock efficiency benchmark
  - Summary: Add a small benchmark utility that reports per-resolution wall-clock time (ms/image) for `ClipVisionEncoder` and includes token counts.
  - Rationale: Root `plan.md` Phase 6 requires efficiency evidence beyond tokens (wall-clock on the same hardware/batch).
  - Scope: `avs/experiments/vision_efficiency.py` (new), smoke checks.
  - Acceptance: Given a batch size and resolutions (112/224/448), writes a JSON report with `ms_per_image` for each resolution; runs offline with `--pretrained false`.
  - Verification: `python -m avs.smoke vision_efficiency`
  - Outputs: `runs/<run_id>/vision_efficiency.json`

- [x] P0029: Add Accuracy–Token efficiency curve plotting utility
  - Summary: Add a small plotting utility to turn AVE-P0 `metrics.json` into an Accuracy–Token scatter/curve with error bars.
  - Rationale: Root `plan.md` requires a paper-ready efficiency curve (accuracy vs tokens/FLOPs/latency); this provides the token-axis plot directly from artifacts.
  - Scope: `avs/visualize/efficiency_curve.py` (new), smoke checks.
  - Acceptance: Given an AVE-P0 `metrics.json` (or an end-to-end `ave_p0_end2end/metrics.json`), writes `efficiency_curve.png` with labeled baselines and mean±std.
  - Verification: `python -m avs.smoke efficiency_curve`
  - Outputs: `runs/<run_id>/efficiency_curve.json`, `runs/<run_id>/efficiency_curve.png`

- [x] P0030: Add long-wav (variable duration) plan.jsonl generation
  - Summary: Support generating `plan.jsonl` for arbitrary-length wavs by inferring `num_segments` from wav duration (1 segment per second).
  - Rationale: Root `plan.md` P1 targets long videos (e.g., EPIC-SOUNDS); we need the same audio→anchors→plan workflow beyond fixed 10s clips.
  - Scope: `avs/pipeline/plan_generation.py`, smoke checks.
  - Acceptance: For a 17s wav, the generated plan has 17 steps and matches the uniform-224 token budget exactly; output JSONL contains anchors, scores, and plan.
  - Verification: `python -m avs.smoke plan_jsonl_long`
  - Outputs: `runs/<run_id>/plan_jsonl_long.json`

- [x] P0031: Add novelty/change-point audio eventness backend (energy_delta)
  - Summary: Add an `energy_delta` backend that scores per-second novelty via absolute log-energy differences.
  - Rationale: Root `plan.md` suggests switching from absolute energy to “新颖度/变化点” if anchors are weak under continuous noise.
  - Scope: `avs/audio/eventness.py`, plumbing in plan generation + eval/runner scripts, smoke checks.
  - Acceptance: `eventness_method=energy_delta` produces 10 scores for a 10s wav and returns stable Top-K anchors on a synthetic “spike” waveform.
  - Verification: `python -m avs.smoke energy_delta_eventness`
  - Outputs: `runs/<run_id>/energy_delta_eventness.json`

- [x] P0032: Add approximate ViT FLOPs estimator (vision efficiency)
  - Summary: Implement an approximate FLOPs estimator for CLIP-ViT forward pass and include it in the `vision_efficiency` benchmark report.
  - Rationale: Root `plan.md` Phase 6 requests efficiency metrics beyond tokens (FLOPs + wall-clock).
  - Scope: `avs/vision/vit_flops.py` (new), `avs/experiments/vision_efficiency.py`, smoke checks.
  - Acceptance: Benchmark JSON includes `approx_flops_per_image` for 112/224/448 and the values increase monotonically with resolution.
  - Verification: `python -m avs.smoke vision_efficiency`
  - Outputs: `runs/<run_id>/vision_efficiency.json`

- [x] P0033: Add EPIC-SOUNDS per-second frame extraction helper (untrimmed)
  - Summary: Provide a CLI to extract one middle-frame per second from an untrimmed EPIC-KITCHENS video, saved as `{0..T-1}.jpg`.
  - Rationale: Root `plan.md` P1 line B needs visual evidence extraction around audio anchors on long videos; per-second frames are the simplest deterministic representation.
  - Scope: `avs/preprocess/epic_sounds_frames.py` (new), reuse ffmpeg utils, smoke checks.
  - Acceptance: Given `--videos-dir` and `--video-id`, writes `<out-frames-dir>/<video_id>/frames/{0..T-1}.jpg` at fps=1 (optionally capped by `--max-seconds`).
  - Verification: `python -m avs.smoke epic_sounds_frames`
  - Outputs: `runs/<run_id>/epic_sounds_frames.json`
  - Evidence: `python -m avs.smoke epic_sounds_frames` → ok (`runs/smoke_20260131-141119/smoke.json`)

- [x] P0034: Standardize EPIC-SOUNDS local data layout paths
  - Summary: Extend `EpicSoundsPaths` with default dirs (`raw/videos`, `audio`, `frames`, `plans`, `caches`, `selected_frames`) and helper path methods.
  - Rationale: Root `plan.md` P1 requires long-video preprocessing and artifacts; a standard layout avoids ad-hoc CLI paths.
  - Scope: `avs/datasets/layout.py`, smoke checks.
  - Acceptance: `epic_sounds_paths()` exposes the standardized paths; EPIC-SOUNDS long-pack smoke can run using these defaults (with synthetic inputs).
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: Standardized default dirs under `data/EPIC_SOUNDS/` (user-provided), plus smoke artifacts under `runs/`.
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0035: Add Hybrid long-video sampling plan generator (EPIC-SOUNDS line B)
  - Summary: Generate a fixed-length Hybrid plan: dense sampling around audio anchors + sparse background sampling, while keeping a strict equal-token budget.
  - Rationale: Root `plan.md` P1 line B needs higher-density visual evidence around anchors on long videos without scaling cost linearly with duration.
  - Scope: `avs/pipeline/long_plan_generation.py`
  - Acceptance: For a 12s wav and `max_steps=8`, produces `selected_seconds` length 8 and a `plan` length 8 whose token budget exactly matches `8 × base_res`.
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: `runs/<run_id>/epic_long_pack_out/plans/<video_id>.long_plan.json`
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0036: Apply long-video plan to frames → manifest + feature cache (Both)
  - Summary: Given extracted per-second frames and a Hybrid plan, materialize a contiguous selected-frames folder, write a JSONL manifest, and (optionally) build a multi-resolution feature cache on the selected seconds.
  - Rationale: Root `plan.md` P1 line B needs an auditable artifact that can be directly consumed by a VLM (manifest) and/or training pipelines (cache).
  - Scope: `avs/pipeline/long_plan_apply.py`, `avs/vision/feature_cache.py`
  - Acceptance: Produces `manifest.jsonl`, `selected_frames/<video_id>/*.jpg`, and `caches/<video_id>.npz` where each array has shape `[max_steps, D]`.
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: `runs/<run_id>/epic_long_pack_out/manifest.jsonl`, `runs/<run_id>/epic_long_pack_out/selected_frames/`, `runs/<run_id>/epic_long_pack_out/caches/*.npz`
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0037: Add EPIC-SOUNDS long-video end-to-end pack + smoke (synthetic-first)
  - Summary: Provide an end-to-end runner: untrimmed video → audio.wav + fps=1 frames → Hybrid plan → manifest + selected frames + (optional) feature cache.
  - Rationale: Root `plan.md` P1 requires an executable, verifiable long-video pipeline even without local EPIC data (smoke uses synthetic videos).
  - Scope: `avs/experiments/epic_sounds_long_pack.py`, `avs/smoke.py`, `avs/smoke_checks.py`
  - Acceptance: `python -m avs.smoke epic_sounds_long_pack` runs on a synthetic video, writing artifacts and passing validation.
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: `runs/<run_id>/epic_long_pack_out/` (manifest, plans, selected_frames, caches)
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0038: Add AVE oracle ceiling sweep (is +2% achievable?)
  - Summary: Add a reproducible oracle-only sweep to estimate the achievable upper bound of “anchored sampling” under equal token budget on official AVE val/test.
  - Rationale: Before chasing +2% on `test402`, confirm the backbone/head has enough headroom (Oracle-TopK vs Uniform). If oracle gains are <2%, anchor tuning alone cannot reach the target.
  - Scope: `avs/experiments/ave_p0_oracle_sweep.py` (new), `scripts/e0010_ave_oracle_ceiling_official.sh` (new)
  - Acceptance: Produces `oracle_ceiling.json` summarizing ≥6 configs with `uniform` vs `oracle_top2` mean/std and paired p-values, plus pointers to raw `metrics.json`.
  - Verification: `bash scripts/e0010_ave_oracle_ceiling_official.sh` (requires official AVE installed)
  - Outputs: `runs/E0010_*/oracle_ceiling.json`
  - Evidence (smoke): `runs/E0010_oracle_ceiling_official_val_20260203-141212/oracle_ceiling.json` (LIMIT_TRAIN=64; LIMIT_EVAL=32; SEEDS=0,1; EPOCHS=1)

- [x] P0039: Add windowed anchors + score smoothing (robust anchor selection)
  - Summary: Add `anchor_select=window_topk` that selects anchors using window-aggregated scores + NMS, and optional score smoothing before selection.
  - Rationale: Plain Top-K often selects adjacent seconds on long-ish events; window aggregation + NMS yields more diverse anchors and better tolerance to A/V misalignment.
  - Scope: `avs/audio/eventness.py`, plumbing in `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_anchor_eval.py`, smoke checks.
  - Acceptance: New selector is deterministic and avoids adjacent anchors under synthetic multi-peak sequences; CLI supports `--anchor-select window_topk --anchor-window 3/5`.
  - Verification: `python -m avs.smoke anchor_window_select`
  - Outputs: `runs/<run_id>/anchor_window_select.json`
  - Evidence: `python -m avs.smoke anchor_window_select` → ok (`runs/smoke_20260202-035940/smoke.json`)

- [x] P0040: Add anchor confidence gating (replace std-only fallback)
  - Summary: Add configurable confidence metrics (std / top1-median / top1-top2 gap / gini) to decide when to fall back to uniform, and record `fallback_reason` per clip in debug.
  - Rationale: Many clips have flat/noisy scores where anchors are unreliable; a stronger gating signal reduces harmful anchored plans and improves stability on `test402`.
  - Scope: `avs/audio/eventness.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_diagnose.py`, smoke checks.
  - Acceptance: `metrics.json` includes `debug_eval.anchored_top2.<clip_id>.fallback_used/fallback_reason/conf_value` for eval clips.
  - Verification: `python -m avs.smoke anchor_confidence_gate`
  - Outputs: `runs/<run_id>/anchor_confidence_gate.json`
  - Evidence: `python -m avs.smoke anchor_confidence_gate` → ok (`runs/smoke_20260202-040007/smoke.json`)

- [x] P0041: Add AVE config sweep + best-to-test reproduction (aim +2% on test402)
  - Summary: Add a fixed-space sweep runner (val402 selection → test402 reproduction) with a machine-readable summary of configs and outcomes.
  - Rationale: Avoid ad-hoc hand tuning; enforce a reproducible process to search configs and re-run the best config on `test402` with `SEEDS=0..9`.
  - Scope: `avs/experiments/ave_p0_sweep.py` (new), `scripts/e0011_ave_p0_sweep_official.sh` (new), `scripts/e0012_ave_p0_best_to_test_official.sh` (new)
  - Acceptance: `sweep_summary.json` lists configs with `anchored_top2 - uniform`, p-values, and paths to each run’s `metrics.json`; best config can be reproduced on test split.
  - Verification: `bash scripts/e0011_ave_p0_sweep_official.sh && bash scripts/e0012_ave_p0_best_to_test_official.sh` (requires official AVE installed)
  - Outputs: `runs/E0011_*/sweep_summary.json`, `runs/E0012_*/metrics.json`
  - Evidence (smoke): `runs/E0011_ave_p0_sweep_official_val_20260203-141418/sweep_summary.json` and `runs/E0012_ave_p0_best_to_test_official_20260203-141430/metrics.json` (LIMIT_TRAIN=64; LIMIT_EVAL=32; SEEDS=0,1; EPOCHS=1)

- [x] P0042: Confirm fusion adds on top of sampling (audio_concat_* baselines)
  - Summary: Add a dedicated script to confirm `audio_concat_anchored_top2` improves over `audio_concat_uniform` under the best sampling config (and record results).
  - Rationale: Target requires both sampling-only and fusion+sampling to be strong; this isolates whether fusion is benefiting from better sampling or simply dominates.
  - Scope: `scripts/e0013_ave_fusion_confirm_official.sh` (new), minor plumbing in `avs/experiments/ave_p0.py` if needed
  - Acceptance: Script runs end-to-end and writes `metrics.json` containing both `audio_concat_uniform` and `audio_concat_anchored_top2` plus paired tests (the target threshold is tracked by `C0004`).
  - Verification: `bash scripts/e0013_ave_fusion_confirm_official.sh` (requires official AVE installed)
  - Outputs: `runs/E0013_*/metrics.json`
  - Evidence (smoke): `runs/E0013_ave_fusion_confirm_official_test_20260203-141624/metrics.json` (LIMIT_TRAIN=64; LIMIT_EVAL=32; SEEDS=0,1; EPOCHS=1)

- [x] P0043: Add EPIC-SOUNDS downstream proxy: video-level multi-label sound event recognition
  - Summary: Add a reproducible downstream task on EPIC-SOUNDS: video-level multi-label classification using selected seconds’ visual features, comparing `uniform` vs `audio_anchored` selection under a fixed token budget.
  - Rationale: Provides a “long video” story with a measurable downstream metric (mAP/macro-F1), beyond anchor Recall@K.
  - Scope: `avs/experiments/epic_sounds_video_cls.py` (new), `avs/models/video_multilabel_head.py` (new), smoke checks, `scripts/e0100_epic_video_cls_local.sh` (new)
  - Acceptance: Synthetic smoke runs end-to-end and writes `metrics.json` with mAP and budget fields; local run works once EPIC mp4s exist under `data/EPIC_SOUNDS/raw/videos/`.
  - Verification: `python -m avs.smoke epic_sounds_video_cls_synth`
  - Outputs: `runs/<run_id>/epic_sounds_video_cls_synth.json`, `runs/<run_id>/epic_sounds_video_cls_synth_metrics.json`
  - Evidence: `python -m avs.smoke epic_sounds_video_cls_synth` → ok (`runs/smoke_20260202-035910/smoke.json`)

- [x] P0044: Add time-window primitives + Coverage@τ metric (Evidence Alignment)
  - Summary: Implement 1D time-window utilities (IoU, merge, dilation) and `Cov@τ` (Coverage@τ) to quantify whether predicted windows cover GT evidence intervals.
  - Rationale: Needed for the Listen-then-Look “Evidence Alignment” story and for diagnosing why anchored gains are small (coverage→accuracy correlation).
  - Scope: `avs/metrics/time_windows.py` (new), optional glue in `avs/metrics/__init__.py`, smoke checks.
  - Acceptance: `iou_1d` and `coverage_at_tau` are deterministic; handles empty evidence/windows; supports float seconds and integer segments.
  - Verification: `python -m avs.smoke evidence_windows`
  - Outputs: `runs/<run_id>/evidence_windows.json`
  - Evidence: `python -m avs.smoke evidence_windows` → ok (`runs/smoke_20260203-134900/smoke.json`)

- [x] P0045: Implement Listen-then-Look budget model + allocator (budgeted config assignment)
  - Summary: Add a strict visual token cost model `Tok(c; L)` and a deterministic budget allocator that assigns per-window configs from a discrete set under `B_vis` and `α` split.
  - Rationale: Turns the method into a decision-complete, reproducible mechanism (no ad-hoc “just sample more near anchors”).
  - Scope: `avs/budget/vis_budget.py` (new), `avs/sampling/allocator.py` (new), smoke checks.
  - Acceptance: Given windows, weights, configs and budget, returns an allocation that never exceeds budget; exposes a stable JSONable report for audit.
  - Verification: `python -m avs.smoke ltl_budget_allocator`
  - Outputs: `runs/<run_id>/ltl_budget_allocator.json`
  - Evidence: `python -m avs.smoke ltl_budget_allocator` → ok (`runs/smoke_20260203-135142/smoke.json`)

- [x] P0046: Extend audio eventness to stride-based scoring + anchor windows (δ, Δ, local maxima)
  - Summary: Support sub-second `stride_s`/`win_s` eventness scoring and convert anchors into explicit time windows `W_i=[t_i-Δ_i, t_i+Δ_i]` (with NMS and fixed expansion).
  - Rationale: Matches the paper setting (Listen-then-Look Stage-1) and enables long-video protocols beyond the fixed 10×1s AVE grid.
  - Scope: `avs/audio/eventness.py`, `avs/audio/augment.py` (new), smoke checks.
  - Acceptance: For a synthetic wav with injected pulses, anchors are found near pulses under multiple `stride_s`; window conversion is deterministic and stable under small shifts.
  - Verification: `python -m avs.smoke ltl_anchor_windows`
  - Outputs: `runs/<run_id>/ltl_anchor_windows.json`
  - Evidence: `python -m avs.smoke ltl_anchor_windows` → ok (`runs/smoke_20260203-135434/smoke.json`)

- [x] P0047: Add cheap-visual anchors baseline (frame-diff eventness)
  - Summary: Implement a low-cost visual eventness heuristic (frame-diff/motion energy on low-res frames) and expose it as an anchor source alongside audio anchors.
  - Rationale: Required baseline in MDE to answer “any window works?” and to provide a fallback when audio is missing/noisy.
  - Scope: `avs/vision/cheap_eventness.py` (new), integrate into `avs/experiments/ave_anchor_eval.py` and `avs/experiments/epic_sounds_anchor_eval.py`, smoke checks.
  - Acceptance: On synthetic sequences with a single visual change, the cheap-visual eventness peaks at the change; anchor eval can run with `method=cheap_visual`.
  - Verification: `python -m avs.smoke cheap_visual_eventness`
  - Outputs: `runs/<run_id>/cheap_visual_eventness.json`
  - Evidence: `python -m avs.smoke cheap_visual_eventness` → ok (`runs/smoke_20260203-135817/smoke.json`)

- [x] P0048: Add MDE harness + Pareto report (Oracle→Predicted; multiple budgets)
  - Summary: Provide a runnable harness that produces Acc–Tok Pareto curves for Oracle vs Predicted vs baselines on a pre-registered budget grid, and writes a single report JSON + plots.
  - Rationale: Establishes the mechanism under the Oracle ceiling, then measures the Predicted gap, with audit-friendly artifacts for reviewers.
  - Scope: `avs/experiments/mde_ltl.py` (new), `avs/visualize/pareto_report.py` (new), smoke checks, `scripts/e0200_*` (new).
  - Acceptance: Toy smoke produces `pareto_report.json` and a plot; full-mode can consume AVE caches and run on val/test splits.
  - Verification: `python -m avs.smoke mde_pareto_toy`
  - Outputs: `runs/<run_id>/pareto_report.json`, `runs/<run_id>/pareto.png`
  - Evidence: `python -m avs.smoke mde_pareto_toy` → ok (`runs/smoke_20260203-140023/smoke.json`)

- [x] P0049: Add degradation protocol runner (offset/noise/silence × α) + report
  - Summary: Implement the Evidence/Degradation protocol: evaluate anchor quality and downstream accuracy under A/V shift, additive noise (SNR), and audio silence, across `α` fallback settings.
  - Rationale: Pre-registered robustness evidence prevents “strong binding only / brittle heuristic” reviewer objections and provides a computable lower bound via `α`.
  - Scope: `avs/experiments/degradation_suite.py` (new), `avs/audio/augment.py`, smoke checks.
  - Acceptance: Toy smoke produces a JSON heatmap keyed by `{shift_s, snr_db, silence_ratio, alpha}`; full-mode runs on AVE val/test.
  - Verification: `python -m avs.smoke ltl_degradation_suite_toy`
  - Outputs: `runs/<run_id>/degradation_suite.json`
  - Evidence: `python -m avs.smoke ltl_degradation_suite_toy` → ok (`runs/smoke_20260203-140151/smoke.json`)

- [x] P0050: Add dataset checklist + download/verify helpers (AVE, EPIC-SOUNDS, EgoSchema/IntentQA)
  - Summary: Standardize required datasets, what can be auto-downloaded, and add `verify_*` scripts that fail fast with actionable instructions.
  - Rationale: Users requested “全量真实数据 + 多卡榨干” runs; we need reproducible dataset install/verify gates before launching long jobs.
  - Scope: `docs/datasets.md` (new), `scripts/datasets/*.sh` (new), optional minimal dataset stubs under `avs/datasets/`.
  - Acceptance: `bash scripts/datasets/verify_all.sh` reports which datasets are installed, and prints exact next steps for missing ones.
  - Verification: `bash scripts/datasets/verify_all.sh`
  - Outputs: `runs/<run_id>/datasets_verify.json`
  - Evidence: `bash scripts/datasets/verify_all.sh` → ok (`runs/datasets_verify_20260203-140543/datasets_verify.json`)

- [x] P0051: Strengthen Stage-1 anchors (energy_stride_max + AV-fused eventness) to close Oracle→Pred gap
  - Summary: Add deployable Stage-1 improvements: (1) stride-based log-energy aggregated to per-second scores (`energy_stride_max`), and (2) high-recall audio+cheap-visual fusion (`av_fused`) that survives silence/noise.
  - Rationale: Current best `anchored_top2` gain on AVE test402 is ~+1% while Oracle upper bound is much higher; evidence-alignment suggests Stage-1 coverage is the bottleneck. Improving anchors is the shortest path to “拉大”.
  - Scope:
    - `avs/audio/eventness.py` (new per-second stride aggregation)
    - `avs/experiments/ave_p0.py` + `avs/experiments/ave_p0_sweep.py` + `avs/experiments/ave_anchor_eval.py` (new methods)
    - `avs/experiments/mde_ltl.py` (E0201 support) + `avs/experiments/degradation_suite.py` (E0203 support)
    - `avs/smoke.py`, `avs/smoke_checks.py` (new smokes)
  - Acceptance:
    - `--eventness-method {energy_stride_max,av_fused}` is supported end-to-end (P0, sweep, anchor eval, MDE, degradation).
    - New smoke checks pass and demonstrate the intended behavior under (audio-only) and (audio-silent but visual-change) cases.
  - Verification:
    - `python -m avs.smoke ltl_eventness_stride_max`
    - `python -m avs.smoke ltl_eventness_av_fused`
    - `python -m avs.smoke all`
  - Outputs: N/A (enables E0201/E0203 + later C0003 reruns)
  - Evidence: `python -m avs.smoke all` → ok (`runs/smoke_20260203-205119/smoke.json`)

- [x] P0052: Fix AV-fused score scale mismatch with anchor confidence gate (avoid all-fallback collapse)
  - Summary: Ensure `eventness_method=av_fused` remains compatible with the default anchor confidence gate (`conf_metric=std`, `std_threshold=1.0`) by scaling fused scores to an energy-like magnitude.
  - Rationale: E0201 showed `av_fused` collapsed to `uniform` because scores were normalized to `[0,1]` while the gate threshold was tuned for log-energy scales, triggering fallback on ~100% clips and invalidating the comparison.
  - Scope:
    - `avs/utils/scores.py` (AV_FUSED_SCORE_SCALE + helper)
    - `avs/experiments/ave_p0.py`, `avs/experiments/ave_p0_sweep.py`, `avs/experiments/ave_anchor_eval.py`, `avs/experiments/mde_ltl.py` (apply the scale in `av_fused`)
    - `avs/smoke_checks.py` (assert gate no longer triggers on the fused synthetic case)
  - Acceptance:
    - `python -m avs.smoke ltl_eventness_av_fused` reports `fallback_used=false` with `conf_threshold=1.0`.
    - Full E0201 `EVENTNESS=av_fused` no longer has `fallback_used≈1.0` in `metrics_predicted.json` (anchor proposals actually used).
  - Verification:
    - `python -m avs.smoke ltl_eventness_av_fused`
    - `TRAIN_DEVICE=cuda:2 EVENTNESS=av_fused bash scripts/e0201_oracle_vs_predicted_official.sh`
  - Outputs: N/A (unblocks fair evaluation of av_fused anchors in E0201/C0007)
  - Evidence: `python -m avs.smoke ltl_eventness_av_fused` → ok (`runs/smoke_20260203-221305/smoke.json`; `conf_value≈1.05 >= 1.0`, `fallback_used=false`)
  - Evidence: `runs/E0201_oracle_vs_predicted_av_fused_scale3p5_full_20260203-221906/oracle_vs_predicted.json` (fallback_used_frac≈0.739; no longer collapses to `uniform`)

- [x] P0053: Add learned audio eventness backends to strengthen Stage-1 anchors (shrink Oracle→Pred gap)
  - Summary: Add supervised audio-only eventness options (trained on AVE train split) to improve anchor reliability and close the Oracle→Predicted gap.
  - Rationale: Oracle anchors show a large upper bound on test402, but current deployable anchors remain ~3% behind Oracle (C0007) and only yield ~+1% gain (C0003). A learned-but-cheap audio eventness model is the shortest path to increase precision without expensive visual passes.
  - Scope:
    - `avs/experiments/mde_ltl.py` (E0201: allow learned methods)
    - `avs/experiments/degradation_suite.py` (E0203: learned-method robustness under shift/noise/silence)
    - `avs/audio/features.py` (feature extraction from in-memory audio for augmentations)
    - `docs/experiment.md` + `docs/mohu.md` (track the new experiments and evidence)
  - Acceptance:
    - `EVENTNESS ∈ {audio_basic_lr,audio_basic_mlp,audio_fbank_mlp,audio_basic_mlp_cls,audio_basic_mlp_cls_target}` runs in E0201 (oracle_vs_predicted) on official AVE.
    - E0203 supports `EVENTNESS=audio_fbank_mlp` (and at least one other learned method) and writes `degradation_suite.json`.
  - Verification:
    - `python -m avs.experiments.mde_ltl oracle_vs_predicted --mode toy`
    - `EVENTNESS=audio_fbank_mlp bash scripts/e0201_oracle_vs_predicted_official.sh`
    - `EVENTNESS=audio_basic_lr bash scripts/e0203_degradation_suite_official.sh`
  - Outputs: `runs/E0201_*/oracle_vs_predicted.json`, `runs/E0203_*/degradation_suite.json`
  - Evidence: `runs/E0201_oracle_vs_predicted_audio_fbank_mlp_20260204-000652/oracle_vs_predicted.json` (wires `EVENTNESS=audio_fbank_mlp`; anchored=0.7138 vs uniform=0.7086)
  - Evidence: `runs/E0203_degradation_audio_basic_lr_20260204-012618/degradation_suite.json` (wires `EVENTNESS=audio_basic_lr` in E0203)

## Conclusions
- [x] C0001: On AVE, under a strictly equal ViT token budget, Audio-anchored sampling (with a lightweight temporal head) improves segment-level accuracy vs Uniform sampling and Random anchors.
  - Evidence required: `metrics.json` with `acc_mean±std` over ≥3 seeds for Uniform-224, Random-TopK, Audio-TopK; plus a statement that token budgets are equal. Must hold on a non-trivial subset (e.g., ≥100 eval clips).
  - Experiments: E0001
  - Artifacts: `runs/AVE_P0/*/metrics.json`
  - Evidence (small subset): `runs/E0001_ave_p0_real_20260131-040050/p0_energy_seedfix/metrics.json` (energy; 3 seeds; `anchored_top2.mean=0.756 > random_top2.mean=0.711 > uniform.mean=0.244`; `token_budget=1960`)
  - Evidence (counter; MLP head): `runs/REAL_AVE_20260131-211548/p0_train180_val165_energy/metrics.json` (energy; 3 seeds; `uniform.mean=0.250 > anchored_top2.mean=0.214`; `token_budget=1960`); `runs/REAL_AVE_20260131-211548/p0_train180_test113_energy/metrics.json` (energy; 3 seeds; `uniform.mean=0.254 > anchored_top2.mean=0.212`; `token_budget=1960`)
  - Evidence (oracle upper bound emerges under a less-extreme equal-budget plan): `runs/REAL_AVE_20260131-211548/p0_train180_val165_energy_160_224_352_k2/metrics.json` (energy; 3 seeds; `oracle_top2.mean=0.258 > uniform.mean=0.250 > anchored_top2.mean=0.242`; `token_budget=1960`)
  - Evidence (k=1 mitigates but still < uniform): `runs/REAL_AVE_20260131-211548/p0_train180_val165_k1_energy_rerun/metrics.json` and `runs/REAL_AVE_20260131-211548/p0_train180_test113_k1_energy_rerun/metrics.json`
  - Evidence (temporal_conv head + robustness knobs; energy; triad=160/224/352; k=2; shift=1; std_thr=1.0; token_budget=1960):
    - Val165: `runs/REAL_AVE_20260131-211548/p0_train180_val165_energy_160_224_352_k2_shift1_std1p0_temporal_s0-9_rerun/metrics.json` (10 seeds; `anchored_top2.mean=0.228 > uniform.mean=0.221 > random.mean=0.211`)
    - Test113: `runs/REAL_AVE_20260131-211548/p0_train180_test113_energy_160_224_352_k2_shift1_std1p0_temporal_s0-9_rerun/metrics.json` (10 seeds; `anchored_top2.mean=0.233 > uniform.mean=0.230 > random.mean=0.221`)
  - Evidence (expanded train=195): `runs/REAL_AVE_20260131-211548/p0_train195_val165_energy_160_224_352_k2_shift1_std1p0_temporal_s0-4/metrics.json` (5 seeds; `anchored_top2.mean=0.232 > uniform.mean=0.211`) and `runs/REAL_AVE_20260131-211548/p0_train195_test113_energy_160_224_352_k2_shift1_std1p0_temporal_s0-4/metrics.json` (5 seeds; `anchored_top2.mean=0.274 > uniform.mean=0.259`)
  - Evidence (official full split; temporal_conv; energy; triad=160/224/352; k=2; shift=1; std_thr=1.0; token_budget=1960; 10 seeds):
    - Val402: `runs/REAL_AVE_OFFICIAL_20260201-124535/p0_train3339_val402_energy_160_224_352_k2_shift1_std1.0_temporal_conv/metrics.json` (`anchored_top2.mean=0.738 > uniform.mean=0.730 > random.mean=0.719`; `paired_ttest.anchored_vs_uniform.p=0.048`)
    - Test402: `runs/REAL_AVE_OFFICIAL_20260201-124535/p0_train3339_test402_energy_160_224_352_k2_shift1_std1.0_temporal_conv/metrics.json` (`anchored_top2.mean≈uniform.mean`: 0.719 vs 0.719; `paired_ttest.anchored_vs_uniform.p=0.896`; `anchored_top2.mean=0.719 > random.mean=0.699`)
  - Evidence (official full split rerun; same config; adds `audio_concat_anchored_top2`; head trained on `cuda:0`; token_budget=1960; 10 seeds):
    - Val402: `runs/REAL_AVE_OFFICIAL_RERUN_20260201-152134/p0_train3339_val402_energy_160_224_352_k2_shift1_std1.0_temporal_conv_v2/metrics.json` (`anchored_top2.mean=0.751 > uniform.mean=0.740`; `paired_ttest.anchored_vs_uniform.p=0.009`; `audio_concat_uniform.mean=0.749`)
    - Test402: `runs/REAL_AVE_OFFICIAL_RERUN_20260201-152134/p0_train3339_test402_energy_160_224_352_k2_shift1_std1.0_temporal_conv_v2/metrics.json` (`anchored_top2.mean=0.731 > uniform.mean=0.719`; `paired_ttest.anchored_vs_uniform.p=0.046`; `audio_concat_uniform.mean=0.734`)

- [x] C0002: Audio-based anchors achieve higher Recall@K (and Recall@K,Δ) than random anchors on AVE.
  - Evidence required: Table or JSON with Recall@K for (energy baseline, PANNs optional, random) and at least one Δ setting.
  - Experiments: E0002
  - Artifacts: `runs/anchors/*/anchors_metrics.json`
  - Evidence: `runs/E0002_anchors_real_20260131-045200/anchor_eval/anchors_metrics.json` (energy; k=2; n=89; Δ=0: ours=0.207 > random=0.194). Also: `runs/REAL_AVE_20260131-211548/anchors_val165_energy/anchors_metrics.json` (k=2; n=165; Δ=0: ours=0.208 > random=0.202) and `runs/REAL_AVE_20260131-211548/anchors_test113_energy/anchors_metrics.json` (k=2; n=113; Δ=0: ours=0.221 > random=0.181). Official full split: val `runs/REAL_AVE_OFFICIAL_20260201-124535/E0002_anchors_official_val/anchor_eval/anchors_metrics.json` (n=401; Δ=0 ours=0.231 > random=0.211) and test `runs/REAL_AVE_OFFICIAL_20260201-124535/E0002_anchors_official_test/anchor_eval/anchors_metrics.json` (n=402; Δ=0 ours=0.231 > random=0.204). Note: for dilated windows (Δ1/Δ2), random > ours on both val/test.

- [ ] C0003: On official AVE test402, sampling-only anchored_top2 improves >= +2.0% with p<0.05 (SEEDS=0..9).
  - Evidence required: `metrics.json` from the best config selected on val402 and reproduced on test402, with strict equal token budget and paired t-test.
  - Experiments: E0012,E0018,E0019,E0021,E0022
  - Evidence (full; energy_v2 improves but still does **not** meet the target):
    - Val401 sweep (selection): `runs/E0018_ave_p0_sweep_official_val_energy_v2_20260203-185629/sweep_summary.json` (best=`energy_ref_k2_topk_std1p0`, Δ=+0.01344, p=0.00175) + `runs/E0018_ave_p0_sweep_official_val_energy_v2_20260203-185629/best_config.json`.
    - Test402 reproduction: `runs/E0019_ave_p0_best_to_test_official_energy_v2_20260203-190500/metrics.json` (anchored=0.7188 vs uniform=0.7086, Δ=+0.01017, p=0.00466; fallback_used≈0.731).
  - Evidence (full; energy_v3 sweep does not find a stronger config than energy_v2):
    - Val401 sweep: `runs/E0021_ave_p0_sweep_official_val_energy_v3_20260203-194306/sweep_summary.json` (best=`energyv3_ref_shift1_std1p0`, Δ=+0.01344, p=0.00175).
    - Test402 reproduction: `runs/E0022_ave_p0_best_to_test_official_energy_v3_20260203-195707/metrics.json` (anchored=0.7188 vs uniform=0.7086, Δ=+0.01017, p=0.00466).
  - Evidence (diagnostic; top-3 val configs do not transfer better than the best):
    - Test402 (val rank #2): `runs/E0022b_energyv3_shift1_std0p6_test402_20260203-195743/metrics.json` (Δ=+0.00512, p=0.144).
    - Test402 (val rank #3): `runs/E0022c_energyv3_shift0_std1p0_test402_20260203-195754/metrics.json` (Δ=+0.00388, p=0.349).
  - Evidence (diagnostic; longer training does not help this gap): `runs/E0024_energy_ref_test402_epochs20_20260203-194640/metrics.json` (Δ=+0.00281, p=0.587).
  - Evidence (diagnostic; increasing K and using score-based base allocation does not beat best): `runs/E0025_energy_k5_maxHigh1_scoreAlloc_test402_20260203-200327/metrics.json` (Δ=+0.00876, p=0.0106).
  - Evidence (full; AST-based anchors do **not** transfer and can significantly regress): `runs/E0015_ave_p0_best_to_test_official_ast_20260203-172848/metrics.json` (anchored=0.7003 vs uniform=0.7123, Δ=-0.0120, p=0.024; fallback≈0.169). Diagnosis: `runs/E0016_ave_p0_diagnose_20260203-173704/diagnose.json` (adjacent 2-anchor cases are most harmful).

- [ ] C0004: On official AVE test402, audio_concat_anchored_top2 improves over audio_concat_uniform (>= +1.0%, p<0.05; SEEDS=0..9).
  - Evidence required: `metrics.json` under the best sampling config, showing fusion gains beyond uniform fusion baseline.
  - Experiments: E0013,E0017,E0020,E0023
  - Evidence (full; does **not** meet the target): `runs/E0013_ave_fusion_confirm_official_test_20260203-150226/metrics.json` (audio_concat_anchored=0.7213 vs audio_concat_uniform=0.7162, Δ=+0.0051, p=0.367).
  - Evidence (full; energy_v2 config regresses fusion): `runs/E0020_ave_fusion_confirm_official_test_energy_v2_20260203-190804/metrics.json` (audio_concat_anchored=0.7195 vs audio_concat_uniform=0.7214, Δ=-0.0020, p=0.598).

- [ ] C0005: On EPIC-SOUNDS video-level multi-label recognition, audio-anchored selection improves mAP on val (SEEDS>=3).
  - Evidence required: `metrics.json` with mAP/macro-F1 and a clear fixed budget definition (`max_steps × base_res`), plus baselines.
  - Experiments: E0100
  - Artifacts: `runs/E0100_*/metrics.json`

- [ ] C0006: Oracle anchors provide an upper bound that shows stable Acc–Tok Pareto improvements across a pre-registered budget grid on AVE.
  - Evidence required: `oracle_ceiling.json` + Pareto plot (with CI) showing Oracle dominates Uniform/Random at ≥1 budget point (and is non-worse elsewhere).
  - Experiments: E0010
  - Artifacts: `runs/E0010_*/oracle_ceiling.json`, `runs/E0010_*/pareto.*`
  - Evidence (oracle ceiling sweep; fixed budget, strong upper bound): val402 `runs/E0010_oracle_ceiling_official_val_20260203-144421/oracle_ceiling.json` (best=`160_224_352_temporal_k5`, oracle=0.7931 vs uniform=0.7311, Δ=+0.0620, p=8.9e-05) and test402 `runs/E0010_oracle_ceiling_official_test_20260203-143455/oracle_ceiling.json` (best=`160_224_352_temporal_k5`, oracle=0.7663 vs uniform=0.7126, Δ=+0.0536, p=8.9e-06). Note: this is not yet a multi-budget Pareto grid; use it as the mechanism upper bound.

- [ ] C0007: Predicted anchors stay within a small gap of Oracle anchors on the same budget grid (deployable stage-1).
  - Evidence required: A report showing mean(Oracle–Pred) ≤ ε across budgets, plus Predicted still beats best baseline with p<0.05 on ≥1 budget.
  - Experiments: E0201
  - Artifacts: `runs/E0201_*/oracle_vs_predicted.json`
  - Evidence (full; fixed budget; test402): `runs/E0201_full_energy_20260203-210017/oracle_vs_predicted.json` (oracle_minus_predicted=0.03124; anchored=0.7188 vs uniform=0.7086, p=0.00466). `runs/E0201_full_energy_stride_max_20260203-210017/oracle_vs_predicted.json` (oracle_minus_predicted=0.03254). `runs/E0201_oracle_vs_predicted_av_fused_scale3p5_full_20260203-221906/oracle_vs_predicted.json` (after fixing confidence-gate scale mismatch; anchored=0.7190 vs uniform=0.7086, p=0.00995; oracle_minus_predicted≈0.03097; fallback_used_frac≈0.739).

- [ ] C0008: Evidence Alignment (Cov@τ) correlates with downstream accuracy and diagnoses failure cases.
  - Evidence required: Cov@τ table and a scatter/correlation report where higher Cov@τ predicts higher anchored gains (report Pearson/Spearman).
  - Experiments: E0202
  - Artifacts: `runs/E0202_*/evidence_alignment.json`
  - Evidence (full; currently weak alignment/correlation on test402): `runs/E0202_evidence_alignment_energy_v2_test_20260203-194355/evidence_alignment.json` (Cov@τ mean≈0.059 for τ∈{0.3,0.5,0.7}; corr pearson≈0.080, spearman≈-0.003).

- [ ] C0009: Listen-then-Look degrades gracefully under shift/noise/silence, and α provides a computable accuracy lower bound.
  - Evidence required: Degradation heatmaps/curves over `{shift_s, snr_db, silence_ratio, alpha}` showing monotonic trends and no catastrophic drops below the α-baseline.
  - Experiments: E0203
  - Artifacts: `runs/E0203_*/degradation_suite.json`, `runs/E0203_*/degradation_plots/*`
  - Evidence (stage-1 recall only; alpha lower bound pending): `runs/E0203_full_energy_20260203-210331/degradation_suite.json`, `runs/E0203_full_energy_stride_max_20260203-210414/degradation_suite.json`, `runs/E0203_full_av_fused_20260203-210458/degradation_suite.json` (av_fused improves mean Recall@K,Δ2 but hurts strict Δ0).
