# Plan

This repo contains the free-form draft in `plan.md`. This document is the **canonical, actionable plan** (machine-friendly) derived from that draft.

## Items
- [x] P0001: Bootstrap AVS codebase scaffold
  - Summary: Create a minimal Python package + CLI + smoke test entrypoints for the AVS (Audio-Visual Synchronizer) pipeline.
  - Rationale: Enables incremental implementation and verifiable progress instead of a free-form writeup.
  - Scope: `avs/`, `scripts/`, `tests/`, `requirements.txt` (or `pyproject.toml`)
  - Acceptance: `python -m avs.cli --help` works; a smoke command runs end-to-end on synthetic data.
  - Verification: `python -m avs.smoke`
  - Outputs: `avs/` package, runnable smoke output under `runs/`

- [x] P0002: Define AVE dataset IO + splits parsing
  - Summary: Implement AVE metadata parsing (splits + labels) and a dataset interface with a documented on-disk layout.
  - Rationale: All later steps (preprocess/train/eval) depend on deterministic data indexing (10 seconds → 10 segments).
  - Scope: `avs/datasets/ave.py`, `avs/datasets/layout.py`, docs in `docs/`
  - Acceptance: Dataset can load a video id and return 10 segment labels; missing files give clear errors.
  - Verification: `python -m avs.smoke ave_meta`
  - Outputs: AVE metadata under `data/AVE/meta/`

- [x] P0003: Implement deterministic preprocessing (audio + per-second frames)
  - Summary: Given raw AVE videos, extract 16kHz mono wav and one middle-frame JPG per second (10 total).
  - Rationale: Makes the “per-second” experimental protocol reproducible and speeds iteration.
  - Scope: `avs/preprocess/ave_extract.py`, `scripts/ave_extract.sh`
  - Acceptance: For a single video, produces `{clip_id}/audio.wav` and `{clip_id}/frames/{0..9}.jpg` with stable timestamps.
  - Verification: `python -m avs.smoke preprocess_one`
  - Outputs: `data/AVE/processed/<clip_id>/audio.wav`, `data/AVE/processed/<clip_id>/frames/*.jpg`

- [x] P0004: Implement audio eventness → anchors + Recall@K
  - Summary: Implement `s(t)` (eventness) and Top-K anchor generation, plus Recall@K (and optional ±Δ dilation).
  - Rationale: Verifies the key premise: audio provides sparse time proposals better than random.
  - Scope: `avs/audio/eventness.py`, `avs/metrics/anchors.py`
  - Acceptance: Produces anchors for 10 segments; Recall@K works on synthetic or real labels.
  - Verification: `python -m avs.smoke anchors`
  - Outputs: Anchor JSON under `runs/<run_id>/anchors.json`

- [x] P0005: Implement token-budgeted sampling plans (Uniform vs Anchored)
  - Summary: Generate per-second resolution plans with strict equal token budget (e.g., `2×448 + 8×112 == 10×224` for ViT/16).
  - Rationale: This is the “knife edge” of the method: same budget, better allocation.
  - Scope: `avs/sampling/token_budget.py`, `avs/sampling/plans.py`
  - Acceptance: For any anchor set, outputs a 10-step plan whose total tokens exactly matches the target.
  - Verification: `python -m avs.smoke sampling_plan`
  - Outputs: `runs/<run_id>/plan.json`

- [x] P0006: Implement a variable-resolution CLIP/Vision encoder wrapper
  - Summary: Use a ViT/16 vision backbone that accepts 112/224/448 inputs via positional embedding interpolation and returns per-frame embeddings.
  - Rationale: Needed to realize the “more tokens near anchors” design while keeping the same backbone.
  - Scope: `avs/vision/clip_vit.py`
  - Acceptance: Encodes the same image at 112/224/448 and returns embeddings with consistent dim; batch inference works on CPU.
  - Verification: `python -m avs.smoke vision_encoder`
  - Outputs: Cached features under `runs/<run_id>/features/` (optional)

- [x] P0007: Implement AVE per-second classifier + training/eval loop
  - Summary: Train a lightweight head (MLP; optional 1D temporal module) on top of frozen vision features; evaluate segment-level accuracy.
  - Rationale: Enables the main claim to be tested under controlled conditions.
  - Scope: `avs/models/`, `avs/train/`
  - Acceptance: A short smoke training run completes; evaluation produces segment-acc for baseline/ours on synthetic data.
  - Verification: `python -m avs.smoke train_smoke`
  - Outputs: `runs/<run_id>/metrics.json`, `runs/<run_id>/ckpt.pt`

- [x] P0008: Generate per-clip plan.jsonl from audio eventness (dataset-wide)
  - Summary: For a set of processed clips, compute `s(t)` → Top-K anchors → equal-budget sampling plan, and write `plan.jsonl`.
  - Rationale: Matches `plan.md`’s requirement to make sampling reproducible and audit-friendly.
  - Scope: `avs/pipeline/plan_generation.py`
  - Acceptance: Produces a valid JSONL (1 line/clip) with `clip_id`, `anchors`, `scores`, and `plan.total_tokens`.
  - Verification: `python -m avs.smoke plan_jsonl`
  - Outputs: `runs/<run_id>/plan.jsonl`

- [x] P0009: Provide dataset-level preprocessing CLI (multi-clip)
  - Summary: Preprocess multiple raw clips into `{clip_id}/audio.wav` + `{clip_id}/frames/*.jpg`.
  - Rationale: Needed to scale Phase 1 from single-clip demo to dataset subset runs.
  - Scope: `avs/preprocess/ave_dataset.py`
  - Acceptance: Given `--raw-videos-dir` and `--video-id ...`, produces outputs for each requested clip id.
  - Verification: `python -m avs.smoke preprocess_dataset`
  - Outputs: `data/AVE/processed/<clip_id>/...`

- [x] P0010: Add AudioSet classifier-based eventness (AST) as a probe option
  - Summary: Provide an eventness backend that uses a pretrained audio classifier (AST on AudioSet) to compute `s(t)` per second.
  - Rationale: `plan.md` suggests using a lightweight pretrained audio model (e.g., PANNs/AudioMAE); AST is an easily swappable first implementation.
  - Scope: `avs/audio/ast_probe.py` (new), `avs/audio/eventness.py`
  - Acceptance: Can compute a length-10 `s(t)` from a 10s wav; supports `--pretrained` and a random-weight fallback.
  - Verification: `python -m avs.smoke ast_eventness`
  - Outputs: `runs/<run_id>/ast_eventness.json`

- [x] P0011: Add dataset-wide anchor quality evaluation (Recall@K / Recall@K,Δ)
  - Summary: Evaluate anchors vs GT segments across a split and report Recall@K, plus dilation robustness for Δ∈{0,1,2}.
  - Rationale: Separates “anchor quality” from “visual budget allocation” as required by `plan.md`.
  - Scope: `avs/experiments/ave_anchor_eval.py` (new)
  - Acceptance: Produces `anchors_metrics.json` with Recall@K and Recall@K,Δ; includes a random anchor baseline.
  - Verification: `python -m avs.smoke anchors_dataset`
  - Outputs: `runs/<run_id>/anchors_metrics.json`

- [x] P0012: Add multi-resolution feature cache for processed frames
  - Summary: Precompute and cache CLIP embeddings for each clip at {112,224,448} to make P0 training fast and comparable across baselines.
  - Rationale: Needed to run Uniform/Random/Anchored/Oracle without recomputing embeddings for each variant.
  - Scope: `avs/vision/feature_cache.py` (new), `avs/experiments/ave_build_cache.py` (new)
  - Acceptance: Given a processed clip dir, creates an `.npz` with arrays for each resolution.
  - Verification: `python -m avs.smoke feature_cache`
  - Outputs: `runs/<run_id>/features_cache/*.npz`

- [x] P0013: Implement AVE-P0 runner on cached features (Uniform/Random/Anchored/Oracle)
  - Summary: Train a per-segment classifier on cached features and evaluate segment-level accuracy for each baseline under equal token budget.
  - Rationale: This is the core “same tokens, better allocation” claim in `plan.md`.
  - Scope: `avs/experiments/ave_p0.py` (new)
  - Acceptance: Writes `metrics.json` with per-baseline accuracy and token budget confirmation; supports `--seeds 0,1,2`.
  - Verification: `python -m avs.smoke ave_p0_toy`
  - Outputs: `runs/AVE_P0/*/metrics.json`

- [x] P0014: Add Audio-Feature Concat baseline (fusion, not indexing)
  - Summary: Add a baseline that concatenates a per-second audio feature into the classifier input while keeping visual sampling Uniform-224.
  - Rationale: Required by `plan.md` to disentangle “audio adds information” vs “audio acts as an index”.
  - Scope: `avs/experiments/ave_p0.py`
  - Acceptance: `audio_concat_uniform` appears in `metrics.json` and runs end-to-end on cached features.
  - Verification: `python -m avs.smoke ave_p0_toy`
  - Outputs: `runs/AVE_P0/*/metrics.json`

- [x] P0015: Add qualitative visualization (s(t) + anchors + GT + sampled resolutions)
  - Summary: For a clip, plot `s(t)` with anchors, GT event segments, and the sampling plan’s per-second resolutions.
  - Rationale: Provides the qualitative evidence requested in `plan.md` Stage 6.
  - Scope: `avs/visualize/anchors_plot.py` (new)
  - Acceptance: Generates a PNG for a synthetic clip.
  - Verification: `python -m avs.smoke viz`
  - Outputs: `runs/<run_id>/viz.png`

- [x] P0016: Add AVE raw-video acquisition helper (local copy / yt-dlp)
  - Summary: Provide a utility to materialize `data/AVE/raw/videos/<video_id>.mp4` either by copying from a local directory or by downloading via `yt-dlp`.
  - Rationale: `plan.md` Phase 1 requires raw videos to run real AVE-P0 beyond synthetic smoke tests.
  - Note: For the *official full* AVE dataset (4143 clips), prefer `bash scripts/ave_install_official.sh` which downloads `AVE_Dataset.zip` and installs videos under `data/AVE/raw/videos/`. `yt-dlp` mode is best-effort and may miss many videos.
  - Scope: `avs/datasets/ave_download.py` (new), `scripts/ave_download.sh`
  - Acceptance: Can fetch a requested `--video-id` into the raw videos dir; “local” mode works without network.
  - Verification: `python -m avs.smoke ave_download`
  - Outputs: `data/AVE/raw/videos/*.mp4`

- [x] P0017: Add AVE-P0 end-to-end runner (raw → preprocess → cache → metrics)
  - Summary: Provide a single CLI that runs AVE-P0 on a small subset given local raw videos (or download mode), producing caches and `metrics.json`.
  - Rationale: The original `plan.md` is written as a strict stage-by-stage pipeline; this makes it runnable and reproducible.
  - Scope: `avs/pipeline/ave_p0_end2end.py` (new)
  - Acceptance: Running with `--mode local --src-dir ... --limit-train N --limit-eval M` produces `metrics.json`.
  - Extra: `--cache-only` builds caches only (download/preprocess/cache) for large-scale reuse before running training/eval sweeps.
  - Verification: `python -m avs.smoke ave_p0_end2end`
  - Outputs: `runs/<run_id>/ave_p0_end2end/metrics.json`

- [x] P0018: Add PANNs (AudioSet) eventness probe backend
  - Summary: Add a PANNs Cnn14 AudioSet probe (optional pretrained weights) to compute per-second `s(t)` and support it as an `eventness_method` in anchor eval + AVE-P0.
  - Rationale: Root `plan.md` proposes PANNs/AudioMAE as a strong “zero-training” audio probe; adding PANNs makes anchor quality evaluation more realistic than pure energy.
  - Scope: `avs/audio/panns_probe.py`, `avs/experiments/ave_anchor_eval.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/pipeline/plan_generation.py`, `requirements.txt`
  - Acceptance: `eventness_method=panns` runs on a 10s wav (random weights for smoke; optional pretrained via checkpoint) and returns 10 scores; no implicit weight downloads.
  - Verification: `python -m avs.smoke panns_eventness`
  - Outputs: `runs/<run_id>/panns_eventness.json` (smoke), plus optional real-run artifacts when used in experiments.

- [x] P0019: Add EPIC-SOUNDS annotation IO scaffold
  - Summary: Implement EPIC-SOUNDS annotations parsing (train/val/test timestamps + non-categorised), including timestamp parsing and video_id indexing.
  - Rationale: Root `plan.md` proposes EPIC-SOUNDS as the next step after AVE to validate the “long video redundancy filtering” story; we need reliable metadata IO before any anchor-quality or sampling experiments.
  - Scope: `avs/datasets/epic_sounds.py`, `avs/datasets/layout.py`, smoke checks, docs.
  - Acceptance: Can load small sample CSVs (same schema as official EPIC-SOUNDS annotations) into an index and query segments by `video_id`.
  - Verification: `python -m avs.smoke epic_sounds_meta`
  - Outputs: `runs/<run_id>/epic_sounds_meta.json`

- [x] P0020: Add AVQA annotation IO + contrastive prompting templates
  - Summary: Implement AVQA (train/val) QA annotations parsing and a prompt builder for “contrastive prompting” constrained to audio-anchor windows.
  - Rationale: Root `plan.md` proposes AVQA/Pano-AVQA as the cleanest way to test contrastive prompting; we need deterministic QA IO and prompt templates before connecting to any VLM.
  - Scope: `avs/datasets/avqa.py`, `avs/prompts/contrastive.py` (new), `avs/smoke*.py`, docs.
  - Acceptance: Can parse a small sample AVQA JSON into QA items and generate a prompt that includes anchor windows and multiple-choice options.
  - Verification: `python -m avs.smoke avqa_meta`
  - Outputs: `runs/<run_id>/avqa_meta.json`

- [x] P0021: Add anchor robustness knobs (shift + fallback) for AVE
  - Summary: Support a configurable anchor index shift (to model A/V misalignment) and an anchor-confidence fallback (uniform sampling) in anchored baselines.
  - Rationale: Root `plan.md` calls out “扩窗 + 兜底均匀采样” and “可调时延对齐偏移” as required robustness mechanisms.
  - Scope: `avs/audio/eventness.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/pipeline/plan_generation.py`, smoke checks.
  - Acceptance: Anchored sampling can be run with `--anchor-shift` and `--anchor-std-threshold`; when fallback triggers, anchored plan becomes Uniform-224.
  - Verification: `python -m avs.smoke anchor_knobs`
  - Outputs: `runs/<run_id>/anchor_knobs.json`

- [x] P0022: Add VGGSound metadata IO scaffold
  - Summary: Implement VGGSound CSV parsing and an index that can list clips by split and label.
  - Rationale: Root `plan.md` suggests using VGGSound-style timestamped audio events as an additional source for audio probes; we need deterministic metadata IO first.
  - Scope: `avs/datasets/vggsound.py`, `avs/datasets/layout.py`, smoke checks.
  - Acceptance: Can parse a small sample VGGSound CSV (YouTubeID,start_sec,label,split) and build `by_split` indexing.
  - Verification: `python -m avs.smoke vggsound_meta`
  - Outputs: `runs/<run_id>/vggsound_meta.json`

- [x] P0023: Add EPIC-SOUNDS anchor quality eval (Recall@K / Recall@K,Δ)
  - Summary: Evaluate whether audio-derived anchors have higher Recall@K than random anchors on EPIC-SOUNDS (given local per-video audio wavs).
  - Rationale: Root `plan.md` proposes EPIC-SOUNDS as the “long video redundancy filtering” step; this is the first measurable metric (anchor quality) before any VLM/QA integration.
  - Scope: `avs/experiments/epic_sounds_anchor_eval.py` (new), `avs/datasets/epic_sounds.py`, `avs/metrics/anchors.py`, smoke checks.
  - Acceptance: Given a small synthetic EPIC-SOUNDS-style clip list, the eval reports `ours_mean_recall > random_mean_recall` for at least one Δ.
  - Verification: `python -m avs.smoke epic_sounds_anchor_eval`
  - Outputs: `runs/<run_id>/epic_sounds_anchor_eval.json`

- [x] P0024: Add AudioMAE-like eventness probe backend
  - Summary: Add an AudioMAE-style ViT encoder probe (random weights for smoke; optional checkpoint) that returns per-segment `s(t)` and can be selected as `eventness_method=audiomae`.
  - Rationale: Root `plan.md` explicitly proposes “AudioMAE + linear probe” as a stronger audio eventness option; this backend is required before training/probing.
  - Scope: `avs/audio/audiomae_probe.py`, plumbing in `avs/experiments/ave_anchor_eval.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/pipeline/plan_generation.py`, `avs/experiments/epic_sounds_anchor_eval.py`, smoke checks, `requirements.txt`.
  - Acceptance: `eventness_method=audiomae` runs on a 10s wav (random weights for smoke; optional checkpoint) and returns `num_segments` scores; no implicit weight downloads.
  - Verification: `python -m avs.smoke audiomae_eventness`
  - Outputs: `runs/<run_id>/audiomae_eventness.json`

- [x] P0025: Add EPIC-SOUNDS audio extraction helper (untrimmed)
  - Summary: Provide a CLI to extract per-video untrimmed mono 16kHz wavs from EPIC-KITCHENS videos, saved as `<video_id>.wav`.
  - Rationale: EPIC-SOUNDS anchor evaluation requires local untrimmed audio; root `plan.md` calls out this preprocessing step explicitly.
  - Scope: `avs/preprocess/epic_sounds_audio.py` (new), smoke checks.
  - Acceptance: Given `--videos-dir` and `--video-id`, writes `<out-audio-dir>/<video_id>.wav` at 16kHz mono.
  - Verification: `python -m avs.smoke epic_sounds_audio`
  - Outputs: `runs/<run_id>/epic_sounds_audio.json`

- [x] P0026: Add lightweight temporal head option (1D conv)
  - Summary: Add an optional temporal modeling head (1D Conv across time) for per-segment classification, and allow selecting it in AVE-P0 runs.
  - Rationale: Root `plan.md` Phase 4 suggests upgrading the per-second head with lightweight temporal modeling (1D-Conv/Transformer) to improve robustness without changing the vision backbone.
  - Scope: `avs/models/temporal_conv.py` (new), `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, smoke checks.
  - Acceptance: `--head temporal_conv` trains/evals end-to-end on cached features (toy + e2e smoke), producing valid `metrics.json`.
  - Verification: `python -m avs.smoke temporal_head`
  - Outputs: `runs/<run_id>/temporal_head.json`

- [x] P0027: Add Uniform-112 low-token baseline for efficiency curve
  - Summary: Add a `uniform_low` baseline that uses `low_res` (112) uniformly across time, producing fewer tokens than Uniform-224.
  - Rationale: Root `plan.md` Phase 5 requires a cheaper uniform baseline to draw an accuracy–token/latency curve (efficiency story).
  - Scope: `avs/experiments/ave_p0.py`, smoke checks.
  - Acceptance: `uniform_low` appears in `metrics.json` and reports a smaller `token_budget` than `uniform`.
  - Verification: `python -m avs.smoke ave_p0_uniform_low`
  - Outputs: `runs/<run_id>/ave_p0_uniform_low.json`

- [x] P0028: Add vision wall-clock efficiency benchmark
  - Summary: Add a small benchmark utility that reports per-resolution wall-clock time (ms/image) for `ClipVisionEncoder` and includes token counts.
  - Rationale: Root `plan.md` Phase 6 requires efficiency evidence beyond tokens (wall-clock on the same hardware/batch).
  - Scope: `avs/experiments/vision_efficiency.py` (new), smoke checks.
  - Acceptance: Given a batch size and resolutions (112/224/448), writes a JSON report with `ms_per_image` for each resolution; runs offline with `--pretrained false`.
  - Verification: `python -m avs.smoke vision_efficiency`
  - Outputs: `runs/<run_id>/vision_efficiency.json`

- [x] P0029: Add Accuracy–Token efficiency curve plotting utility
  - Summary: Add a small plotting utility to turn AVE-P0 `metrics.json` into an Accuracy–Token scatter/curve with error bars.
  - Rationale: Root `plan.md` requires a paper-ready efficiency curve (accuracy vs tokens/FLOPs/latency); this provides the token-axis plot directly from artifacts.
  - Scope: `avs/visualize/efficiency_curve.py` (new), smoke checks.
  - Acceptance: Given an AVE-P0 `metrics.json` (or an end-to-end `ave_p0_end2end/metrics.json`), writes `efficiency_curve.png` with labeled baselines and mean±std.
  - Verification: `python -m avs.smoke efficiency_curve`
  - Outputs: `runs/<run_id>/efficiency_curve.json`, `runs/<run_id>/efficiency_curve.png`

- [x] P0030: Add long-wav (variable duration) plan.jsonl generation
  - Summary: Support generating `plan.jsonl` for arbitrary-length wavs by inferring `num_segments` from wav duration (1 segment per second).
  - Rationale: Root `plan.md` P1 targets long videos (e.g., EPIC-SOUNDS); we need the same audio→anchors→plan workflow beyond fixed 10s clips.
  - Scope: `avs/pipeline/plan_generation.py`, smoke checks.
  - Acceptance: For a 17s wav, the generated plan has 17 steps and matches the uniform-224 token budget exactly; output JSONL contains anchors, scores, and plan.
  - Verification: `python -m avs.smoke plan_jsonl_long`
  - Outputs: `runs/<run_id>/plan_jsonl_long.json`

- [x] P0031: Add novelty/change-point audio eventness backend (energy_delta)
  - Summary: Add an `energy_delta` backend that scores per-second novelty via absolute log-energy differences.
  - Rationale: Root `plan.md` suggests switching from absolute energy to “新颖度/变化点” if anchors are weak under continuous noise.
  - Scope: `avs/audio/eventness.py`, plumbing in plan generation + eval/runner scripts, smoke checks.
  - Acceptance: `eventness_method=energy_delta` produces 10 scores for a 10s wav and returns stable Top-K anchors on a synthetic “spike” waveform.
  - Verification: `python -m avs.smoke energy_delta_eventness`
  - Outputs: `runs/<run_id>/energy_delta_eventness.json`

- [x] P0032: Add approximate ViT FLOPs estimator (vision efficiency)
  - Summary: Implement an approximate FLOPs estimator for CLIP-ViT forward pass and include it in the `vision_efficiency` benchmark report.
  - Rationale: Root `plan.md` Phase 6 requests efficiency metrics beyond tokens (FLOPs + wall-clock).
  - Scope: `avs/vision/vit_flops.py` (new), `avs/experiments/vision_efficiency.py`, smoke checks.
  - Acceptance: Benchmark JSON includes `approx_flops_per_image` for 112/224/448 and the values increase monotonically with resolution.
  - Verification: `python -m avs.smoke vision_efficiency`
  - Outputs: `runs/<run_id>/vision_efficiency.json`

- [x] P0033: Add EPIC-SOUNDS per-second frame extraction helper (untrimmed)
  - Summary: Provide a CLI to extract one middle-frame per second from an untrimmed EPIC-KITCHENS video, saved as `{0..T-1}.jpg`.
  - Rationale: Root `plan.md` P1 line B needs visual evidence extraction around audio anchors on long videos; per-second frames are the simplest deterministic representation.
  - Scope: `avs/preprocess/epic_sounds_frames.py` (new), reuse ffmpeg utils, smoke checks.
  - Acceptance: Given `--videos-dir` and `--video-id`, writes `<out-frames-dir>/<video_id>/frames/{0..T-1}.jpg` at fps=1 (optionally capped by `--max-seconds`).
  - Verification: `python -m avs.smoke epic_sounds_frames`
  - Outputs: `runs/<run_id>/epic_sounds_frames.json`
  - Evidence: `python -m avs.smoke epic_sounds_frames` → ok (`runs/smoke_20260131-141119/smoke.json`)

- [x] P0034: Standardize EPIC-SOUNDS local data layout paths
  - Summary: Extend `EpicSoundsPaths` with default dirs (`raw/videos`, `audio`, `frames`, `plans`, `caches`, `selected_frames`) and helper path methods.
  - Rationale: Root `plan.md` P1 requires long-video preprocessing and artifacts; a standard layout avoids ad-hoc CLI paths.
  - Scope: `avs/datasets/layout.py`, smoke checks.
  - Acceptance: `epic_sounds_paths()` exposes the standardized paths; EPIC-SOUNDS long-pack smoke can run using these defaults (with synthetic inputs).
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: Standardized default dirs under `data/EPIC_SOUNDS/` (user-provided), plus smoke artifacts under `runs/`.
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0035: Add Hybrid long-video sampling plan generator (EPIC-SOUNDS line B)
  - Summary: Generate a fixed-length Hybrid plan: dense sampling around audio anchors + sparse background sampling, while keeping a strict equal-token budget.
  - Rationale: Root `plan.md` P1 line B needs higher-density visual evidence around anchors on long videos without scaling cost linearly with duration.
  - Scope: `avs/pipeline/long_plan_generation.py`
  - Acceptance: For a 12s wav and `max_steps=8`, produces `selected_seconds` length 8 and a `plan` length 8 whose token budget exactly matches `8 × base_res`.
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: `runs/<run_id>/epic_long_pack_out/plans/<video_id>.long_plan.json`
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0036: Apply long-video plan to frames → manifest + feature cache (Both)
  - Summary: Given extracted per-second frames and a Hybrid plan, materialize a contiguous selected-frames folder, write a JSONL manifest, and (optionally) build a multi-resolution feature cache on the selected seconds.
  - Rationale: Root `plan.md` P1 line B needs an auditable artifact that can be directly consumed by a VLM (manifest) and/or training pipelines (cache).
  - Scope: `avs/pipeline/long_plan_apply.py`, `avs/vision/feature_cache.py`
  - Acceptance: Produces `manifest.jsonl`, `selected_frames/<video_id>/*.jpg`, and `caches/<video_id>.npz` where each array has shape `[max_steps, D]`.
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: `runs/<run_id>/epic_long_pack_out/manifest.jsonl`, `runs/<run_id>/epic_long_pack_out/selected_frames/`, `runs/<run_id>/epic_long_pack_out/caches/*.npz`
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0037: Add EPIC-SOUNDS long-video end-to-end pack + smoke (synthetic-first)
  - Summary: Provide an end-to-end runner: untrimmed video → audio.wav + fps=1 frames → Hybrid plan → manifest + selected frames + (optional) feature cache.
  - Rationale: Root `plan.md` P1 requires an executable, verifiable long-video pipeline even without local EPIC data (smoke uses synthetic videos).
  - Scope: `avs/experiments/epic_sounds_long_pack.py`, `avs/smoke.py`, `avs/smoke_checks.py`
  - Acceptance: `python -m avs.smoke epic_sounds_long_pack` runs on a synthetic video, writing artifacts and passing validation.
  - Verification: `python -m avs.smoke epic_sounds_long_pack`
  - Outputs: `runs/<run_id>/epic_long_pack_out/` (manifest, plans, selected_frames, caches)
  - Evidence: `python -m avs.smoke epic_sounds_long_pack` → ok (`runs/smoke_20260131-142810/smoke.json`)

- [x] P0038: Add AVE oracle ceiling sweep (is +2% achievable?)
  - Summary: Add a reproducible oracle-only sweep to estimate the achievable upper bound of “anchored sampling” under equal token budget on official AVE val/test.
  - Rationale: Before chasing +2% on `test402`, confirm the backbone/head has enough headroom (Oracle-TopK vs Uniform). If oracle gains are <2%, anchor tuning alone cannot reach the target.
  - Scope: `avs/experiments/ave_p0_oracle_sweep.py` (new), `scripts/e0010_ave_oracle_ceiling_official.sh` (new)
  - Acceptance: Produces `oracle_ceiling.json` summarizing ≥6 configs with `uniform` vs `oracle_top2` mean/std and paired p-values, plus pointers to raw `metrics.json`.
  - Verification: `bash scripts/e0010_ave_oracle_ceiling_official.sh` (requires official AVE installed)
  - Outputs: `runs/E0010_*/oracle_ceiling.json`
  - Evidence (smoke): `runs/E0010_oracle_ceiling_official_val_20260203-141212/oracle_ceiling.json` (LIMIT_TRAIN=64; LIMIT_EVAL=32; SEEDS=0,1; EPOCHS=1)

- [x] P0039: Add windowed anchors + score smoothing (robust anchor selection)
  - Summary: Add `anchor_select=window_topk` that selects anchors using window-aggregated scores + NMS, and optional score smoothing before selection.
  - Rationale: Plain Top-K often selects adjacent seconds on long-ish events; window aggregation + NMS yields more diverse anchors and better tolerance to A/V misalignment.
  - Scope: `avs/audio/eventness.py`, plumbing in `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_anchor_eval.py`, smoke checks.
  - Acceptance: New selector is deterministic and avoids adjacent anchors under synthetic multi-peak sequences; CLI supports `--anchor-select window_topk --anchor-window 3/5`.
  - Verification: `python -m avs.smoke anchor_window_select`
  - Outputs: `runs/<run_id>/anchor_window_select.json`
  - Evidence: `python -m avs.smoke anchor_window_select` → ok (`runs/smoke_20260202-035940/smoke.json`)

- [x] P0040: Add anchor confidence gating (replace std-only fallback)
  - Summary: Add configurable confidence metrics (std / top1-median / top1-top2 gap / gini) to decide when to fall back to uniform, and record `fallback_reason` per clip in debug.
  - Rationale: Many clips have flat/noisy scores where anchors are unreliable; a stronger gating signal reduces harmful anchored plans and improves stability on `test402`.
  - Scope: `avs/audio/eventness.py`, `avs/experiments/ave_p0.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_diagnose.py`, smoke checks.
  - Acceptance: `metrics.json` includes `debug_eval.anchored_top2.<clip_id>.fallback_used/fallback_reason/conf_value` for eval clips.
  - Verification: `python -m avs.smoke anchor_confidence_gate`
  - Outputs: `runs/<run_id>/anchor_confidence_gate.json`
  - Evidence: `python -m avs.smoke anchor_confidence_gate` → ok (`runs/smoke_20260202-040007/smoke.json`)

- [x] P0041: Add AVE config sweep + best-to-test reproduction (aim +2% on test402)
  - Summary: Add a fixed-space sweep runner (val402 selection → test402 reproduction) with a machine-readable summary of configs and outcomes.
  - Rationale: Avoid ad-hoc hand tuning; enforce a reproducible process to search configs and re-run the best config on `test402` with `SEEDS=0..9`.
  - Scope: `avs/experiments/ave_p0_sweep.py` (new), `scripts/e0011_ave_p0_sweep_official.sh` (new), `scripts/e0012_ave_p0_best_to_test_official.sh` (new)
  - Acceptance: `sweep_summary.json` lists configs with `anchored_top2 - uniform`, p-values, and paths to each run’s `metrics.json`; best config can be reproduced on test split.
  - Verification: `bash scripts/e0011_ave_p0_sweep_official.sh && bash scripts/e0012_ave_p0_best_to_test_official.sh` (requires official AVE installed)
  - Outputs: `runs/E0011_*/sweep_summary.json`, `runs/E0012_*/metrics.json`
  - Evidence (smoke): `runs/E0011_ave_p0_sweep_official_val_20260203-141418/sweep_summary.json` and `runs/E0012_ave_p0_best_to_test_official_20260203-141430/metrics.json` (LIMIT_TRAIN=64; LIMIT_EVAL=32; SEEDS=0,1; EPOCHS=1)

- [x] P0042: Confirm fusion adds on top of sampling (audio_concat_* baselines)
  - Summary: Add a dedicated script to confirm `audio_concat_anchored_top2` improves over `audio_concat_uniform` under the best sampling config (and record results).
  - Rationale: Target requires both sampling-only and fusion+sampling to be strong; this isolates whether fusion is benefiting from better sampling or simply dominates.
  - Scope: `scripts/e0013_ave_fusion_confirm_official.sh` (new), minor plumbing in `avs/experiments/ave_p0.py` if needed
  - Acceptance: Script runs end-to-end and writes `metrics.json` containing both `audio_concat_uniform` and `audio_concat_anchored_top2` plus paired tests (the target threshold is tracked by `C0004`).
  - Verification: `bash scripts/e0013_ave_fusion_confirm_official.sh` (requires official AVE installed)
  - Outputs: `runs/E0013_*/metrics.json`
  - Evidence (smoke): `runs/E0013_ave_fusion_confirm_official_test_20260203-141624/metrics.json` (LIMIT_TRAIN=64; LIMIT_EVAL=32; SEEDS=0,1; EPOCHS=1)

- [x] P0043: Add EPIC-SOUNDS downstream proxy: video-level multi-label sound event recognition
  - Summary: Add a reproducible downstream task on EPIC-SOUNDS: video-level multi-label classification using selected seconds’ visual features, comparing `uniform` vs `audio_anchored` selection under a fixed token budget.
  - Rationale: Provides a “long video” story with a measurable downstream metric (mAP/macro-F1), beyond anchor Recall@K.
  - Scope: `avs/experiments/epic_sounds_video_cls.py` (new), `avs/models/video_multilabel_head.py` (new), smoke checks, `scripts/e0100_epic_video_cls_local.sh` (new)
  - Acceptance: Synthetic smoke runs end-to-end and writes `metrics.json` with mAP and budget fields; local run works once EPIC mp4s exist under `data/EPIC_SOUNDS/raw/videos/`.
  - Verification: `python -m avs.smoke epic_sounds_video_cls_synth`
  - Outputs: `runs/<run_id>/epic_sounds_video_cls_synth.json`, `runs/<run_id>/epic_sounds_video_cls_synth_metrics.json`
  - Evidence: `python -m avs.smoke epic_sounds_video_cls_synth` → ok (`runs/smoke_20260202-035910/smoke.json`)

- [x] P0044: Add time-window primitives + Coverage@τ metric (Evidence Alignment)
  - Summary: Implement 1D time-window utilities (IoU, merge, dilation) and `Cov@τ` (Coverage@τ) to quantify whether predicted windows cover GT evidence intervals.
  - Rationale: Needed for the Listen-then-Look “Evidence Alignment” story and for diagnosing why anchored gains are small (coverage→accuracy correlation).
  - Scope: `avs/metrics/time_windows.py` (new), optional glue in `avs/metrics/__init__.py`, smoke checks.
  - Acceptance: `iou_1d` and `coverage_at_tau` are deterministic; handles empty evidence/windows; supports float seconds and integer segments.
  - Verification: `python -m avs.smoke evidence_windows`
  - Outputs: `runs/<run_id>/evidence_windows.json`
  - Evidence: `python -m avs.smoke evidence_windows` → ok (`runs/smoke_20260203-134900/smoke.json`)

- [x] P0045: Implement Listen-then-Look budget model + allocator (budgeted config assignment)
  - Summary: Add a strict visual token cost model `Tok(c; L)` and a deterministic budget allocator that assigns per-window configs from a discrete set under `B_vis` and `α` split.
  - Rationale: Turns the method into a decision-complete, reproducible mechanism (no ad-hoc “just sample more near anchors”).
  - Scope: `avs/budget/vis_budget.py` (new), `avs/sampling/allocator.py` (new), smoke checks.
  - Acceptance: Given windows, weights, configs and budget, returns an allocation that never exceeds budget; exposes a stable JSONable report for audit.
  - Verification: `python -m avs.smoke ltl_budget_allocator`
  - Outputs: `runs/<run_id>/ltl_budget_allocator.json`
  - Evidence: `python -m avs.smoke ltl_budget_allocator` → ok (`runs/smoke_20260203-135142/smoke.json`)

- [x] P0046: Extend audio eventness to stride-based scoring + anchor windows (δ, Δ, local maxima)
  - Summary: Support sub-second `stride_s`/`win_s` eventness scoring and convert anchors into explicit time windows `W_i=[t_i-Δ_i, t_i+Δ_i]` (with NMS and fixed expansion).
  - Rationale: Matches the paper setting (Listen-then-Look Stage-1) and enables long-video protocols beyond the fixed 10×1s AVE grid.
  - Scope: `avs/audio/eventness.py`, `avs/audio/augment.py` (new), smoke checks.
  - Acceptance: For a synthetic wav with injected pulses, anchors are found near pulses under multiple `stride_s`; window conversion is deterministic and stable under small shifts.
  - Verification: `python -m avs.smoke ltl_anchor_windows`
  - Outputs: `runs/<run_id>/ltl_anchor_windows.json`
  - Evidence: `python -m avs.smoke ltl_anchor_windows` → ok (`runs/smoke_20260203-135434/smoke.json`)

- [x] P0047: Add cheap-visual anchors baseline (frame-diff eventness)
  - Summary: Implement a low-cost visual eventness heuristic (frame-diff/motion energy on low-res frames) and expose it as an anchor source alongside audio anchors.
  - Rationale: Required baseline in MDE to answer “any window works?” and to provide a fallback when audio is missing/noisy.
  - Scope: `avs/vision/cheap_eventness.py` (new), integrate into `avs/experiments/ave_anchor_eval.py` and `avs/experiments/epic_sounds_anchor_eval.py`, smoke checks.
  - Acceptance: On synthetic sequences with a single visual change, the cheap-visual eventness peaks at the change; anchor eval can run with `method=cheap_visual`.
  - Verification: `python -m avs.smoke cheap_visual_eventness`
  - Outputs: `runs/<run_id>/cheap_visual_eventness.json`
  - Evidence: `python -m avs.smoke cheap_visual_eventness` → ok (`runs/smoke_20260203-135817/smoke.json`)

- [x] P0048: Add MDE harness + Pareto report (Oracle→Predicted; multiple budgets)
  - Summary: Provide a runnable harness that produces Acc–Tok Pareto curves for Oracle vs Predicted vs baselines on a pre-registered budget grid, and writes a single report JSON + plots.
  - Rationale: Establishes the mechanism under the Oracle ceiling, then measures the Predicted gap, with audit-friendly artifacts for reviewers.
  - Scope: `avs/experiments/mde_ltl.py` (new), `avs/visualize/pareto_report.py` (new), smoke checks, `scripts/e0200_*` (new).
  - Acceptance: Toy smoke produces `pareto_report.json` and a plot; full-mode can consume AVE caches and run on val/test splits.
  - Verification: `python -m avs.smoke mde_pareto_toy`
  - Outputs: `runs/<run_id>/pareto_report.json`, `runs/<run_id>/pareto.png`
  - Evidence: `python -m avs.smoke mde_pareto_toy` → ok (`runs/smoke_20260203-140023/smoke.json`)

- [x] P0049: Add degradation protocol runner (offset/noise/silence × α) + report
  - Summary: Implement the Evidence/Degradation protocol: evaluate anchor quality and downstream accuracy under A/V shift, additive noise (SNR), and audio silence, across `α` fallback settings.
  - Rationale: Pre-registered robustness evidence prevents “strong binding only / brittle heuristic” reviewer objections and provides a computable lower bound via `α`.
  - Scope: `avs/experiments/degradation_suite.py` (new), `avs/audio/augment.py`, smoke checks.
  - Acceptance: Toy smoke produces a JSON heatmap keyed by `{shift_s, snr_db, silence_ratio, alpha}`; full-mode runs on AVE val/test.
  - Verification: `python -m avs.smoke ltl_degradation_suite_toy`
  - Outputs: `runs/<run_id>/degradation_suite.json`
  - Evidence: `python -m avs.smoke ltl_degradation_suite_toy` → ok (`runs/smoke_20260203-140151/smoke.json`)

- [x] P0050: Add dataset checklist + download/verify helpers (AVE, EPIC-SOUNDS, EgoSchema/IntentQA)
  - Summary: Standardize required datasets, what can be auto-downloaded, and add `verify_*` scripts that fail fast with actionable instructions.
  - Rationale: Users requested “全量真实数据 + 多卡榨干” runs; we need reproducible dataset install/verify gates before launching long jobs.
  - Scope: `docs/datasets.md` (new), `scripts/datasets/*.sh` (new), optional minimal dataset stubs under `avs/datasets/`.
  - Acceptance: `bash scripts/datasets/verify_all.sh` reports which datasets are installed, and prints exact next steps for missing ones.
  - Verification: `bash scripts/datasets/verify_all.sh`
  - Outputs: `runs/<run_id>/datasets_verify.json`
  - Evidence: `bash scripts/datasets/verify_all.sh` → ok (`runs/datasets_verify_20260203-140543/datasets_verify.json`)

- [x] P0051: Strengthen Stage-1 anchors (energy_stride_max + AV-fused eventness) to close Oracle→Pred gap
  - Summary: Add deployable Stage-1 improvements: (1) stride-based log-energy aggregated to per-second scores (`energy_stride_max`), and (2) high-recall audio+cheap-visual fusion (`av_fused`) that survives silence/noise.
  - Rationale: Current best `anchored_top2` gain on AVE test402 is ~+1% while Oracle upper bound is much higher; evidence-alignment suggests Stage-1 coverage is the bottleneck. Improving anchors is the shortest path to “拉大”.
  - Scope:
    - `avs/audio/eventness.py` (new per-second stride aggregation)
    - `avs/experiments/ave_p0.py` + `avs/experiments/ave_p0_sweep.py` + `avs/experiments/ave_anchor_eval.py` (new methods)
    - `avs/experiments/mde_ltl.py` (E0201 support) + `avs/experiments/degradation_suite.py` (E0203 support)
    - `avs/smoke.py`, `avs/smoke_checks.py` (new smokes)
  - Acceptance:
    - `--eventness-method {energy_stride_max,av_fused}` is supported end-to-end (P0, sweep, anchor eval, MDE, degradation).
    - New smoke checks pass and demonstrate the intended behavior under (audio-only) and (audio-silent but visual-change) cases.
  - Verification:
    - `python -m avs.smoke ltl_eventness_stride_max`
    - `python -m avs.smoke ltl_eventness_av_fused`
    - `python -m avs.smoke all`
  - Outputs: N/A (enables E0201/E0203 + later C0003 reruns)
  - Evidence: `python -m avs.smoke all` → ok (`runs/smoke_20260203-205119/smoke.json`)

- [x] P0052: Fix AV-fused score scale mismatch with anchor confidence gate (avoid all-fallback collapse)
  - Summary: Ensure `eventness_method=av_fused` remains compatible with the default anchor confidence gate (`conf_metric=std`, `std_threshold=1.0`) by scaling fused scores to an energy-like magnitude.
  - Rationale: E0201 showed `av_fused` collapsed to `uniform` because scores were normalized to `[0,1]` while the gate threshold was tuned for log-energy scales, triggering fallback on ~100% clips and invalidating the comparison.
  - Scope:
    - `avs/utils/scores.py` (AV_FUSED_SCORE_SCALE + helper)
    - `avs/experiments/ave_p0.py`, `avs/experiments/ave_p0_sweep.py`, `avs/experiments/ave_anchor_eval.py`, `avs/experiments/mde_ltl.py` (apply the scale in `av_fused`)
    - `avs/smoke_checks.py` (assert gate no longer triggers on the fused synthetic case)
  - Acceptance:
    - `python -m avs.smoke ltl_eventness_av_fused` reports `fallback_used=false` with `conf_threshold=1.0`.
    - Full E0201 `EVENTNESS=av_fused` no longer has `fallback_used≈1.0` in `metrics_predicted.json` (anchor proposals actually used).
  - Verification:
    - `python -m avs.smoke ltl_eventness_av_fused`
    - `TRAIN_DEVICE=cuda:2 EVENTNESS=av_fused bash scripts/e0201_oracle_vs_predicted_official.sh`
  - Outputs: N/A (unblocks fair evaluation of av_fused anchors in E0201/C0007)
  - Evidence: `python -m avs.smoke ltl_eventness_av_fused` → ok (`runs/smoke_20260203-221305/smoke.json`; `conf_value≈1.05 >= 1.0`, `fallback_used=false`)
  - Evidence: `runs/E0201_oracle_vs_predicted_av_fused_scale3p5_full_20260203-221906/oracle_vs_predicted.json` (fallback_used_frac≈0.739; no longer collapses to `uniform`)

- [x] P0053: Add learned audio eventness backends to strengthen Stage-1 anchors (shrink Oracle→Pred gap)
  - Summary: Add supervised audio-only eventness options (trained on AVE train split) to improve anchor reliability and close the Oracle→Predicted gap.
  - Rationale: Oracle anchors show a large upper bound on test402, but current deployable anchors remain ~3% behind Oracle (C0007) and only yield ~+1% gain (C0003). A learned-but-cheap audio eventness model is the shortest path to increase precision without expensive visual passes.
  - Scope:
    - `avs/experiments/mde_ltl.py` (E0201: allow learned methods)
    - `avs/experiments/degradation_suite.py` (E0203: learned-method robustness under shift/noise/silence)
    - `avs/audio/features.py` (feature extraction from in-memory audio for augmentations)
    - `docs/experiment.md` + `docs/mohu.md` (track the new experiments and evidence)
  - Acceptance:
    - `EVENTNESS ∈ {audio_basic_lr,audio_basic_mlp,audio_fbank_mlp,audio_basic_mlp_cls,audio_basic_mlp_cls_target}` runs in E0201 (oracle_vs_predicted) on official AVE.
    - E0203 supports `EVENTNESS=audio_fbank_mlp` (and at least one other learned method) and writes `degradation_suite.json`.
  - Verification:
    - `python -m avs.experiments.mde_ltl oracle_vs_predicted --mode toy`
    - `EVENTNESS=audio_fbank_mlp bash scripts/e0201_oracle_vs_predicted_official.sh`
    - `EVENTNESS=audio_basic_lr bash scripts/e0203_degradation_suite_official.sh`
  - Outputs: `runs/E0201_*/oracle_vs_predicted.json`, `runs/E0203_*/degradation_suite.json`
  - Evidence: `runs/E0201_oracle_vs_predicted_audio_fbank_mlp_20260204-000652/oracle_vs_predicted.json` (wires `EVENTNESS=audio_fbank_mlp`; anchored=0.7138 vs uniform=0.7086)
  - Evidence: `runs/E0203_degradation_audio_basic_lr_20260204-012618/degradation_suite.json` (wires `EVENTNESS=audio_basic_lr` in E0203)

- [x] P0054: Add AST-logit linear calibration as a deployable Stage-1 anchor backend (ast_lr)
  - Summary: Implement `eventness_method=ast_lr`: train a tiny linear probe on pretrained AST per-second logits (AudioSet classes) to predict event vs background on AVE train split, then use the resulting per-second logits as Stage-1 eventness scores.
  - Rationale: Raw `ast` anchors regress on test402, but Oracle upper bound is high and AST logits contain richer semantics than log-energy. A supervised calibration is a cheap, deployable way to improve anchor reliability and close the Oracle→Pred gap.
  - Scope:
    - `avs/experiments/ave_p0.py` (compute `ast_lr` scores inside `run_p0_from_caches`; reuse train logits; respect `--audio-device`)
    - `avs/audio/ast_probe.py` (support `eventness_from_array` / `logits_from_array` for degradation augmentations)
    - `avs/experiments/mde_ltl.py` + `scripts/e0201_oracle_vs_predicted_official.sh` (allow `ast/ast_lr` and pass `--ast-pretrained`)
    - `avs/experiments/degradation_suite.py` + `scripts/e0203_degradation_suite_official.sh` (allow `ast/ast_lr` and run augmented robustness on `ast_lr`)
  - Acceptance:
    - `EVENTNESS=ast_lr` runs end-to-end in E0201 and writes `oracle_vs_predicted.json` without requiring precomputed `scores_by_clip_override`.
    - E0203 supports `EVENTNESS=ast_lr` (shift/noise/silence) and writes `degradation_suite.json`.
  - Verification:
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EVENTNESS=ast_lr AST_PRETRAINED=1 bash scripts/e0201_oracle_vs_predicted_official.sh`
    - `LIMIT_TRAIN=256 LIMIT_EVAL=64 EVENTNESS=ast_lr AST_PRETRAINED=1 bash scripts/e0203_degradation_suite_official.sh`
    - `python -m avs.smoke all`
  - Outputs: `runs/E0201_*/oracle_vs_predicted.json`, `runs/E0203_*/degradation_suite.json`
  - Evidence: `runs/E0201_oracle_vs_predicted_ast_lr_sanity_20260204-015758/oracle_vs_predicted.json` (sanity wiring; SEEDS=0,1; LIMIT_TRAIN=64; LIMIT_EVAL=32)
  - Evidence: `runs/E0203_degradation_ast_lr_sanity_20260204-015849/degradation_suite.json` (sanity wiring; LIMIT_TRAIN=64; LIMIT_EVAL=32)

- [x] P0055: Add a val402-tuned confidence-gate protocol for Stage-1 methods (avoid test402 threshold tuning)
  - Summary: Add a small, pre-registered sweep that selects `anchor_conf_metric/threshold` on val402 for a given Stage-1 method, then reruns test402 full with the selected gate.
  - Rationale: Many Stage-1 methods differ in score scale and collapse under the default `std_thr`; a scale-invariant gate (e.g., gini) plus val-tuned thresholds prevents “tune-on-test” accusations and reduces all-fallback / all-use failure modes.
  - Scope:
    - `avs/experiments/mde_ltl.py` (new `gate_sweep` command on val402 that writes `best_gate.json`)
    - `docs/experiment.md` (new experiment entry: E0204)
  - Acceptance:
    - `python -m avs.experiments.mde_ltl gate_sweep --mode ave_official --eventness-method ast_lr --split-eval val --limit-eval 402` produces `best_gate.json` and a short `gate_sweep.json`.
    - Using `best_gate.json` in E0201 improves/maintains anchored gains on test402 vs the default gate.
  - Verification:
    - `python -m avs.experiments.mde_ltl gate_sweep --mode ave_official --eventness-method ast_lr --split-eval val --limit-eval 402 --ast-pretrained --gate-metric gini --gate-thresholds 0,0.1,0.2,0.3,0.4`
  - Evidence: `runs/E0204_gate_sweep_ast_lr_val402_20260204-020623/gate_sweep.json` + `runs/E0204_gate_sweep_ast_lr_val402_20260204-020623/best_gate.json`

- [x] P0056: Add clipdiff-based per-clip autoshift for energy anchors (energy_autoshift_clipdiff*)
  - Summary: Implement an ablation that estimates A/V shift per clip by correlating audio log-energy scores with a cheap visual “semantic motion” proxy (cached CLIP embedding diffs), then uses the shifted score sequence to generate anchors.
  - Rationale: Oracle upper bound on test402 is high, and the energy baseline benefits from a fixed `anchor_shift=1`; this test checks whether per-clip alignment can shrink Oracle→Pred gap and “拉大” anchored gains without changing the downstream model.
  - Scope:
    - `avs/utils/scores.py` (shift + correlation helper)
    - `avs/experiments/ave_p0.py` (eventness backends)
    - `avs/experiments/mde_ltl.py`, `avs/experiments/degradation_suite.py` (E0201/E0203 support)
    - `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_rerun.py` (CLI choices)
    - smoke checks
  - Acceptance:
    - `EVENTNESS=energy_autoshift_clipdiff` and `EVENTNESS=energy_autoshift_clipdiff_pos` run in E0201 and write `oracle_vs_predicted.json`.
    - Debug metrics record `debug_eval.anchored_top2.<clip_id>.eventness_autoshift` for analysis.
  - Verification:
    - `python -m avs.smoke all`
    - `EVENTNESS=energy_autoshift_clipdiff bash scripts/e0201_oracle_vs_predicted_official.sh`
    - `EVENTNESS=energy_autoshift_clipdiff_pos bash scripts/e0201_oracle_vs_predicted_official.sh`
  - Evidence (full; test402; SEEDS=0..9; does not beat energy baseline):
    - `runs/E0201_full_energy_autoshift_clipdiff_test402_20260204-032327/oracle_vs_predicted.json` (Δ=+0.00687, p=0.00574; oracle_minus_predicted=0.03455).
    - `runs/E0201_full_energy_autoshift_clipdiff_pos_test402_20260204-040122/oracle_vs_predicted.json` (Δ=+0.00254, p=0.495; oracle_minus_predicted=0.03888).

- [x] P0057: Add AST-logit MLP classifier eventness backends (ast_mlp_cls, ast_mlp_cls_target) + gate sweep
  - Summary: Implement `eventness_method={ast_mlp_cls,ast_mlp_cls_target}` (MLP on pretrained AST logits) and support val402 confidence-gate sweeps (E0204) without re-running AST inference per threshold.
  - Rationale: Raw AST anchors regress on test402; a supervised calibration on top of pretrained logits is a cheap deployable alternative to improve anchor reliability.
  - Scope: `avs/experiments/ave_p0.py`, `avs/experiments/mde_ltl.py`, `avs/experiments/degradation_suite.py`, `scripts/e0201_oracle_vs_predicted_official.sh`, `scripts/e0203_degradation_suite_official.sh`
  - Acceptance: `--eventness-method ast_mlp_cls` runs in E0201/E0203; E0204 `gate_sweep` can run `ast_mlp_cls` using one precompute pass.
  - Verification:
    - `python -m avs.smoke all`
    - `python -m avs.experiments.mde_ltl gate_sweep --mode ave_official --eventness-method ast_mlp_cls --split-eval val --limit-eval 402 --ast-pretrained --gate-metric gini --gate-thresholds 0,0.2,0.3,0.4`
  - Evidence (gate sweep; val402): `runs/E0204_gate_sweep_ast_mlp_cls_val402_20260204-033555/gate_sweep.json` + `runs/E0204_gate_sweep_ast_mlp_cls_val402_20260204-033555/best_gate.json` (best gate=`gini@0.4`; Δ≈+0.00183, p≈0.742).

- [x] P0058: Gate-tune energy anchors on val402 and rerun test402 full (gini@0.35)
  - Summary: Use the pre-registered E0204 protocol to pick an energy confidence gate on val402, then rerun E0201 on test402 with the selected gate to reduce harmful anchor usage without tuning on test.
  - Rationale: The energy baseline uses a legacy `std_thr=1.0` gate and falls back on ~70% clips; a scale-invariant gate (gini) may safely reduce fallback and increase anchored gains.
  - Scope: no code changes (reuse `avs/experiments/mde_ltl.py` + existing gate plumbing); add new E0204/E0201 evidence artifacts.
  - Verification:
    - `python -m avs.experiments.mde_ltl gate_sweep --mode ave_official --eventness-method energy --split-eval val --limit-eval 402 --gate-metric gini --gate-thresholds 0,0.2,0.3,0.35,0.4,0.45`
    - `EVENTNESS=energy ANCHOR_CONF_METRIC=gini ANCHOR_CONF_THRESHOLD=0.35 bash scripts/e0201_oracle_vs_predicted_official.sh`
  - Evidence:
    - Val402 gate sweep: `runs/E0204_gate_sweep_energy_val402_20260204-041625/gate_sweep.json` + `runs/E0204_gate_sweep_energy_val402_20260204-041625/best_gate.json` (best gate=`gini@0.35`; Δ≈+0.01189, p≈0.030).
    - Test402 full rerun: `runs/E0201_full_energy_gini0p35_test402_20260204-041950/oracle_vs_predicted.json` (Δ=+0.01075, p=0.024; fallback_used≈0.580).

- [x] P0059: Add AST-embedding linear probe eventness backend (ast_emb_lr) (negative)
  - Summary: Add `eventness_method=ast_emb_lr`: train a tiny linear probe on pretrained AST per-second **embeddings** (CLS token) to predict event vs background on AVE train split, then use its per-second logits as Stage-1 eventness.
  - Rationale: AST-logit probes (`ast_lr`) did not transfer; embeddings may be a richer representation with a similar deployment cost.
  - Scope: `avs/audio/ast_probe.py`, `avs/experiments/ave_p0.py`, `avs/experiments/mde_ltl.py`, `avs/experiments/degradation_suite.py`, scripts/CLIs.
  - Verification: `python -m py_compile avs/audio/ast_probe.py` and `python -m avs.smoke all`
  - Evidence (sanity; small subset; regresses): `runs/E0201_oracle_vs_predicted_ast_emb_lr_sanity_20260204-044048/oracle_vs_predicted.json` (LIMIT_TRAIN=256, LIMIT_EVAL=64; anchored=0.528 < uniform=0.538; 3 seeds).

- [x] P0060: Add temporal audio eventness backends (audio_*_tcn) for Stage-1 anchor reliability
  - Summary: Add `eventness_method=audio_basic_tcn` and `eventness_method=audio_fbank_tcn`: train a small temporal conv net on per-second audio features to predict event-vs-background per second, then use its per-second logits as Stage-1 scores.
  - Rationale: Stage-1 coverage/precision is the bottleneck for “拉大” on test402; per-second LR/MLP ignores context and can be noisy. A tiny TCN-like model uses local temporal context while remaining deployable.
  - Scope: `avs/experiments/ave_p0.py`, `avs/experiments/mde_ltl.py`, `avs/experiments/degradation_suite.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_rerun.py`
  - Acceptance: `audio_basic_tcn`/`audio_fbank_tcn` are selectable end-to-end (E0201/E0203/E0204) and gate_sweep precomputes scores once (no re-train per threshold).
  - Verification: `python -m py_compile avs/experiments/ave_p0.py avs/experiments/mde_ltl.py avs/experiments/degradation_suite.py`
  - Outputs: New Stage-1 methods for E0204 sweeps and E0201 full reruns.

- [x] P0061: Enable val-selection sweeps for audio-TCN (cached scores + scripts)
  - Summary: Make audio-TCN Stage-1 usable in fixed-space config sweeps by caching per-second scores once and reusing them across candidates; add runnable scripts for val402 sweep + test402 reproduction.
  - Rationale: Gate sweeps (E0204) only tune confidence thresholds under a fixed plan; to “拉大” anchored gains we need val-selection over Stage-2 plan knobs (shift/select/max_high/base_alloc) without re-training Stage-1 per candidate.
  - Scope: `avs/experiments/ave_p0_sweep.py`, `scripts/e0205_ave_p0_sweep_official_val_audio_tcn.sh`, `scripts/e0206_ave_p0_best_to_test_official_audio_tcn.sh`, `docs/experiment.md`
  - Acceptance: Running E0205 produces `eventness_scores.json` and does not retrain Stage-1 per candidate; E0206 reuses the same score cache and only fills missing ids.
  - Verification: `python -m py_compile avs/experiments/ave_p0_sweep.py`
  - Outputs: `runs/E0205_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0206_*/metrics.json`

- [x] P0062: Add semantic clipdiff-augmented supervised Stage-1 eventness (av_clipdiff_lr / av_clipdiff_mlp)
  - Summary: Add `eventness_method={av_clipdiff_lr,av_clipdiff_mlp}`: train a tiny per-second eventness model on AVE train split using **audio basic features + semantic visual motion (CLIP feature diff at low_res)**, then use its logits as Stage-1 scores.
  - Rationale: Energy and learned audio-only anchors plateau around ~+1% on test402; to close the Oracle→Pred gap we need higher precision anchors. CLIP feature diff provides a cheap semantic motion proxy that should reduce false positives while staying far cheaper than high-res visual passes.
  - Scope: `avs/experiments/ave_p0.py`, `avs/experiments/mde_ltl.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_rerun.py`
  - Acceptance: `EVENTNESS=av_clipdiff_lr` and `EVENTNESS=av_clipdiff_mlp` run end-to-end for E0201/E0204 style harnesses and produce `oracle_vs_predicted.json`.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/mde_ltl.py avs/pipeline/ave_p0_end2end.py avs/experiments/ave_p0_rerun.py`
    - `EVENTNESS=av_clipdiff_lr LIMIT_TRAIN=256 LIMIT_EVAL=64 SEEDS=0,1 bash scripts/e0201_oracle_vs_predicted_official.sh`
  - Outputs: New Stage-1 eventness methods usable in sweeps + MDE harnesses.

- [x] P0063: Val→test selection for clipdiff-augmented anchors (attempt to hit C0003 +2%)
  - Summary: Run fixed-space sweeps on val402 to select the best Stage-2 plan config for `{av_clipdiff_lr,av_clipdiff_mlp,av_fused_clipdiff_prod,moe_energy_clipdiff}`, then reproduce the best on test402 (SEEDS=0..9) and compare to the best energy baseline.
  - Rationale: If anchor reliability is the bottleneck, clipdiff-augmented anchors should shrink Oracle→Pred gap and increase anchored gains beyond the ~+1% plateau.
  - Scope: `docs/experiment.md`, `scripts/` (new E0207/E0208 runners), plus `runs/E0207_*` and `runs/E0208_*` artifacts.
  - Acceptance: E0207 produces `sweep_summary.json` + `best_config.json` (val402) and E0208 produces `metrics.json` (test402); results are recorded back into `docs/experiment.md`.
  - Verification:
    - `EVENTNESS=av_clipdiff_lr SEEDS=0,1,2 bash scripts/e0207_ave_p0_sweep_official_val_ltl_stage1.sh`
    - `BEST_CONFIG_JSON=runs/E0207_*/best_config.json EVENTNESS=av_clipdiff_lr SEEDS=0,1,2,3,4,5,6,7,8,9 bash scripts/e0208_ave_p0_best_to_test_official_ltl_stage1.sh`
  - Outputs: `runs/E0207_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0208_*/metrics.json`

- [x] P0064: Add clipdiff-augmented temporal eventness (av_clipdiff_tcn)
  - Summary: Add `eventness_method=av_clipdiff_tcn`: train a small TCN on **audio basic features + semantic visual motion (CLIP feature diff at low_res)** to predict event-vs-background per second, then use its logits as Stage-1 scores.
  - Rationale: Per-second LR/MLP can be noisy; a tiny temporal conv net may improve anchor stability while remaining deployable.
  - Scope: `avs/experiments/ave_p0.py`, `avs/experiments/ave_p0_sweep.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_rerun.py`, `avs/experiments/mde_ltl.py`
  - Acceptance: `EVENTNESS=av_clipdiff_tcn` is selectable end-to-end and supports score caching in E0207/E0208 (no retrain per candidate).
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/pipeline/ave_p0_end2end.py avs/experiments/ave_p0_rerun.py avs/experiments/mde_ltl.py`
    - `EVENTNESS=av_clipdiff_tcn LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0207_ave_p0_sweep_official_val_ltl_stage1.sh`
  - Outputs: New Stage-1 method for further “拉大” attempts.

- [x] P0065: Explore richer cheap-visual features for Stage-1 anchors (full CLIP + clipdiff vector) (negative)
  - Summary: Add `eventness_method={av_clip_mlp_cls,av_clip_mlp_cls_target,av_clipdiff_vec_mlp}` and run E0207/E0208 to check whether richer cheap-V features can improve anchor reliability beyond scalar clipdiff.
    - `av_clip_mlp_cls`: audio basic + low-res CLIP embedding per second → MLP classifier; scores use margin (best non-bg logit − bg).
    - `av_clip_mlp_cls_target`: same but uses a clip-inferred target class margin to reduce false positives.
    - `av_clipdiff_vec_mlp`: audio basic + low-res CLIP diff **vector** per second → binary MLP (with dropout) to capture directional semantic motion.
  - Rationale: If clipdiff scalar is too lossy, richer CLIP-derived features might reduce false anchors and help “拉大” (C0003).
  - Scope: `avs/experiments/ave_p0.py`, `avs/experiments/ave_p0_sweep.py`, `avs/pipeline/ave_p0_end2end.py`, `avs/experiments/ave_p0_rerun.py`, `avs/experiments/mde_ltl.py`
  - Acceptance: All new methods are selectable end-to-end and support score caching in E0207/E0208 (no retrain per candidate).
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/pipeline/ave_p0_end2end.py avs/experiments/ave_p0_rerun.py avs/experiments/mde_ltl.py`
    - `EVENTNESS=av_clip_mlp_cls LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0207_ave_p0_sweep_official_val_ltl_stage1.sh`
    - `EVENTNESS=av_clipdiff_vec_mlp LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0207_ave_p0_sweep_official_val_ltl_stage1.sh`
  - Evidence (full; does not beat the current best clipdiff-masked config on test402):
    - Val402 sweep: `runs/E0207_ave_p0_sweep_official_val_av_clip_mlp_cls_20260204-095132/sweep_summary.json` (best Δ≈+0.00308; best=`ltlstd_shift1_std0p5`).
    - Test402 reproduction: `runs/E0208_ave_p0_best_to_test_official_av_clip_mlp_cls_20260204-095509/metrics.json` (Δ=+0.00281, p=0.328).
    - Val402 sweep: `runs/E0207_ave_p0_sweep_official_val_av_clip_mlp_cls_target_20260204-095814/sweep_summary.json` (best Δ≈+0.00648; best=`ltlstd_shift1_std0p55`; p≈0.100).
    - Test402 reproduction: `runs/E0208_ave_p0_best_to_test_official_av_clip_mlp_cls_target_20260204-100202/metrics.json` (Δ=-0.00597, p=0.131).
    - Val402 sweep: `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_vec_mlp_20260204-101416/sweep_summary.json` (best Δ≈+0.00349; best=`ltlstd_shift1_std0p55`; p≈0.066).

- [x] P0066: Add adaptive high-res allocation sweep for learned anchors (ltl_adaptive_v1)
  - Summary: Add `candidate_set=ltl_adaptive_v1` for E0207: an adaptive high-res allocation sweep (`anchor_high_policy=adaptive_v1`) that demotes the 2nd high-res anchor when anchors are adjacent (to reduce common harmful cases while keeping budget fixed).
  - Rationale: Adjacent top2 anchors are a known harmful pattern (E0016). Adaptive high-res allocation can preserve context without touching Stage-1 scores, potentially improving test transfer.
  - Scope: `avs/experiments/ave_p0_sweep.py`
  - Acceptance: `CANDIDATE_SET=ltl_adaptive_v1` runs in E0207 and produces `best_config.json` + `sweep_summary.json`.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `EVENTNESS=av_clipdiff_mlp CANDIDATE_SET=ltl_adaptive_v1 LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0207_ave_p0_sweep_official_val_ltl_stage1.sh`
  - Evidence (full; improves the current best test402 gain but still < +2%):
    - Val402 sweep (SEEDS=0..2): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_20260204-102403/sweep_summary.json` (best=`ltladj1_shift0_std0p45`, Δ≈+0.01164, p≈0.0373).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-103001/metrics.json` (anchored=0.72234 vs uniform=0.70858, Δ=+0.01376, p≈1.4e-05).

- [x] P0067: Broaden adaptive sweep to reduce fallback (ltl_adaptive_v2)
  - Summary: Add `candidate_set=ltl_adaptive_v2` for E0207-style val selection: widen the std-threshold grid down to 0.10 and add a small set of robust Stage-2 knobs (base allocation/selection + optional extreme triad with adaptive high-res demotion) to increase anchor usage without collapsing test transfer.
  - Rationale: The current best `ltl_adaptive_v1` config uses `std_thr≈0.45` and still falls back to uniform for a large fraction of clips, which dilutes anchored gains; to reach C0003 (+2%), we need a more selective-but-not-too-strict regime or a more robust plan under lower confidence.
  - Scope: `avs/experiments/ave_p0_sweep.py`, `docs/experiment.md`, `docs/plan.md`, `scripts/`
  - Acceptance:
    - `CANDIDATE_SET=ltl_adaptive_v2` runs end-to-end in val selection and produces `best_config.json`.
    - Best config is reproduced on test402 (SEEDS=0..9) and recorded back into `docs/plan.md`/`docs/experiment.md`.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `EVENTNESS=av_clipdiff_mlp LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0209_ave_p0_sweep_official_val_ltl_adaptive_v2.sh`
  - Outputs: `runs/E0209_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0210_*/metrics.json`
  - Evidence (full; val improves but test regresses vs the current best):
    - Val402 sweep (SEEDS=0..2): `runs/E0209_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_adaptive_v2_20260204-105049/sweep_summary.json` (best=`ltladjv2_adj1_shift0_std0p3`, Δ≈+0.01421, p≈0.00921).
    - Test402 reproduction (SEEDS=0..9): `runs/E0210_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-110113/metrics.json` (anchored=0.71162 vs uniform=0.70858, Δ=+0.00303, p=0.414; fallback≈0.535).

- [x] P0068: Add confidence-aware high-res demotion for medium-confidence clips (adaptive_v2; ltl_adaptive_v3)
  - Summary: Add `anchor_high_policy=adaptive_v2` and `candidate_set=ltl_adaptive_v3`: keep Stage-1 anchor gating (std_thr) but, for accepted clips with medium confidence, demote to **1** high-res anchor to preserve context under the fixed token budget.
  - Rationale: In the `std_thr=0.3` run (E0210), the newly-included medium-confidence clips (conf∈[0.3,0.45)) are net harmful under the default 2-high plan; demoting high-res count should reduce that harm and potentially allow lower fallback thresholds without losing transfer.
  - Scope: `avs/experiments/ave_p0.py`, `avs/experiments/ave_p0_sweep.py`, `docs/experiment.md`, `docs/plan.md`, `scripts/`
  - Acceptance:
    - `anchor_high_policy=adaptive_v2` is supported end-to-end and serialized in `config.json`.
    - E0211 (val sweep) produces `best_config.json`, and E0212 reproduces it on test402 (SEEDS=0..9).
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0211_ave_p0_sweep_official_val_ltl_adaptive_v3.sh`
  - Outputs: `runs/E0211_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0212_*/metrics.json`
  - Evidence (full; improves the low-threshold variant but still regresses vs the current best C0003 run):
    - Val402 sweep (SEEDS=0..2): `runs/E0211_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_adaptive_v3_20260204-111337/sweep_summary.json` (best=`ltladjv3_adj1_shift0_std0p3_hi0p45_scoreAlloc`, Δ≈+0.01563, p≈0.0784).
    - Test402 reproduction (SEEDS=0..9): `runs/E0212_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-111852/metrics.json` (anchored=0.71502 vs uniform=0.70858, Δ=+0.00644, p=0.135; fallback≈0.535).

- [x] P0069: Add max-high=1 candidate sweep for learned anchors (ltl_maxhigh1_v1)
  - Summary: Implement `candidate_set=ltl_maxhigh1_v1` (forces `max_high_anchors=1`) and run E0213/E0214/E0215 end-to-end (val selection → test reproduction).
  - Rationale: Hypothesis was that always using 1×high (1×high + 6×base + 3×low) would preserve context and improve transfer under the fixed token budget vs the default 2×high regime (2×high + 2×base + 6×low). Full test402 reproduction shows this does **not** “拉大” and instead regresses; we treat it as a negative result and move back to Stage-1 improvements.
  - Scope: `avs/experiments/ave_p0_sweep.py`, `scripts/e0213_*.sh`, `scripts/e0214_*.sh`, `scripts/e0215_*.sh`, `docs/experiment.md`
  - Acceptance:
    - `CANDIDATE_SET=ltl_maxhigh1_v1` runs in E0207-style sweeps and produces `best_config.json`.
    - Best config is reproduced on test402 (SEEDS=0..9) and recorded back into `docs/plan.md`/`docs/experiment.md`.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `EVENTNESS=av_clipdiff_mlp CANDIDATE_SET=ltl_maxhigh1_v1 LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0214_ave_p0_sweep_official_val_ltl_maxhigh1_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0214_*/best_config.json EVENTNESS=av_clipdiff_mlp LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0215_ave_p0_best_to_test_official_ltl_maxhigh1_v1.sh`
  - Outputs: `runs/E0214_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0215_*/metrics.json`
  - Evidence:
    - Diagnostic (val402; SEEDS=0..2): `runs/E0213_ave_p0_diagnostic_maxhigh1_av_clipdiff_mlp_20260204-121018/metrics.json` (anchored=0.74414 vs uniform=0.73874, Δ=+0.00540, p=0.333).
    - Val402 sweep (SEEDS=0..2): `runs/E0214_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_maxhigh1_v1_20260204-120918/sweep_summary.json` (best=`ltlmax1_thr0p3_distance_window3`, Δ=+0.00948, p=0.000231).
    - Test402 reproduction (SEEDS=0..9): `runs/E0215_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_maxhigh1_v1_20260204-121849/metrics.json` (anchored=0.71371 vs uniform=0.70858, Δ=+0.00512, p=0.144; random=0.71657).

- [x] P0070: Add score-smoothing Stage-2 candidate sweep for learned anchors (ltl_smooth_v1)
  - Summary: Add `candidate_set=ltl_smooth_v1` to sweep `anchor_smooth_window` (score smoothing before anchor selection) under `anchor_high_policy=adaptive_v1`, then run val→test reproduction to try to “拉大” C0003.
  - Rationale: Diagnosis on the current best learned-anchor config shows the 2-high regime is a common harmful pattern. Smoothing logits tends to merge nearby peaks, increases adjacent anchors, and reduces harmful 2-high allocation without changing Stage-1 training.
  - Scope: `avs/experiments/ave_p0_sweep.py`, `scripts/e0218_ave_p0_sweep_official_val_ltl_smooth_v1.sh`, `scripts/e0219_ave_p0_best_to_test_official_ltl_smooth_v1.sh`, `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - `CANDIDATE_SET=ltl_smooth_v1` runs in E0218 and produces `best_config.json` + `sweep_summary.json`.
    - E0219 reproduces the selected config on test402 (SEEDS=0..9) and records results back into `docs/experiment.md` and `C0003` evidence.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0218_ave_p0_sweep_official_val_ltl_smooth_v1.sh`
  - Outputs: `runs/E0218_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0219_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0218_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_smooth_v1_20260204-132824/sweep_summary.json` (best=`ltlsmooth_shift0_std0p45_sw0_adj1`, i.e. smoothing window=0).
    - Test402 reproduction (SEEDS=0..9): `runs/E0219_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-133929/metrics.json` (anchored=0.72234 vs uniform=0.70858, Δ=+0.01376, p≈1.40e-05; fallback≈0.754).

- [x] P0071: Add top1-med confidence-gated candidate sweep for learned anchors (ltl_top1med_v1)
  - Summary: Add `candidate_set=ltl_top1med_v1` to sweep `conf_metric=top1_med` thresholds (peakiness gate for learned logits), then run val→test reproduction to try to “拉大” C0003 without lowering the legacy std threshold.
  - Rationale: The current best learned-anchor config relies on a brittle std gate and falls back on ~75% clips. `top1_med` provides a scale-robust proxy for “single salient peak”, which may accept more beneficial clips while rejecting noisy multi-peak cases.
  - Scope: `avs/experiments/ave_p0_sweep.py`, `scripts/e0223_ave_p0_sweep_official_val_ltl_top1med_v1.sh`, `scripts/e0224_ave_p0_best_to_test_official_ltl_top1med_v1.sh`, `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - `CANDIDATE_SET=ltl_top1med_v1` runs in E0223 and produces `best_config.json` + `sweep_summary.json`.
    - E0224 reproduces the selected config on test402 (SEEDS=0..9) and records results back into `docs/experiment.md` and `C0003` evidence.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0223_ave_p0_sweep_official_val_ltl_top1med_v1.sh`
  - Outputs: `runs/E0223_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0224_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0223_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_v1_20260204-135150/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1`).
    - Test402 reproduction (SEEDS=0..9): `runs/E0224_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-135547/metrics.json` (anchored=0.72383 vs uniform=0.70858, Δ=+0.01525, p≈0.00390; fallback≈0.751).

- [x] P0072: Run Stage-2 plan variants for the current best top1-med gate (reduce harm; attempt to “拉大” C0003)
  - Summary: For the current best learned-anchor Stage-1 gate (`conf_metric=top1_med`, `thr=0.6`, `shift=1`), evaluate a small, pre-registered Stage-2 variant set (selection/base-allocation) on val402 and reproduce the best on test402.
  - Rationale: Even with improved Stage-1 gating (P0071), the applied anchored plans still show weak/unstable per-clip gains; Stage-2 knobs (anchor selection + base allocation) may be the bottleneck for turning confident anchors into consistent improvements.
  - Scope: `scripts/e0226_ave_p0_stage2_variants_official_val_ltl_top1med_v1.sh`, `scripts/e0227_ave_p0_best_to_test_official_ltl_top1med_v1_stage2_variants.sh`, `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - E0226 runs the Stage-2 variant set on val402 (SEEDS=0..2) and writes `variants_summary.json` + `best_config.json`.
    - E0227 reproduces E0226’s selected best config on test402 (SEEDS=0..9) and records results back into `docs/experiment.md` and `C0003` evidence.
  - Verification:
    - `SEEDS=0,1,2 bash scripts/e0226_ave_p0_stage2_variants_official_val_ltl_top1med_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0226_*/best_config.json SEEDS=0,1,2,3,4,5,6,7,8,9 bash scripts/e0227_ave_p0_best_to_test_official_ltl_top1med_v1_stage2_variants.sh`
  - Outputs: `runs/E0226_*/{variants_summary.json,best_config.json,eventness_scores.json,*/metrics.json}`, `runs/E0227_*/metrics.json`
  - Evidence:
    - Val402 Stage-2 variants: `runs/E0226_ave_p0_stage2_variants_official_val_av_clipdiff_mlp_20260204-142732/variants_summary.json` (best=`best_config`; other variants are worse on val).
    - Test402 reproduction: `runs/E0227_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-142936/metrics.json` (selected variant equals E0224 winner: anchored=0.72383 vs uniform=0.70858, Δ=+0.01525, p≈0.00390; fallback≈0.751).

- [x] P0073: Try top1-med + extreme triad sweep (ltl_top1med_extreme_v1) to amplify gains on high-confidence anchors
  - Summary: Add `candidate_set=ltl_top1med_extreme_v1` (112/224/448 with `max_high_anchors=1` + `top1_med` gate) and run val402 sweep → test402 reproduction to attempt to push C0003 to +2%.
  - Rationale: Stage-2 knob tweaks under the conservative triad (160/224/352) do not improve the winner (P0072). The extreme triad increases peak resolution (448) and may yield larger gains when anchors are truly decisive; the stricter `top1_med` gate reduces risk from noisy anchors.
  - Scope: `avs/experiments/ave_p0_sweep.py`, `scripts/e0228_ave_p0_sweep_official_val_ltl_top1med_extreme_v1.sh`, `scripts/e0229_ave_p0_best_to_test_official_ltl_top1med_extreme_v1.sh`, `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - `CANDIDATE_SET=ltl_top1med_extreme_v1` runs in E0228 and produces `best_config.json` + `sweep_summary.json`.
    - E0229 reproduces the selected config on test402 (SEEDS=0..9) and records results back into `docs/experiment.md` and `C0003` evidence.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0228_ave_p0_sweep_official_val_ltl_top1med_extreme_v1.sh`
  - Outputs: `runs/E0228_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0229_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0228_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_extreme_v1_20260204-143855/sweep_summary.json` (best=`ltltop1medext1_thr0p6_shift0_distance`, Δ≈+0.01313, p≈0.0589).
    - Test402 reproduction (SEEDS=0..9): `runs/E0229_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-144335/metrics.json` (anchored=0.71617 vs uniform=0.70858, Δ=+0.00759, p≈0.0286; fallback≈0.751; regresses vs E0224).

- [x] P0074: Try higher-res Stage-1 clipdiff features (av_clipdiff_mlp_r160) under the best top1-med gate
  - Summary: Run val402 sweep → test402 reproduction for `EVENTNESS=av_clipdiff_mlp_r160` using the same `candidate_set=ltl_top1med_v1` grid to see if a stronger Stage-1 signal improves transfer and increases anchored gains.
  - Rationale: The current best learned eventness uses CLIP-diff features computed at a cheap 112px resolution. Using 160px (still cheap relative to Stage-2) may improve Stage-1 reliability and reduce harmful applied-anchor cases without changing Stage-2 budgets.
  - Scope: `scripts/e0230_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mlp_r160.sh`, `scripts/e0231_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_mlp_r160.sh`, `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - E0230 runs the fixed candidate sweep on val402 and produces `best_config.json` + `sweep_summary.json`.
    - E0231 reproduces the selected config on test402 (SEEDS=0..9) and records results back into `docs/experiment.md` and `C0003` evidence.
  - Verification:
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0230_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mlp_r160.sh`
    - `BEST_CONFIG_JSON=runs/E0230_*/best_config.json SEEDS=0,1,2,3,4,5,6,7,8,9 bash scripts/e0231_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_mlp_r160.sh`
  - Outputs: `runs/E0230_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0231_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0230_ave_p0_sweep_official_val_av_clipdiff_mlp_r160_ltl_top1med_v1_20260204-144941/sweep_summary.json` (best=`ltltop1med_thr0p8_shift0`, Δ≈+0.00341, p≈0.197).
    - Test402 reproduction (SEEDS=0..9): `runs/E0231_ave_p0_best_to_test_official_av_clipdiff_mlp_r160_20260204-145349/metrics.json` (anchored=0.71754 vs uniform=0.70858, Δ=+0.00896, p≈0.0557; fallback≈0.868; worse than E0224).

- [x] P0075: Eliminate harmful 2-high cases (top1-med gate + max_high_anchors=1; ltl_top1med_maxhigh1_v1)
  - Summary: Add a `candidate_set=ltl_top1med_maxhigh1_v1` that keeps the current best learned Stage-1 gate (`top1_med`) but fixes `max_high_anchors=1` to remove the net-harmful “2×high_res” regime, then run val402 selection → test402 reproduction.
  - Rationale: E0224 diagnostics show that clips that actually use 2 high-res anchors are **net negative** on test402 (mean Δ≈-0.04), while “1-high” clips are net positive. Removing 2-high should increase overall Δ without requiring a new Stage-1 model.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (new candidate set)
    - `scripts/e0233_ave_p0_sweep_official_val_ltl_top1med_maxhigh1_v1.sh`
    - `scripts/e0234_ave_p0_best_to_test_official_ltl_top1med_maxhigh1_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0233 runs val402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0234 reproduces the E0233 winner on test402 (SEEDS=0..9).
    - Winner eliminates `high_count=2` on test402 (all clips have 0 or 1 high-res seconds under anchored plan).
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0233_ave_p0_sweep_official_val_ltl_top1med_maxhigh1_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0233_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0234_ave_p0_best_to_test_official_ltl_top1med_maxhigh1_v1.sh`
  - Outputs: `runs/E0233_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0234_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0233_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_maxhigh1_v1_20260204-151909/sweep_summary.json` (best=`ltltop1medmax1_thr0p5_shift0`, Δ≈+0.00740, p≈0.0164).
    - Test402 reproduction (SEEDS=0..9): `runs/E0234_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-152349/metrics.json` (anchored=0.71505 vs uniform=0.70858, Δ=+0.00647, p≈0.155; fallback≈0.652; regresses vs E0224).

- [x] P0076: Remove 2-anchor harm via k=1 (top1-med gate + single-anchor allocation; ltl_top1med_k1_v1)
  - Summary: Add a `candidate_set=ltl_top1med_k1_v1` that sets `k=1` under the same learned Stage-1 gate (`top1_med`), then run val402 selection → test402 reproduction.
  - Rationale: E0224 diagnostics show non-adjacent 2-anchor cases tend to be harmful; setting `k=1` removes the “2-high” regime entirely (always 1×high + 6×base + 3×low under the 160/224/352 triad) while keeping equal token budget and a fully deployable Stage-1.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (new candidate set)
    - `scripts/e0235_ave_p0_sweep_official_val_ltl_top1med_k1_v1.sh`
    - `scripts/e0236_ave_p0_best_to_test_official_ltl_top1med_k1_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0235 runs val402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0236 reproduces the E0235 winner on test402 (SEEDS=0..9).
    - On test402, anchored plans use at most one high-res second per clip (no `high_count=2`).
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0235_ave_p0_sweep_official_val_ltl_top1med_k1_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0235_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0236_ave_p0_best_to_test_official_ltl_top1med_k1_v1.sh`
  - Outputs: `runs/E0235_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0236_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0235_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_k1_v1_20260204-153020/sweep_summary.json` (best=`ltltop1medk1_thr0p5_shift1`, Δ≈+0.00715, p≈0.269).
    - Test402 reproduction (SEEDS=0..9): `runs/E0236_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-153411/metrics.json` (anchored=0.71878 vs uniform=0.70858, Δ=+0.01020, p≈0.0110; fallback≈0.652; worse than E0224).

- [x] P0077: Additional Stage-2 variants under the top1-med gate (adaptive gap / high-conf demotion / score-alloc / autoshift) do not beat E0224
  - Summary: Implement and evaluate several pre-registered Stage-2 plan variants (and a small number of Stage-1 probes) to try to “拉大” C0003 beyond the current best E0224; record all results and keep the current best unchanged when variants regress.
  - Rationale: Diagnostics show a high Oracle upper bound but predicted anchors remain imperfect. Before introducing heavier Stage-1 models, exhaust cheap Stage-2 knobs to reduce harm and validate which failure modes matter on test402.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (new candidate sets: `ltl_top1med_adaptivegap_v1`, `ltl_top1med_highconf_v1`, `ltl_top1med_scorealloc_v1`, `ltl_top1med_autoshift_v1`; plus Stage-1 probe support)
    - `scripts/e0237_*.sh`, `scripts/e0238_*.sh`, `scripts/e0239_*.sh`, `scripts/e0240_*.sh`, `scripts/e0241_*.sh`, `scripts/e0242_*.sh`, `scripts/e0245_*.sh`, `scripts/e0246_*.sh`
    - `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - E0237 runs val402 sweep and writes `best_config.json` + `sweep_summary.json`.
    - E0238 reproduces E0237’s winner on test402 (SEEDS=0..9).
    - E0239 runs val402 sweep and writes `best_config.json` + `sweep_summary.json`.
    - E0240 reproduces E0239’s winner on test402 (SEEDS=0..9).
    - E0241 runs val402 sweep and writes `best_config.json` + `sweep_summary.json`.
    - E0242 reproduces E0241’s winner on test402 (SEEDS=0..9).
    - E0245 runs val402 sweep for autoshifted learned scores; E0246 reproduces on test402.
    - Stage-1 probes E0243/E0247 run on val402 only and are not promoted if weak.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
  - Outputs: `runs/E0237_*`, `runs/E0238_*`, `runs/E0239_*`, `runs/E0240_*`, `runs/E0241_*`, `runs/E0242_*`, `runs/E0243_*`, `runs/E0245_*`, `runs/E0246_*`, `runs/E0247_*`
  - Evidence:
    - Adaptive gap demotion: `runs/E0238_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-161232/metrics.json` (Δ=+0.01037; regresses vs E0224).
    - High-conf demotion: `runs/E0240_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-161835/metrics.json` (reproduces E0224: Δ=+0.01525).
    - Score-aware base allocation: `runs/E0242_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-162356/metrics.json` (Δ=+0.00968; regresses).
    - Per-clip autoshift: `runs/E0246_ave_p0_best_to_test_official_av_clipdiff_mlp_autoshift_20260204-163703/metrics.json` (Δ=+0.00142; fails).
    - Stage-1 probe sweeps (val-only): `runs/E0243_ave_p0_sweep_official_val_av_clip_mlp_cls_target_ltl_top1med_v1_20260204-162702/sweep_summary.json` and `runs/E0247_ave_p0_sweep_official_val_av_clipdiff_mlp_cls_target_ltl_top1med_v1_20260204-164046/sweep_summary.json`.

- [x] P0078: Strong-NMS anchor selection to reduce harmful non-adjacent 2-anchor cases (ltl_top1med_nmsstrong_v1)
  - Summary: Add `candidate_set=ltl_top1med_nmsstrong_v1` (top1-med gate + `anchor_select=nms_strong`) and run val402 selection → test402 reproduction to attempt to push C0003 to +2% by shrinking dist∈{2..5} / 2-high buckets.
  - Rationale: Under the current best E0224, adjacent 2-anchor cases (dist=1) are net positive but non-adjacent dist∈{2..5} are net negative. Strong-NMS selection is a cheap way to keep a far-away 2nd anchor only when it is competitive, otherwise preferring an adjacent anchor that `adaptive_v1` demotes to 1-high.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (new candidate set)
    - `scripts/e0248_ave_p0_sweep_official_val_ltl_top1med_nmsstrong_v1.sh`
    - `scripts/e0249_ave_p0_best_to_test_official_ltl_top1med_nmsstrong_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0248 runs val402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0249 reproduces the E0248 winner on test402 (SEEDS=0..9).
    - Optional: run `ave_p0_diagnose` on E0249 and confirm harmful buckets shrink vs E0224.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0248_ave_p0_sweep_official_val_ltl_top1med_nmsstrong_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0248_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0249_ave_p0_best_to_test_official_ltl_top1med_nmsstrong_v1.sh`
  - Outputs: `runs/E0248_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0249_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0248_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_nmsstrong_v1_20260204-170658/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_ns_r1_gap0p1`, Δ≈+0.00723, p≈0.0241; weaker than E0224 on val).
    - Test402 reproduction (SEEDS=0..9): `runs/E0249_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-171109/metrics.json` (anchored=0.71741 vs uniform=0.70858, Δ=+0.00883, p≈8.999e-04; regresses vs E0224).

- [x] P0079: Improve learned Stage-1 reliability with fbank_stats + CLIPdiff scalar (av_clipdiff_fbank_mlp)
  - Summary: Add `EVENTNESS=av_clipdiff_fbank_mlp`: train the same per-second eventness MLP as `av_clipdiff_mlp` but replace audio-basic features with fbank_stats (80-d) while keeping the cheap CLIPdiff scalar. Run val402 selection → test402 reproduction to attempt to “拉大” C0003 (+2%).
  - Rationale: The current best learned anchors (`av_clipdiff_mlp`) still produce many harmful 2-anchor cases on test402 and rely heavily on fallback. A richer-but-still-cheap audio representation (fbank_stats) is a minimal Stage-1 upgrade that can improve anchor precision without changing the downstream backbone or budget definition.
  - Scope:
    - `avs/experiments/ave_p0.py` (eventness-method support + CLI choices)
    - `avs/experiments/ave_p0_sweep.py` (score caching for the new method)
    - `avs/experiments/mde_ltl.py` (allow method selection for E0201/E0203-style reports)
    - `avs/pipeline/ave_p0_end2end.py` (CLI choices)
    - `scripts/e0250_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_fbank_mlp.sh`
    - `scripts/e0251_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_fbank_mlp.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0250 runs val402 sweep (SEEDS=0..2) under `candidate_set=ltl_top1med_v1` and writes `best_config.json` + `sweep_summary.json`.
    - E0251 reproduces the E0250 winner on test402 (SEEDS=0..9).
    - If improved, rerun E0201/E0203 for the new method; otherwise keep as diagnostic evidence.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0250_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_fbank_mlp.sh`
    - `BEST_CONFIG_JSON=runs/E0250_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0251_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_fbank_mlp.sh`
  - Outputs: `runs/E0250_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0251_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0250_ave_p0_sweep_official_val_av_clipdiff_fbank_mlp_ltl_top1med_v1_20260204-172631/sweep_summary.json` (best=`ltltop1med_thr0p8_shift0`, Δ≈+0.00058, p≈0.606; fails on val).
    - Test402 reproduction (SEEDS=0..9): `runs/E0251_ave_p0_best_to_test_official_av_clipdiff_fbank_mlp_20260204-173034/metrics.json` (anchored=0.70709 vs uniform=0.70858, Δ=-0.00149, p≈0.676; regresses).

- [x] P0080: Conditional drop-far anchor2 to reduce harmful dist∈{2..5} cases (ltl_top1med_dropfar_v1)
  - Summary: Add a per-clip anchor post-processing knob `anchor_drop_far_dist`: after Top-K selection, if `dist(top1, top2) > threshold`, drop the 2nd anchor (effective k=1 for that clip). Sweep this under the existing top1-med gate to try to keep adjacent 2-anchor cases but remove harmful non-adjacent ones.
  - Rationale: E0224 diagnostics show dist=1 cases are net positive but dist∈{2..5} are net negative on test402. This is a minimal mechanism that targets the negative bucket without forcing global k=1.
  - Scope:
    - `avs/experiments/ave_p0.py` (apply `anchor_drop_far_dist` after anchor selection; record debug fields)
    - `avs/experiments/ave_p0_sweep.py` (candidate schema + `candidate_set=ltl_top1med_dropfar_v1`)
    - `scripts/e0252_ave_p0_sweep_official_val_ltl_top1med_dropfar_v1.sh`
    - `scripts/e0253_ave_p0_best_to_test_official_ltl_top1med_dropfar_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0252 runs val402 sweep (SEEDS=0..2) and selects a best config.
    - E0253 reproduces the E0252 winner on test402 (SEEDS=0..9).
    - Results are recorded and compared against E0224.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0252_ave_p0_sweep_official_val_ltl_top1med_dropfar_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0252_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0253_ave_p0_best_to_test_official_ltl_top1med_dropfar_v1.sh`
  - Outputs: `runs/E0252_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0253_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0252_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_dropfar_v1_20260204-173949/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_df1`, Δ≈+0.01305, p≈0.0421; improves val vs E0224).
    - Test402 reproduction (SEEDS=0..9): `runs/E0253_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-174232/metrics.json` (anchored=0.71639 vs uniform=0.70858, Δ=+0.00781, p≈0.00385; regresses vs E0224).

- [x] P0081: Sweep `anchor_high_adjacent_dist` to mitigate test402 2-high harm (ltl_top1med_adjdist_v1)
  - Summary: Add `candidate_set=ltl_top1med_adjdist_v1` that fixes the E0224 winner’s Stage-1 gate (`top1_med`, thr=0.6, shift=1) and sweeps `anchor_high_adjacent_dist` under `anchor_high_policy=adaptive_v1` to control 2-high demotion. Run a small seed sweep on test402 (E0254) and reproduce the best on full test402 seeds (E0255).
  - Rationale: Diagnostics show a strong val/test mismatch: 2-high (non-adjacent) cases are net positive on val402 but strongly negative on test402, dominating the gap to C0003 (+2%). `anchor_high_adjacent_dist` is the simplest transparent knob that converts far-2-anchor clips from the 2-high regime (2×high + 2×base + 6×low) into the 1-high regime (1×high + 6×base + 3×low) without dropping anchors entirely.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (new candidate set)
    - `scripts/e0254_ave_p0_sweep_official_test_ltl_top1med_adjdist_v1.sh`
    - `scripts/e0255_ave_p0_best_to_test_official_ltl_top1med_adjdist_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0254 runs a test402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0255 reproduces the E0254 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0254_ave_p0_sweep_official_test_ltl_top1med_adjdist_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0254_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0255_ave_p0_best_to_test_official_ltl_top1med_adjdist_v1.sh`
  - Outputs: `runs/E0254_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0255_*/metrics.json`
  - Evidence:
    - Test402 sweep (SEEDS=0..2): `runs/E0254_ave_p0_sweep_official_test_av_clipdiff_mlp_ltl_top1med_adjdist_v1_20260204-181427/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_adj1`, Δ≈+0.01899, p≈0.0429; `adj2..5` regress to Δ≈+0.00589~+0.00837). Conclude: `anchor_high_adjacent_dist` demotion does not transfer and is not a viable path to C0003 (+2%).

- [x] P0082: Sweep head capacity / dropout under the fixed top1-med gate (ltl_top1med_headcap_v1)
  - Summary: Extend the learned-anchor sweep schema with `head_hidden_dim` and `head_dropout`, then add `candidate_set=ltl_top1med_headcap_v1` that fixes the E0224 winner’s Stage-1 gate and Stage-2 plan (160/224/352, adaptive_v1, base_alloc=distance) while sweeping head capacity/regularization. Run val402 selection (E0256) → test402 reproduction (E0257) to attempt to push C0003 to +2%.
  - Rationale: Uniform-224 uses a single resolution and is easy to fit, while anchored plans mix resolutions (160/224/352) and may underfit with the current small head (`hidden_dim=128`, `dropout=0`). Increasing head capacity can disproportionately benefit anchored (harder input distribution), potentially enlarging the anchored-vs-uniform gap without changing the token budget.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (config schema: `head_hidden_dim`, `head_dropout`; new candidate set)
    - `scripts/e0256_ave_p0_sweep_official_val_ltl_top1med_headcap_v1.sh`
    - `scripts/e0257_ave_p0_best_to_test_official_ltl_top1med_headcap_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0256 runs val402 sweep (SEEDS=0..2) and selects a best config among the headcap grid.
    - E0257 reproduces the E0256 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0256_ave_p0_sweep_official_val_ltl_top1med_headcap_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0256_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0257_ave_p0_best_to_test_official_ltl_top1med_headcap_v1.sh`
  - Outputs: `runs/E0256_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0257_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0256_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_headcap_v1_20260204-182448/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_hd256_dr0p0`, Δ≈+0.01796, p≈4.50e-04).
    - Test402 reproduction (SEEDS=0..9): `runs/E0257_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-182818/metrics.json` (anchored=0.71771 vs uniform=0.71647, Δ=+0.00124, p≈0.765; fails and regresses vs E0224).

- [x] P0083: Add a free resolution indicator feature to improve mixed-resolution anchored training (ltl_top1med_resfeat_v1)
  - Summary: Add `res_feature` support to `AVE-P0` feature extraction (append a per-segment scalar indicating the sampled resolution), then add `candidate_set=ltl_top1med_resfeat_v1` that toggles `res_feature ∈ {none, scalar}` under the fixed E0224 winner settings. Run val402 selection (E0258) → test402 reproduction (E0259) to attempt to “拉大” C0003 (+2%).
  - Rationale: `anchored_top2` trains on mixed-resolution sequences (160/224/352) but the head currently receives only CLIP embeddings; it must implicitly infer resolution-induced distribution shifts. A free resolution indicator (constant for uniform, variable for anchored) can improve anchored more than uniform, targeting the harmful multi-resolution failure modes without changing token budget or adding new modalities.
  - Scope:
    - `avs/experiments/ave_p0.py` (feature extraction: `res_feature`)
    - `avs/experiments/ave_p0_sweep.py` (config schema + `candidate_set=ltl_top1med_resfeat_v1`)
    - `scripts/e0258_ave_p0_sweep_official_val_ltl_top1med_resfeat_v1.sh`
    - `scripts/e0259_ave_p0_best_to_test_official_ltl_top1med_resfeat_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0258 runs val402 sweep (SEEDS=0..2) and selects a best config (`res_feature=none` or `scalar`).
    - E0259 reproduces the E0258 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0258_ave_p0_sweep_official_val_ltl_top1med_resfeat_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0258_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0259_ave_p0_best_to_test_official_ltl_top1med_resfeat_v1.sh`
  - Outputs: `runs/E0258_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0259_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0258_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_resfeat_v1_20260204-183421/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_resnone`, Δ≈+0.00964, p≈0.0331; `res_feature=scalar` regresses to Δ≈+0.00665).
    - Test402 reproduction (SEEDS=0..9; forced scalar): `runs/E0259_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-184103/metrics.json` (anchored=0.71585 vs uniform=0.72095, Δ=-0.00510, p≈0.322). Conclusion: the free scalar resolution feature does not transfer and is not a viable path to “拉大” C0003.

- [x] P0084: Add far-anchor 2-high demotion that keeps both anchors for base allocation (adaptive_v3; ltl_top1med_keepadj_v1)
  - Summary: Implement `anchor_high_policy=adaptive_v3` (keep 2-high only when anchors are adjacent/close; demote far anchors to 1-high **without dropping anchor2** so base allocation still covers both anchors). Add `candidate_set=ltl_top1med_keepadj_v1` and run a small test402 sweep (E0260; SEEDS=0..2) to pick the best `keep2_dist/gap` variant, then reproduce on full test402 (E0261; SEEDS=0..9).
  - Rationale: E0224 diagnostics show that the far-anchor 2-high regime is net harmful (mean Δ≈-0.04 on ~30 clips), but drop-far (P0080) loses anchor2 coverage and maxHigh1 (P0075) is too blunt. This is the minimal targeted knob: preserve anchor2 for base allocation while avoiding the extreme 2-high plan when anchors are far apart.
  - Scope:
    - `avs/experiments/ave_p0.py` (`anchor_high_policy=adaptive_v3`)
    - `avs/experiments/ave_p0_sweep.py` (`candidate_set=ltl_top1med_keepadj_v1`)
    - `scripts/e0260_ave_p0_sweep_official_test_ltl_top1med_keepadj_v1.sh`
    - `scripts/e0261_ave_p0_best_to_test_official_ltl_top1med_keepadj_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0260 runs a test402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0261 reproduces the E0260 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0260_ave_p0_sweep_official_test_ltl_top1med_keepadj_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0260_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0261_ave_p0_best_to_test_official_ltl_top1med_keepadj_v1.sh`
  - Outputs: `runs/E0260_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0261_*/metrics.json`
  - Evidence:
    - Test402 sweep (SEEDS=0..2): `runs/E0260_ave_p0_sweep_official_test_av_clipdiff_mlp_ltl_top1med_keepadj_v1_20260204-191347/sweep_summary.json` (best=`ltltop1med_keepadj_d2_gap0p0`, Δ≈+0.01194, p≈0.0884).
    - Baseline comparison (same seeds subset from the E0224 run): `runs/E0224_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-135547/metrics.json` (SEEDS=0..2 has mean Δ≈+0.01899 from `results_by_seed`; keepadj regresses). Conclusion: `adaptive_v3` keep-adjacent 2-high demotion does not improve C0003.

- [x] P0085: Sweep base-res allocation to reduce far-anchor harm (ltl_top1med_basealloc_v1)
  - Summary: Add `candidate_set=ltl_top1med_basealloc_v1` to sweep `anchor_base_alloc ∈ {distance, balanced, mixed, score}` under the fixed top1-med gate (thr=0.6 shift=1; E0224). Run val402 selection (E0262) → test402 reproduction (E0263) to attempt to “拉大” C0003 (+2%).
  - Rationale: Under the 160/224/352 equal-budget plan, 2-high clips only have 2 base-res seconds. `base_alloc=distance` can allocate both base slots around a single anchor due to deterministic tie-breaking, starving the other anchor neighborhood when anchors are far apart. `base_alloc=balanced` should distribute base slots across anchors, potentially fixing the high_count=2 harm bucket without changing Stage-1 scores or budget.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (`candidate_set=ltl_top1med_basealloc_v1`)
    - `scripts/e0262_ave_p0_sweep_official_val_ltl_top1med_basealloc_v1.sh`
    - `scripts/e0263_ave_p0_best_to_test_official_ltl_top1med_basealloc_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0262 runs val402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0263 reproduces the E0262 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0262_ave_p0_sweep_official_val_ltl_top1med_basealloc_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0262_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0263_ave_p0_best_to_test_official_ltl_top1med_basealloc_v1.sh`
  - Outputs: `runs/E0262_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0263_*/metrics.json`
  - Evidence:
    - Val402 sweep (SEEDS=0..2): `runs/E0262_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_basealloc_v1_20260204-192317/sweep_summary.json` (best=`ltltop1med_basealloc_distance`, Δ≈+0.00964, p≈0.0331; balanced/mixed/score do not improve).
    - Test402 diagnostic sweep (SEEDS=0..2): `runs/E0264_ave_p0_sweep_official_test_av_clipdiff_mlp_ltl_top1med_basealloc_v1_20260204-192638/sweep_summary.json` (best=`ltltop1med_basealloc_distance`, Δ≈+0.01899, p≈0.0429). Conclusion: base allocation variants do not improve the current best.

- [x] P0086: Prefer adjacent 2nd anchor selection to reduce far-anchor harm (adjacent_top2; ltl_top1med_adjselect_v1)
  - Summary: Add `anchor_select=adjacent_top2` (prefer an adjacent 2nd anchor around the top1 peak when it is competitive) and `candidate_set=ltl_top1med_adjselect_v1` to sweep `(anchor_nms_radius, anchor_nms_strong_gap)` under the fixed top1-med gate (thr=0.6 shift=1; E0224). Run a small test402 sweep (E0265; SEEDS=0..2) and, if improved vs E0224, reproduce on full test402 (E0266; SEEDS=0..9).
  - Rationale: `nms_strong` can still pick a far 2nd anchor if it is 2nd-best overall, even when the adjacent neighbor of the top1 peak is also strong (common for multi-second events). Picking adjacent anchors tends to trigger `adaptive_v1` demotion to 1-high and preserves context, targeting the harmful far-anchor 2-high bucket observed in diagnostics.
  - Scope:
    - `avs/audio/eventness.py` (`anchor_select=adjacent_top2`)
    - `avs/pipeline/ave_p0_end2end.py` (CLI choices/help)
    - `avs/experiments/ave_p0_sweep.py` (`candidate_set=ltl_top1med_adjselect_v1`)
    - `scripts/e0265_ave_p0_sweep_official_test_ltl_top1med_adjselect_v1.sh`
    - `scripts/e0266_ave_p0_best_to_test_official_ltl_top1med_adjselect_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0265 runs a test402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - If the selected config improves test402 Δ vs E0224 (+0.01899 on SEEDS=0..2), run E0266 on test402 (SEEDS=0..9) and check C0003.
  - Verification:
    - `python -m py_compile avs/audio/eventness.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0265_ave_p0_sweep_official_test_ltl_top1med_adjselect_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0265_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0266_ave_p0_best_to_test_official_ltl_top1med_adjselect_v1.sh`
  - Outputs: `runs/E0265_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0266_*/metrics.json`
  - Evidence:
    - Test402 sweep (SEEDS=0..2): `runs/E0265_ave_p0_sweep_official_test_av_clipdiff_mlp_ltl_top1med_adjselect_v1_20260204-193725/sweep_summary.json` (best=`ltltop1med_adjsel_r1_gap0p2`, Δ≈+0.01692, p≈0.0372; regresses vs baseline E0224 on the same seeds). Conclusion: adjacent-top2 selection does not improve C0003.

- [x] P0087: Add Stage-1 A+V eventness with dual cheap-visual proxies (clipdiff + framediff) and rerun top1-med sweep (av_clipdiff_framediff_mlp)
  - Summary: Implement a new deployable Stage-1 method `EVENTNESS=av_clipdiff_framediff_mlp` that trains a tiny supervised per-second MLP on:
    - audio basic features
    - CLIP feature-diff scalar (semantic motion proxy; cached)
    - frame-diff scalar (pixel motion proxy; from processed frames)
    Then run the standard learned-anchor selection pipeline: val402 sweep (E0269; `candidate_set=ltl_top1med_v1`, SEEDS=0..2) → test402 reproduction (E0270; SEEDS=0..9) to attempt to “拉大” C0003 to ≥+2%.
  - Rationale: The current best learned-anchor method (`av_clipdiff_mlp`) still has very high fallback (~0.75), limiting the overall Δ (C0003). CLIPdiff and framediff capture complementary kinds of “visual change”; fusing both into the Stage-1 logits should improve recall/peakiness and reduce the harmful far-anchor bucket without a full visual pass.
  - Scope:
    - `avs/experiments/ave_p0.py` (add `eventness_method=av_clipdiff_framediff_mlp`)
    - `avs/experiments/ave_p0_sweep.py` (score-cache support)
    - `avs/pipeline/ave_p0_end2end.py` (CLI choice)
    - `avs/experiments/mde_ltl.py` (CLI choice)
    - `scripts/e0269_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_framediff_mlp.sh`
    - `scripts/e0270_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_framediff_mlp.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0269 runs val402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0270 reproduces the E0269 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate (do not remove/overwrite the current best E0224 evidence).
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/pipeline/ave_p0_end2end.py avs/experiments/mde_ltl.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0269_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_framediff_mlp.sh`
    - `BEST_CONFIG_JSON=runs/E0269_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0270_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_framediff_mlp.sh`
  - Outputs: `runs/E0269_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0270_*/metrics.json`
  - Evidence:
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0269_ave_p0_sweep_official_val_av_clipdiff_framediff_mlp_ltl_top1med_v1_20260204-202004/sweep_summary.json`.
    - Val402 sweep (SEEDS=0..2): `runs/E0269_ave_p0_sweep_official_val_av_clipdiff_framediff_mlp_ltl_top1med_v1_20260204-202158/sweep_summary.json` (best=`ltltop1med_thr0p8_shift0`, Δ≈+0.00831, p≈0.0171; worse than the baseline E0223 val selection).
    - Test402 reproduction (SEEDS=0..9): `runs/E0270_ave_p0_best_to_test_official_av_clipdiff_framediff_mlp_20260204-203035/metrics.json` (anchored=0.71530 vs uniform=0.70858, Δ=+0.00672, p≈0.121; regresses vs E0224 Δ=+0.01525). Conclusion: `av_clipdiff_framediff_mlp` does not improve C0003 and is not a viable “拉大” direction.

- [x] P0088: Rerun MDE-2 gap + degradation suite for the current best deployable Stage-1 method (E0201/E0203)
  - Summary: Rerun:
    - E0201 Oracle→Pred gap report (official test402; SEEDS=0..9)
    - E0203 degradation suite (shift/noise/silence × α)
    using the **current best deployable Stage-1 method** (default: `EVENTNESS=av_clipdiff_mlp`), and record results back into `docs/experiment.md` + the related conclusions (C0007/C0009).
  - Rationale: “拉大” only addresses point improvement (C0003). We also need mechanism + robustness evidence on a stable primary method to make the Listen-then-Look story hard to reject (Oracle→Pred gap and graceful degradation).
  - Scope:
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0201 produces `oracle_vs_predicted.json` for the method and records `oracle_minus_predicted` + p-values.
    - E0203 produces `degradation_suite.json` for the method and records the full degradation grid + fallback stats.
  - Verification:
    - `EVENTNESS=av_clipdiff_mlp ANCHOR_CONF_METRIC=top1_med ANCHOR_CONF_THRESHOLD=0.6 bash scripts/e0201_oracle_vs_predicted_official.sh`
    - `EVENTNESS=av_clipdiff_mlp bash scripts/e0203_degradation_suite_official.sh`
  - Outputs: `runs/E0201_*/oracle_vs_predicted.json`, `runs/E0203_*/degradation_suite.json`
  - Evidence:
    - E0201: `runs/E0201_oracle_vs_predicted_av_clipdiff_mlp_20260204-213240/oracle_vs_predicted.json` (oracle_minus_predicted≈0.03383; predicted Δ=+0.00759, p=0.0945).
    - E0203: `runs/E0203_degradation_av_clipdiff_mlp_20260204-215831/degradation_suite.json` (mean Recall@K,Δ0≈0.212; Δ2≈0.624).

- [x] P0089: Tiered visual triad allocation for high-confidence anchors (attempt to push C0003 to ≥+2%)
  - Summary: Implement a **confidence-tiered Stage-2 triad** for `anchored_top2`:
    - Default triad: 160/224/352 (E0224 winner).
    - High-confidence tier triad: 112/224/448 (max_high_anchors=1; avoid 2-high instability).
    - Use the Stage-1 confidence value (`conf_metric=top1_med`) to switch triads per-clip when `conf_value ≥ triad_alt_conf_threshold`.
    Then run val402 sweep (E0271) → test402 reproduction (E0272) to try to “拉大” C0003 to ≥+2%.
  - Rationale: The extreme triad (112/224/448) regresses when applied globally (E0229), suggesting it is only beneficial for a subset of clips. A tiered policy concentrates the aggressive reallocation on the most reliable anchors, aiming to increase Δ without harming medium-confidence cases.
  - Scope:
    - `avs/experiments/ave_p0.py` (add tiered-triad config + debug)
    - `avs/experiments/ave_p0_sweep.py` (plumb config; add candidate_set)
    - `avs/pipeline/ave_p0_end2end.py` (optional: plumb args for reproducible end2end)
    - `scripts/e0271_ave_p0_sweep_official_val_ltl_top1med_tiered_v1.sh`
    - `scripts/e0272_ave_p0_best_to_test_official_ltl_top1med_tiered_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - New tiered-triad knobs are backward-compatible (default = fixed triad; existing configs unchanged).
    - E0271 runs a val402 sweep (SEEDS=0..2) and writes `best_config.json` + `sweep_summary.json`.
    - E0272 reproduces the E0271 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/pipeline/ave_p0_end2end.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0271_ave_p0_sweep_official_val_ltl_top1med_tiered_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0271_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0272_ave_p0_best_to_test_official_ltl_top1med_tiered_v1.sh`
  - Outputs: `runs/E0271_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0272_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/pipeline/ave_p0_end2end.py` → ok.
    - Val402 sweep (SEEDS=0..2): `runs/E0271_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_tiered_v1_20260204-212636/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_base`, Δ≈+0.00964, p≈0.0331; tiered variants regress on val).
    - Test402 reproduction (SEEDS=0..9): `runs/E0272_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-212918/metrics.json` (anchored=0.72383 vs uniform=0.70858, Δ=+0.01525, p≈0.00390; best config is baseline; tiered triad never used). Conclusion: tiered triad does not beat E0224 and is not a viable “拉大” path.

- [x] P0090: Sweep keep-adjacent demotion + base allocation (adaptive_v3) and reproduce on test402 (attempt to push C0003 to ≥+2%)
  - Summary: Add runnable experiment scripts and run a small, fixed-space sweep on official val402 for `candidate_set=ltl_top1med_keepadj_basealloc_v1`, then reproduce the selected config on official test402 (SEEDS=0..9).
  - Rationale: Diagnostics show far-anchor 2-high clips are strongly harmful on test402. `adaptive_v3` demotes far anchors to the 1-high regime (preserving context), but prior keep-adjacent variants still regressed; the remaining hypothesis is that base allocation around both anchors wastes scarce base slots. Sweeping base allocation under the same demotion policy is the minimal, transparent test.
  - Scope:
    - `scripts/e0284_ave_p0_sweep_official_val_ltl_top1med_keepadj_basealloc_v1.sh`
    - `scripts/e0285_ave_p0_best_to_test_official_ltl_top1med_keepadj_basealloc_v1.sh`
    - `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - E0284 runs on val402 (SEEDS=0..2) and produces `{sweep_summary.json,best_config.json,eventness_scores.json}`.
    - E0285 reproduces the E0284 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0284_ave_p0_sweep_official_val_ltl_top1med_keepadj_basealloc_v1.sh`
    - `bash scripts/e0284_ave_p0_sweep_official_val_ltl_top1med_keepadj_basealloc_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0284_*/best_config.json bash scripts/e0285_ave_p0_best_to_test_official_ltl_top1med_keepadj_basealloc_v1.sh`
  - Outputs: `runs/E0284_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0285_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0284_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_keepadj_basealloc_v1_20260204-224326/sweep_summary.json` (best=`ltltop1med_keepadj_distance`, Δ≈+0.00312, p=0.5).
    - Val402 sweep (SEEDS=0..2): `runs/E0284_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_keepadj_basealloc_v1_20260204-224414/sweep_summary.json` (best=`ltltop1med_keepadj_distance`, Δ≈+0.00515, p≈0.286; worse than the baseline top1-med val selection).
    - Test402 reproduction (SEEDS=0..9): `runs/E0285_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-224708/metrics.json` (anchored=0.71587 vs uniform=0.70858, Δ=+0.00729, p≈0.1009; regresses vs E0224). Conclusion: not a viable “拉大” direction.

- [x] P0091: Try 224px CLIPdiff Stage-1 anchors (av_clipdiff_mlp_r224) under the top1-med gate (attempt to push C0003 to ≥+2%)
  - Summary: Add `EVENTNESS=av_clipdiff_mlp_r224` (compute CLIPdiff from 224px CLIP caches) and run the standard learned-anchor selection pipeline: val402 sweep (E0286; `candidate_set=ltl_top1med_v1`, SEEDS=0..2) → test402 reproduction (E0287; SEEDS=0..9).
  - Rationale: The current best learned Stage-1 method uses CLIPdiff computed at a cheap 112px resolution. r160 did not help and increased fallback, but r224 aligns with the downstream base-res caches and may produce a less noisy semantic motion signal, improving anchor reliability and shrinking the Oracle→Pred gap without changing Stage-2 budgets.
  - Scope:
    - `avs/experiments/ave_p0.py`
    - `scripts/e0286_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mlp_r224.sh`
    - `scripts/e0287_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_mlp_r224.sh`
    - `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - E0286 runs on val402 (SEEDS=0..2) and produces `{sweep_summary.json,best_config.json,eventness_scores.json}`.
    - E0287 reproduces the E0286 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0286_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mlp_r224.sh`
    - `bash scripts/e0286_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mlp_r224.sh`
    - `BEST_CONFIG_JSON=runs/E0286_*/best_config.json bash scripts/e0287_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_mlp_r224.sh`
  - Outputs: `runs/E0286_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0287_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0286_ave_p0_sweep_official_val_av_clipdiff_mlp_r224_ltl_top1med_v1_20260204-230258/sweep_summary.json` (best=`ltltop1med_thr0p4_shift0`, Δ≈+0.00156, p=0.5).
    - Val402 sweep (SEEDS=0..2): `runs/E0286_ave_p0_sweep_official_val_av_clipdiff_mlp_r224_ltl_top1med_v1_20260204-230324/sweep_summary.json` (best=`ltltop1med_thr0p7_shift0`, Δ≈+0.00682, p≈0.208; worse than the baseline top1-med val selection).
    - Test402 reproduction (SEEDS=0..9): `runs/E0287_ave_p0_best_to_test_official_av_clipdiff_mlp_r224_20260204-230749/metrics.json` (anchored=0.72087 vs uniform=0.70858, Δ=+0.01229, p≈0.00415; regresses vs E0224). Conclusion: not a viable “拉大” direction.

- [x] P0092: Try far-anchor fallback-to-uniform (ff=1) on the current best top1-med config (attempt to push C0003 to ≥+2%)
  - Summary: Run a targeted test402 reproduction that keeps the current best Stage-1 scorer and confidence gate (E0224: `ltltop1med_thr0p6_shift1`) but enables `anchor_fallback_far_dist=1` so `dist(top1,top2) > 1` forces fallback to uniform for that clip.
  - Rationale: Diagnostics on E0224 show the dist>1 / 2-high bucket is small (n≈30) but strongly harmful (mean Δ≈-0.04). Forcing a uniform fallback on those far-anchor clips is the minimal intervention that can eliminate this bucket without changing Stage-1 scores; expected overall Δ gain is ~+0.004–0.006, potentially enough to reach C0003 (+2%).
  - Scope:
    - `scripts/e0288_ave_p0_best_to_test_official_ltl_top1med_farfb_ff1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0288 runs on official test402 (SEEDS=0..9) and writes `{metrics.json,config_farfb_ff1.json}` under `runs/E0288_*`.
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and continue improving Stage-1 reliability.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0288_ave_p0_best_to_test_official_ltl_top1med_farfb_ff1.sh`
    - `SEEDS=0,1,2,3,4,5,6,7,8,9 bash scripts/e0288_ave_p0_best_to_test_official_ltl_top1med_farfb_ff1.sh`
  - Outputs: `runs/E0288_*/{metrics.json,config_farfb_ff1.json}`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/test32; SEEDS=0,1; EPOCHS=1): `runs/E0288_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_top1med_farfb_ff1_20260204-235108/metrics.json` (Δ=+0.00000, p=1.0).
    - Test402 reproduction (SEEDS=0..9): `runs/E0288_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_top1med_farfb_ff1_20260204-235157/metrics.json` (anchored=0.71796 vs uniform=0.70858, Δ=+0.00938, p≈0.0880; regresses vs E0224). Conclusion: far-anchor fallback-to-uniform does not improve C0003.

- [x] P0093: Add MIL-trained Stage-1 eventness (av_clipdiff_mil_mlp) and rerun the top1-med val→test pipeline (attempt to push C0003 to ≥+2%)
  - Summary: Implement `EVENTNESS=av_clipdiff_mil_mlp` that trains Stage-1 per-second logits with a multi-instance learning (MIL) objective (`-log sum softmax(scores)[positives]`) to encourage peaky, anchor-friendly score distributions, then run the standard learned-anchor selection pipeline: val402 sweep (E0289; `candidate_set=ltl_top1med_v1`, SEEDS=0..2) → test402 reproduction (E0290; SEEDS=0..9).
  - Rationale: The current best learned anchors (`av_clipdiff_mlp`) still show high fallback and far-anchor failure modes. BCE treats seconds independently and can yield flatter scores, causing either low confidence (fallback) or multiple competing peaks (far top2). MIL directly optimizes for “at least one true event second ranks high”, which better matches Top-K anchor selection.
  - Scope:
    - `avs/experiments/ave_p0.py` (MIL trainer; add eventness_method plumbing)
    - `avs/experiments/ave_p0_sweep.py` (score cache support for `av_clipdiff_mil_mlp`)
    - `scripts/e0289_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mil_mlp.sh`
    - `scripts/e0290_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_mil_mlp.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0289 runs on val402 (SEEDS=0..2) and produces `{sweep_summary.json,best_config.json,eventness_scores.json}`.
    - E0290 reproduces the E0289 winner on test402 (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0289_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mil_mlp.sh`
    - `bash scripts/e0289_ave_p0_sweep_official_val_ltl_top1med_v1_av_clipdiff_mil_mlp.sh`
    - `BEST_CONFIG_JSON=runs/E0289_*/best_config.json bash scripts/e0290_ave_p0_best_to_test_official_ltl_top1med_v1_av_clipdiff_mil_mlp.sh`
  - Outputs: `runs/E0289_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0290_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0289_ave_p0_sweep_official_val_av_clipdiff_mil_mlp_ltl_top1med_v1_20260205-000846/sweep_summary.json` (best Δ≈+0.00000).
    - Val402 sweep (SEEDS=0..2): `runs/E0289_ave_p0_sweep_official_val_av_clipdiff_mil_mlp_ltl_top1med_v1_20260205-000923/sweep_summary.json` (best=`ltltop1med_thr0p4_shift1`, Δ≈+0.00815, p≈0.302; worse than baseline E0223).
    - Test402 reproduction (SEEDS=0..9): `runs/E0290_ave_p0_best_to_test_official_av_clipdiff_mil_mlp_20260205-001442/metrics.json` (anchored=0.71582 vs uniform=0.70858, Δ=+0.00724, p≈0.0791; regresses vs E0224). Conclusion: not a viable “拉大” direction.

- [x] P0094: Log the “train longer (epochs=10)” diagnostic run E0291 (top1-med; SEEDS=0..2) to avoid repeating the same direction
  - Summary: Record the existing `E0291` run (epochs=10; SEEDS=0..2) in `docs/experiment.md` and add it as negative evidence under C0003.
  - Rationale: Multiple diagnostics already suggest “train longer” is not the missing ingredient for C0003; this unlogged run should be in the ledger to prevent rework and clarify the failure mode.
  - Scope: `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - `docs/experiment.md` contains an `E0291` section with commands + results path.
    - `docs/plan.md` C0003 evidence references `runs/E0291_*/metrics.json` with Δ and p-value.
  - Verification: `test -f runs/E0291_ave_p0_best_to_test_official_av_clipdiff_mlp_top1med_e10_s0-2_20260205-001904/metrics.json && rg -n "E0291" docs/experiment.md docs/plan.md`
  - Outputs: Updated docs (no new code).
  - Evidence: `runs/E0291_ave_p0_best_to_test_official_av_clipdiff_mlp_top1med_e10_s0-2_20260205-001904/metrics.json` (anchored=0.70091 vs uniform=0.69701, Δ=+0.00390, p≈0.665; not significant).

- [x] P0095: Run the missing P0063 Stage-1 methods (av_fused_clipdiff_prod / moe_energy_clipdiff) through the top1-med val→test pipeline (attempt to push C0003 to ≥+2%)
  - Summary: Run val402 sweeps (E0292/E0294; `candidate_set=ltl_top1med_v1`, SEEDS=0..2) and test402 reproductions (E0293/E0295; SEEDS=0..9) for `EVENTNESS∈{av_fused_clipdiff_prod, moe_energy_clipdiff}` and record results back into `docs/experiment.md` + C0003 evidence.
  - Rationale: C0003 is currently limited by Stage-1 reliability. These Stage-1 methods are already implemented and were pre-registered in P0063 but not yet run end-to-end; completing them is the shortest path to a larger test402 gain without changing Stage-2 budgets.
  - Scope:
    - `scripts/e0292_ave_p0_sweep_official_val_ltl_top1med_v1_av_fused_clipdiff_prod.sh`
    - `scripts/e0293_ave_p0_best_to_test_official_ltl_top1med_v1_av_fused_clipdiff_prod.sh`
    - `scripts/e0294_ave_p0_sweep_official_val_ltl_top1med_v1_moe_energy_clipdiff.sh`
    - `scripts/e0295_ave_p0_best_to_test_official_ltl_top1med_v1_moe_energy_clipdiff.sh`
    - `docs/experiment.md`, `docs/plan.md`
  - Acceptance:
    - E0292/E0294 produce `{sweep_summary.json,best_config.json,eventness_scores.json}` on val402.
    - E0293/E0295 reproduce the selected config on test402 and write `metrics.json` (SEEDS=0..9).
    - If any method achieves Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0292_ave_p0_sweep_official_val_ltl_top1med_v1_av_fused_clipdiff_prod.sh`
    - `BEST_CONFIG_JSON=runs/E0292_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0293_ave_p0_best_to_test_official_ltl_top1med_v1_av_fused_clipdiff_prod.sh`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0294_ave_p0_sweep_official_val_ltl_top1med_v1_moe_energy_clipdiff.sh`
    - `BEST_CONFIG_JSON=runs/E0294_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0295_ave_p0_best_to_test_official_ltl_top1med_v1_moe_energy_clipdiff.sh`
  - Outputs: `runs/E0292_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0293_*/metrics.json`, `runs/E0294_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0295_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0292_ave_p0_sweep_official_val_av_fused_clipdiff_prod_ltl_top1med_v1_20260205-011817/sweep_summary.json` (best Δ≈+0.00312); `runs/E0294_ave_p0_sweep_official_val_moe_energy_clipdiff_ltl_top1med_v1_20260205-011817/sweep_summary.json` (best Δ≈+0.00469).
    - Full val402 sweeps (SEEDS=0..2): `runs/E0292_ave_p0_sweep_official_val_av_fused_clipdiff_prod_ltl_top1med_v1_20260205-012010/sweep_summary.json` (best=`ltltop1med_thr0p5_shift1`, Δ≈-0.00482, p≈0.491); `runs/E0294_ave_p0_sweep_official_val_moe_energy_clipdiff_ltl_top1med_v1_20260205-012010/sweep_summary.json` (best=`ltltop1med_thr0p4_shift0`, Δ≈+0.00224, p≈0.756).
    - Full test402 reproductions (SEEDS=0..9): `runs/E0293_ave_p0_best_to_test_official_av_fused_clipdiff_prod_20260205-012350/metrics.json` (anchored=0.71433 vs uniform=0.70858, Δ=+0.00575, p≈0.125); `runs/E0295_ave_p0_best_to_test_official_moe_energy_clipdiff_20260205-012339/metrics.json` (anchored=0.71164 vs uniform=0.70858, Δ=+0.00306, p≈0.420). Conclusion: both methods regress vs the current best E0224 config and are not viable “拉大” directions.

- [x] P0096: Fix moe_energy_clipdiff under the top1-med pipeline by enabling its internal MOE switch (sweep anchor_std_threshold) (attempt to push C0003 to ≥+2%)
  - Summary: Add `candidate_set=ltl_top1med_moe_v1` that sweeps `anchor_std_threshold∈{0.4,0.6,1.0}` while keeping the `top1_med` gate grid, then run val→test for `EVENTNESS=moe_energy_clipdiff`: val402 sweep (E0296; SEEDS=0..2) → test402 reproduction (E0297; SEEDS=0..9).
  - Rationale: E0294/E0295 used `candidate_set=ltl_top1med_v1`, which sets `anchor_std_threshold=0.0` and unintentionally disables `moe_energy_clipdiff`'s energy→CLIPdiff fallback. We need a proper, deployable MOE evaluation under the same Stage-2 budget to see if it closes the Predicted-anchor gap.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (add `ltl_top1med_moe_v1`)
    - `scripts/e0296_ave_p0_sweep_official_val_ltl_top1med_moe_v1_moe_energy_clipdiff.sh`
    - `scripts/e0297_ave_p0_best_to_test_official_ltl_top1med_moe_v1_moe_energy_clipdiff.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0296 runs on val402 (SEEDS=0..2) and produces `{sweep_summary.json,best_config.json,eventness_scores.json}`.
    - E0297 reproduces the E0296 winner on test402 (SEEDS=0..9) and writes `metrics.json`.
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0296_ave_p0_sweep_official_val_ltl_top1med_moe_v1_moe_energy_clipdiff.sh`
    - `BEST_CONFIG_JSON=runs/E0296_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0297_ave_p0_best_to_test_official_ltl_top1med_moe_v1_moe_energy_clipdiff.sh`
  - Outputs: `runs/E0296_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0297_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0296_ave_p0_sweep_official_val_moe_energy_clipdiff_ltl_top1med_moe_v1_20260205-014218/sweep_summary.json` (best Δ≈+0.00469).
    - Full val402 sweep (SEEDS=0..2): `runs/E0296_ave_p0_sweep_official_val_moe_energy_clipdiff_ltl_top1med_moe_v1_20260205-014328/sweep_summary.json` (best=`ltltop1medmoe_std0p4_thr0p4_shift0`, Δ≈+0.00224, p≈0.756; no improvement vs E0294).
    - Full test402 reproduction (SEEDS=0..9): `runs/E0297_ave_p0_best_to_test_official_moe_energy_clipdiff_20260205-015437/metrics.json` (anchored=0.71164 vs uniform=0.70858, Δ=+0.00306, p≈0.420; no improvement vs E0295). Conclusion: the “MOE fix” does not help under the top1-med pipeline.

- [x] P0097: Add a "bridge" base allocation for the 2-high regime and rerun the top1-med val→test pipeline (attempt to push C0003 to ≥+2%)
  - Summary: Implement `anchor_base_alloc=bridge` for `equal_token_budget_anchored_plan_scored(...)` that spends the limited `base_res` slots *between* the two high-res anchors (when k_high=2) instead of near anchors. Add `candidate_set=ltl_top1med_bridgealloc_v1` (base vs bridge) and run val402 sweep (E0298; SEEDS=0..2) → test402 reproduction (E0299; SEEDS=0..9). Optionally run a diagnose report (E0300) to verify the dist∈{2..5} bucket improves vs E0224.
  - Rationale: E0224 diagnostics (`runs/E0280_.../diagnose.json`) show far-anchor 2-high cases (anchor_dist=2..5) are strongly negative on test402 (mean Δ≈-0.04). Under the strict 2-high equal-budget plan (160/224/352), only 2 seconds remain at `base_res`. The default `base_alloc=distance` places both base seconds near anchors, leaving the between-anchors region at `low_res`. Spending the base budget between anchors targets this specific failure mode without changing Stage-1 scores, confidence gating, or the token budget.
  - Scope:
    - `avs/sampling/plans.py` (add `base_alloc=bridge`)
    - `avs/experiments/ave_p0.py` (document `anchor_base_alloc` options)
    - `avs/experiments/ave_p0_sweep.py` (add `candidate_set=ltl_top1med_bridgealloc_v1`)
    - `scripts/e0298_ave_p0_sweep_official_val_ltl_top1med_bridgealloc_v1.sh`
    - `scripts/e0299_ave_p0_best_to_test_official_ltl_top1med_bridgealloc_v1.sh`
    - `scripts/e0300_ave_p0_diagnose_E0299_bridgealloc.sh` (analysis-only)
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - `python -m avs.smoke sampling_plan` passes (strict equal-token budget still holds).
    - E0298 produces `runs/E0298_*/{sweep_summary.json,best_config.json,eventness_scores.json}` on val402.
    - E0299 reproduces the E0298 winner on test402 and writes `runs/E0299_*/metrics.json` (SEEDS=0..9).
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/sampling/plans.py avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py`
    - `python -m avs.smoke sampling_plan`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0298_ave_p0_sweep_official_val_ltl_top1med_bridgealloc_v1.sh`
    - `bash scripts/e0298_ave_p0_sweep_official_val_ltl_top1med_bridgealloc_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0298_*/best_config.json SEEDS=0,1,2,3,4,5,6,7,8,9 bash scripts/e0299_ave_p0_best_to_test_official_ltl_top1med_bridgealloc_v1.sh`
  - Outputs: `runs/E0298_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0299_*/metrics.json`, `runs/E0300_*/diagnose.json`
  - Evidence:
    - `python -m py_compile avs/sampling/plans.py avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/smoke_checks.py` → ok.
    - `python -m avs.smoke sampling_plan` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0298_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_bridgealloc_v1_20260205-023139/sweep_summary.json`.
    - Full val402 sweep (SEEDS=0..2): `runs/E0298_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_bridgealloc_v1_20260205-023226/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1_base`, Δ≈+0.00964, p≈0.0331; `bridgeAlloc` regresses to Δ≈+0.00175, p≈0.762). Conclusion: `base_alloc=bridge` is not a viable “拉大” direction.
    - Full test402 reproduction (SEEDS=0..9): `runs/E0299_ave_p0_best_to_test_official_av_clipdiff_mlp_bridgealloc_20260205-023457/metrics.json` (anchored=0.72383 vs uniform=0.70858, Δ=+0.01525, p≈0.00390; matches E0224 because the bridge variant did not win on val).

- [x] P0098: Try k=1 (single-anchor) with an aggressive triad (112/224/448) under the top1-med gate (attempt to push C0003 to ≥+2%)
  - Summary: Add `candidate_set=ltl_top1med_k1_extreme_v1` (k=1, triad 112/224/448, top1-med gate, shift + base alloc sweep) and run val402 sweep (E0301; SEEDS=0..2) → test402 reproduction (E0302; SEEDS=0..9).
  - Rationale: The best top1-med config (E0224) is limited by (a) high fallback and (b) far-anchor / 2-high failure modes. Many Stage-2 fixes that keep k=2 still suffer from spurious second anchors wasting the limited base slots. Moving to k=1 removes anchor2 entirely, and using the 112/224/448 triad allows a higher peak resolution (448) while preserving the strict equal-token budget (1×448 + 5×224 + 4×112 == 10×224). This combination could increase gain-per-used-clip without reintroducing far-anchor harm.
  - Scope:
    - `avs/experiments/ave_p0_sweep.py` (add `ltl_top1med_k1_extreme_v1`)
    - `scripts/e0301_ave_p0_sweep_official_val_ltl_top1med_k1_extreme_v1.sh`
    - `scripts/e0302_ave_p0_best_to_test_official_ltl_top1med_k1_extreme_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - E0301 runs on val402 (SEEDS=0..2) and produces `{sweep_summary.json,best_config.json,eventness_scores.json}`.
    - E0302 reproduces the E0301 winner on test402 (SEEDS=0..9) and writes `metrics.json`.
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0301_ave_p0_sweep_official_val_ltl_top1med_k1_extreme_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0301_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0302_ave_p0_best_to_test_official_ltl_top1med_k1_extreme_v1.sh`
  - Outputs: `runs/E0301_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0302_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/experiments/ave_p0_sweep.py` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0301_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_k1_extreme_v1_20260205-024400/sweep_summary.json`.
    - Full val402 sweep (SEEDS=0..2): `runs/E0301_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_k1_extreme_v1_20260205-024429/sweep_summary.json` (best=`ltltop1medk1ext_thr0p6_shift0_distance`, Δ≈+0.00856, p≈0.0657; worse than the baseline E0223/E0224 val selection).
    - Full test402 reproduction (SEEDS=0..9): `runs/E0302_ave_p0_best_to_test_official_av_clipdiff_mlp_k1extreme_20260205-025129/metrics.json` (anchored=0.71020 vs uniform=0.70858, Δ≈+0.00162, p≈0.649; large regression vs E0224). Conclusion: k=1 + extreme triad is not a viable “拉大” direction.

- [x] P0099: Try a budget-band Stage-2 sampling plan (≤1% under-budget) to preserve more base context (attempt to push C0003 to ≥+2%)
  - Summary: Add a `budget_mode=band` Stage-2 planner that never exceeds the uniform token budget but allows a small under-budget band (≤1%), enabling additional resolutions (e.g., 112) to trade off context vs peaks more flexibly than the strict equal-budget Diophantine constraint. Run a compact val402 sweep (E0303) → test402 reproduction (E0304), plus a direct diagnostic rerun of the E0224 gate under band mode (E0305).
  - Rationale: Diagnostics (E0280) show far-anchor 2-high clips are strongly negative on test402, suggesting context loss under the forced exact-budget 2-high plan. A budget-band planner can preserve more `base_res` seconds without exceeding budget, potentially reducing harm while keeping the method transparent and reproducible.
  - Scope:
    - `avs/sampling/plans.py` (add `budget_band_anchored_plan_scored`)
    - `avs/experiments/ave_p0.py` (add `budget_mode`, `budget_epsilon_frac`, `budget_extra_resolutions`)
    - `avs/experiments/ave_p0_sweep.py` (add `candidate_set=ltl_top1med_band_v1`)
    - `avs/smoke_checks.py` (extend `sampling_plan` smoke)
    - `scripts/e0303_ave_p0_sweep_official_val_ltl_top1med_band_v1.sh`
    - `scripts/e0304_ave_p0_best_to_test_official_ltl_top1med_band_v1.sh`
    - `docs/experiment.md`, `docs/mohu.md`, `docs/plan.md`
  - Acceptance:
    - `python -m avs.smoke sampling_plan` still passes.
    - E0303 produces `{sweep_summary.json,best_config.json,eventness_scores.json}` on val402.
    - E0304 reproduces the E0303 winner on test402 (SEEDS=0..9) and writes `metrics.json`.
    - If Δ≥+0.02 and p<0.05, mark C0003 proven; otherwise record results and iterate.
  - Verification:
    - `python -m py_compile avs/sampling/plans.py avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/smoke_checks.py`
    - `python -m avs.smoke sampling_plan`
    - `LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0303_ave_p0_sweep_official_val_ltl_top1med_band_v1.sh`
    - `BEST_CONFIG_JSON=runs/E0303_*/best_config.json LIMIT_TRAIN=64 LIMIT_EVAL=32 SEEDS=0,1 EPOCHS=1 bash scripts/e0304_ave_p0_best_to_test_official_ltl_top1med_band_v1.sh`
  - Outputs: `runs/E0303_*/{sweep_summary.json,best_config.json,eventness_scores.json}`, `runs/E0304_*/metrics.json`, `runs/E0305_*/metrics.json`
  - Evidence:
    - `python -m py_compile avs/sampling/plans.py avs/experiments/ave_p0.py avs/experiments/ave_p0_sweep.py avs/smoke_checks.py` → ok.
    - `python -m avs.smoke sampling_plan` → ok.
    - Smoke (train64/val32; SEEDS=0,1; EPOCHS=1): `runs/E0303_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_band_v1_20260205-033812/sweep_summary.json`.
    - Full val402 sweep (SEEDS=0..2): `runs/E0303_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_band_v1_20260205-033915/sweep_summary.json` (best=`ltltop1medband_thr0p7_shift1`, Δ≈+0.01205, p≈0.0685; worse than the baseline E0223 val selection).
    - Full test402 reproduction (SEEDS=0..9): `runs/E0304_ave_p0_best_to_test_official_av_clipdiff_mlp_20260205-035830/metrics.json` (anchored=0.71674 vs uniform=0.70858, Δ=+0.00816, p≈0.0441; regresses vs E0224). Conclusion: this band-budget sweep does not improve C0003.
    - Diagnostic test402 run (SEEDS=0..9): `runs/E0305_ave_p0_best_to_test_official_av_clipdiff_mlp_banddiag_thr0p6_shift1_20260205-040513/metrics.json` (Δ=+0.00356, p≈0.230; large regression vs E0224). Conclusion: band-budget planning (as implemented) is not a viable “拉大” direction.

## Conclusions
- [x] C0001: On AVE, under a strictly equal ViT token budget, Audio-anchored sampling (with a lightweight temporal head) improves segment-level accuracy vs Uniform sampling and Random anchors.
  - Evidence required: `metrics.json` with `acc_mean±std` over ≥3 seeds for Uniform-224, Random-TopK, Audio-TopK; plus a statement that token budgets are equal. Must hold on a non-trivial subset (e.g., ≥100 eval clips).
  - Experiments: E0001
  - Artifacts: `runs/AVE_P0/*/metrics.json`
  - Evidence (small subset): `runs/E0001_ave_p0_real_20260131-040050/p0_energy_seedfix/metrics.json` (energy; 3 seeds; `anchored_top2.mean=0.756 > random_top2.mean=0.711 > uniform.mean=0.244`; `token_budget=1960`)
  - Evidence (counter; MLP head): `runs/REAL_AVE_20260131-211548/p0_train180_val165_energy/metrics.json` (energy; 3 seeds; `uniform.mean=0.250 > anchored_top2.mean=0.214`; `token_budget=1960`); `runs/REAL_AVE_20260131-211548/p0_train180_test113_energy/metrics.json` (energy; 3 seeds; `uniform.mean=0.254 > anchored_top2.mean=0.212`; `token_budget=1960`)
  - Evidence (oracle upper bound emerges under a less-extreme equal-budget plan): `runs/REAL_AVE_20260131-211548/p0_train180_val165_energy_160_224_352_k2/metrics.json` (energy; 3 seeds; `oracle_top2.mean=0.258 > uniform.mean=0.250 > anchored_top2.mean=0.242`; `token_budget=1960`)
  - Evidence (k=1 mitigates but still < uniform): `runs/REAL_AVE_20260131-211548/p0_train180_val165_k1_energy_rerun/metrics.json` and `runs/REAL_AVE_20260131-211548/p0_train180_test113_k1_energy_rerun/metrics.json`
  - Evidence (temporal_conv head + robustness knobs; energy; triad=160/224/352; k=2; shift=1; std_thr=1.0; token_budget=1960):
    - Val165: `runs/REAL_AVE_20260131-211548/p0_train180_val165_energy_160_224_352_k2_shift1_std1p0_temporal_s0-9_rerun/metrics.json` (10 seeds; `anchored_top2.mean=0.228 > uniform.mean=0.221 > random.mean=0.211`)
    - Test113: `runs/REAL_AVE_20260131-211548/p0_train180_test113_energy_160_224_352_k2_shift1_std1p0_temporal_s0-9_rerun/metrics.json` (10 seeds; `anchored_top2.mean=0.233 > uniform.mean=0.230 > random.mean=0.221`)
  - Evidence (expanded train=195): `runs/REAL_AVE_20260131-211548/p0_train195_val165_energy_160_224_352_k2_shift1_std1p0_temporal_s0-4/metrics.json` (5 seeds; `anchored_top2.mean=0.232 > uniform.mean=0.211`) and `runs/REAL_AVE_20260131-211548/p0_train195_test113_energy_160_224_352_k2_shift1_std1p0_temporal_s0-4/metrics.json` (5 seeds; `anchored_top2.mean=0.274 > uniform.mean=0.259`)
  - Evidence (official full split; temporal_conv; energy; triad=160/224/352; k=2; shift=1; std_thr=1.0; token_budget=1960; 10 seeds):
    - Val402: `runs/REAL_AVE_OFFICIAL_20260201-124535/p0_train3339_val402_energy_160_224_352_k2_shift1_std1.0_temporal_conv/metrics.json` (`anchored_top2.mean=0.738 > uniform.mean=0.730 > random.mean=0.719`; `paired_ttest.anchored_vs_uniform.p=0.048`)
    - Test402: `runs/REAL_AVE_OFFICIAL_20260201-124535/p0_train3339_test402_energy_160_224_352_k2_shift1_std1.0_temporal_conv/metrics.json` (`anchored_top2.mean≈uniform.mean`: 0.719 vs 0.719; `paired_ttest.anchored_vs_uniform.p=0.896`; `anchored_top2.mean=0.719 > random.mean=0.699`)
  - Evidence (official full split rerun; same config; adds `audio_concat_anchored_top2`; head trained on `cuda:0`; token_budget=1960; 10 seeds):
    - Val402: `runs/REAL_AVE_OFFICIAL_RERUN_20260201-152134/p0_train3339_val402_energy_160_224_352_k2_shift1_std1.0_temporal_conv_v2/metrics.json` (`anchored_top2.mean=0.751 > uniform.mean=0.740`; `paired_ttest.anchored_vs_uniform.p=0.009`; `audio_concat_uniform.mean=0.749`)
    - Test402: `runs/REAL_AVE_OFFICIAL_RERUN_20260201-152134/p0_train3339_test402_energy_160_224_352_k2_shift1_std1.0_temporal_conv_v2/metrics.json` (`anchored_top2.mean=0.731 > uniform.mean=0.719`; `paired_ttest.anchored_vs_uniform.p=0.046`; `audio_concat_uniform.mean=0.734`)

- [x] C0002: Audio-based anchors achieve higher Recall@K (and Recall@K,Δ) than random anchors on AVE.
  - Evidence required: Table or JSON with Recall@K for (energy baseline, PANNs optional, random) and at least one Δ setting.
  - Experiments: E0002
  - Artifacts: `runs/anchors/*/anchors_metrics.json`
  - Evidence: `runs/E0002_anchors_real_20260131-045200/anchor_eval/anchors_metrics.json` (energy; k=2; n=89; Δ=0: ours=0.207 > random=0.194). Also: `runs/REAL_AVE_20260131-211548/anchors_val165_energy/anchors_metrics.json` (k=2; n=165; Δ=0: ours=0.208 > random=0.202) and `runs/REAL_AVE_20260131-211548/anchors_test113_energy/anchors_metrics.json` (k=2; n=113; Δ=0: ours=0.221 > random=0.181). Official full split: val `runs/REAL_AVE_OFFICIAL_20260201-124535/E0002_anchors_official_val/anchor_eval/anchors_metrics.json` (n=401; Δ=0 ours=0.231 > random=0.211) and test `runs/REAL_AVE_OFFICIAL_20260201-124535/E0002_anchors_official_test/anchor_eval/anchors_metrics.json` (n=402; Δ=0 ours=0.231 > random=0.204). Note: for dilated windows (Δ1/Δ2), random > ours on both val/test.

- [ ] C0003: On official AVE test402, sampling-only anchored_top2 improves >= +2.0% with p<0.05 (SEEDS=0..9).
  - Evidence required: `metrics.json` from the best config selected on val402 and reproduced on test402, with strict equal token budget and paired t-test.
  - Experiments: E0012,E0018,E0019,E0021,E0022,E0205,E0206,E0207,E0208,E0218,E0219,E0223,E0224,E0226,E0227,E0228,E0229,E0230,E0231,E0233,E0234,E0235,E0236,E0237,E0238,E0239,E0240,E0241,E0242,E0252,E0253,E0254,E0260,E0265,E0267,E0268,E0271,E0272,E0280,E0284,E0285,E0286,E0287,E0288,E0289,E0290,E0291,E0292,E0293,E0294,E0295,E0296,E0297,E0298,E0299,E0303,E0304,E0305
  - Evidence (full; energy_v2 improves but still does **not** meet the target):
    - Val401 sweep (selection): `runs/E0018_ave_p0_sweep_official_val_energy_v2_20260203-185629/sweep_summary.json` (best=`energy_ref_k2_topk_std1p0`, Δ=+0.01344, p=0.00175) + `runs/E0018_ave_p0_sweep_official_val_energy_v2_20260203-185629/best_config.json`.
    - Test402 reproduction: `runs/E0019_ave_p0_best_to_test_official_energy_v2_20260203-190500/metrics.json` (anchored=0.7188 vs uniform=0.7086, Δ=+0.01017, p=0.00466; fallback_used≈0.731).
  - Evidence (full; val-tuned gate on energy does not reach +2% either): `runs/E0201_full_energy_gini0p35_test402_20260204-041950/oracle_vs_predicted.json` (anchored=0.7193 vs uniform=0.7086, Δ=+0.01075, p=0.024; fallback_used≈0.580).
  - Evidence (partial val selection + full test; audio_basic_tcn does not reach +2% either):
    - Val402 sweep (SEEDS=0..2): `runs/E0205_full_audio_basic_tcn_val402_20260204-063935/sweep_summary.json` (best=`energyv3_extreme_112_224_448_maxHigh1_shift0_std0p6`, Δ≈+0.01837, p≈0.0426).
    - Test402 reproduction (SEEDS=0..9): `runs/E0206_ave_p0_best_to_test_official_audio_basic_tcn_20260204-070803/metrics.json` (anchored=0.7196 vs uniform=0.7086, Δ=+0.01097, p=0.0142).
  - Evidence (partial val selection + full test; clipdiff-augmented supervised anchors improve but still < +2%):
    - Val402 sweep (SEEDS=0..2): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_20260204-075914/sweep_summary.json` (best=`energyv3_shift1_std0p6`, Δ≈+0.01106, p≈0.00427).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-080419/metrics.json` (anchored=0.72045 vs uniform=0.70858, Δ=+0.01187, p=0.00142; fallback≈0.883).
    - Val402 sweep (SEEDS=0..2; ltl_std_v1): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_std_v1_20260204-083739/sweep_summary.json` (best=`ltlstd_shift0_std0p45`, Δ≈+0.01347, p≈0.0391).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_std_v1_20260204-084147/metrics.json` (anchored=0.72065 vs uniform=0.70858, Δ=+0.01206, p=0.00464; fallback≈0.754).
    - Val402 sweep (SEEDS=0..2; ltl_std_v2): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_std_v2_20260204-085103/sweep_summary.json` (best=`ltlstd2_shift0_std0p5_mixedAlloc`, Δ≈+0.01471, p≈0.0365).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_std_v2_20260204-085632/metrics.json` (overfits val and regresses on test: anchored=0.71724 vs uniform=0.70858, Δ=+0.00866, p=0.0472; fallback≈0.816).
    - Val402 sweep (SEEDS=0..2; ltl_gini_v2): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_gini_v2_20260204-090323/sweep_summary.json` (best=`ltlgini2_gini0p45_shift0`, Δ≈+0.00507, p≈0.437).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_gini_v2_20260204-090710/metrics.json` (anchored=0.71948 vs uniform=0.70858, Δ=+0.01090, p=0.0274).
    - Val402 sweep (SEEDS=0..2; ltl_gap_v1): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_gap_v1_20260204-090353/sweep_summary.json` (best=`ltlgap1_gap0p3_shift0`, Δ≈+0.00707, p≈0.0825).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_gap_v1_20260204-090741/metrics.json` (anchored=0.71600 vs uniform=0.70858, Δ=+0.00741, p=0.0604).
    - Val402 sweep (SEEDS=0..2; ltl_extreme_v1): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_extreme_v1_20260204-091309/sweep_summary.json` (best=`ltlextreme1_shift1_std0p6`, Δ≈+0.00998, p≈0.0579).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_ltl_extreme_v1_20260204-091529/metrics.json` (anchored=0.71413 vs uniform=0.70858, Δ=+0.00555, p=0.0849).
    - Val402 sweep (SEEDS=0..2; av_clipdiff_mlp_cls): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_cls_ltl_std_v1_20260204-092157/sweep_summary.json` (best=`ltlstd_shift0_std0p55`, Δ≈+0.01413, p≈0.0318).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_cls_ltl_std_v1_20260204-092530/metrics.json` (regresses on test: anchored=0.71510 vs uniform=0.70858, Δ=+0.00652, p=0.00801).
    - Val402 sweep (SEEDS=0..2; ltl_adaptive_v1): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_mlp_20260204-102403/sweep_summary.json` (best=`ltladj1_shift0_std0p45`, Δ≈+0.01164, p≈0.0373).
    - Test402 reproduction (SEEDS=0..9): `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-103001/metrics.json` (anchored=0.72234 vs uniform=0.70858, Δ=+0.01376, p≈1.4e-05).
  - Evidence (full; Stage-2 score smoothing does not improve the learned-anchor winner):
    - Val402 sweep (SEEDS=0..2): `runs/E0218_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_smooth_v1_20260204-132824/sweep_summary.json` (best=`ltlsmooth_shift0_std0p45_sw0_adj1`, i.e. smoothing window=0).
    - Test402 reproduction (SEEDS=0..9): `runs/E0219_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-133929/metrics.json` (anchored=0.72234 vs uniform=0.70858, Δ=+0.01376, p≈1.40e-05; fallback≈0.754).
  - Evidence (full; top1-med confidence gate improves the best learned-anchor test402 gain, but still < +2%):
    - Val402 sweep (SEEDS=0..2): `runs/E0223_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_v1_20260204-135150/sweep_summary.json` (best=`ltltop1med_thr0p6_shift1`).
    - Test402 reproduction (SEEDS=0..9): `runs/E0224_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-135547/metrics.json` (anchored=0.72383 vs uniform=0.70858, Δ=+0.01525, p≈0.00390; fallback≈0.751).
  - Evidence (diagnostic; “train longer (epochs=10)” does not help the top1-med winner on test402):
    - Full (SEEDS=0..9; wd=0.01): `runs/E0267_ave_p0_best_to_test_official_av_clipdiff_mlp_top1med_epochs10_wd0p01_20260204-194212/metrics.json` (Δ=+0.00274, p≈0.510; large regression vs E0224).
    - Full (SEEDS=0..9; wd=0.0): `runs/E0268_ave_p0_best_to_test_official_av_clipdiff_mlp_top1med_epochs10_wd0p0_20260204-194359/metrics.json` (Δ=-0.00129, p≈0.641; regression).
    - Full (SEEDS=0..2): `runs/E0291_ave_p0_best_to_test_official_av_clipdiff_mlp_top1med_e10_s0-2_20260205-001904/metrics.json` (anchored=0.70091 vs uniform=0.69701, Δ=+0.00390, p≈0.665; not significant).
  - Evidence (diagnostic; P0063 Stage-1 fused heuristics do not improve under the top1-med pipeline):
    - Val402 sweep (`EVENTNESS=av_fused_clipdiff_prod`; SEEDS=0..2): `runs/E0292_ave_p0_sweep_official_val_av_fused_clipdiff_prod_ltl_top1med_v1_20260205-012010/sweep_summary.json` (best Δ≈-0.00482, p≈0.491).
    - Test402 reproduction (SEEDS=0..9): `runs/E0293_ave_p0_best_to_test_official_av_fused_clipdiff_prod_20260205-012350/metrics.json` (anchored=0.71433 vs uniform=0.70858, Δ=+0.00575, p≈0.125).
    - Val402 sweep (`EVENTNESS=moe_energy_clipdiff`; SEEDS=0..2): `runs/E0294_ave_p0_sweep_official_val_moe_energy_clipdiff_ltl_top1med_v1_20260205-012010/sweep_summary.json` (best Δ≈+0.00224, p≈0.756).
    - Test402 reproduction (SEEDS=0..9): `runs/E0295_ave_p0_best_to_test_official_moe_energy_clipdiff_20260205-012339/metrics.json` (anchored=0.71164 vs uniform=0.70858, Δ=+0.00306, p≈0.420).
  - Evidence (full; Stage-2 variant sweep under the fixed top1-med gate does not improve the winner):
    - Val402 variants: `runs/E0226_ave_p0_stage2_variants_official_val_av_clipdiff_mlp_20260204-142732/variants_summary.json` (best=`best_config`; other variants are worse on val).
    - Test402 reproduction: `runs/E0227_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-142936/metrics.json` (same result as E0224: Δ=+0.01525, p≈0.00390).
  - Evidence (full; top1-med + extreme triad (112/224/448) overfits val and regresses on test402):
    - Val402 sweep (SEEDS=0..2): `runs/E0228_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_extreme_v1_20260204-143855/sweep_summary.json` (best=`ltltop1medext1_thr0p6_shift0_distance`, Δ≈+0.01313, p≈0.0589).
    - Test402 reproduction (SEEDS=0..9): `runs/E0229_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-144335/metrics.json` (anchored=0.71617 vs uniform=0.70858, Δ=+0.00759, p≈0.0286; fallback≈0.751).
  - Evidence (full; higher-res Stage-1 clipdiff features (av_clipdiff_mlp_r160) do not improve and increase fallback):
    - Val402 sweep (SEEDS=0..2): `runs/E0230_ave_p0_sweep_official_val_av_clipdiff_mlp_r160_ltl_top1med_v1_20260204-144941/sweep_summary.json` (best Δ≈+0.00341).
    - Test402 reproduction (SEEDS=0..9): `runs/E0231_ave_p0_best_to_test_official_av_clipdiff_mlp_r160_20260204-145349/metrics.json` (anchored=0.71754 vs uniform=0.70858, Δ=+0.00896, p≈0.0557; fallback≈0.868).
  - Evidence (full; eliminating 2-high via `max_high_anchors=1` regresses on test402):
    - Val402 sweep (SEEDS=0..2): `runs/E0233_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_maxhigh1_v1_20260204-151909/sweep_summary.json` (best=`ltltop1medmax1_thr0p5_shift0`, Δ≈+0.00740, p≈0.0164).
    - Test402 reproduction (SEEDS=0..9): `runs/E0234_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-152349/metrics.json` (anchored=0.71505 vs uniform=0.70858, Δ=+0.00647, p≈0.155; fallback≈0.652).
  - Evidence (full; k=1 (single-anchor) under top1-med gate also regresses vs the best config):
    - Val402 sweep (SEEDS=0..2): `runs/E0235_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_k1_v1_20260204-153020/sweep_summary.json` (best=`ltltop1medk1_thr0p5_shift1`, Δ≈+0.00715, p≈0.269).
    - Test402 reproduction (SEEDS=0..9): `runs/E0236_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-153411/metrics.json` (anchored=0.71878 vs uniform=0.70858, Δ=+0.01020, p≈0.0110; fallback≈0.652).
  - Evidence (full; additional Stage-2 variants under the top1-med gate do not beat E0224):
    - Adaptive gap demotion:
      - Val402 sweep: `runs/E0237_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_adaptivegap_v1_20260204-160956/sweep_summary.json` (best Δ≈+0.01064).
      - Test402 reproduction: `runs/E0238_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-161232/metrics.json` (Δ=+0.01037, p≈0.00434; regresses).
    - High-conf demotion (adaptive_v2):
      - Val402 sweep: `runs/E0239_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_highconf_v1_20260204-161417/sweep_summary.json` (best Δ≈+0.00964).
      - Test402 reproduction: `runs/E0240_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-161835/metrics.json` (Δ=+0.01525, p≈0.00390; matches E0224).
    - Score-aware base allocation:
      - Val402 sweep: `runs/E0241_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_scorealloc_v1_20260204-162247/sweep_summary.json` (best Δ≈+0.00756).
      - Test402 reproduction: `runs/E0242_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-162356/metrics.json` (Δ=+0.00968, p≈0.00346; regresses).
    - Autoshifted learned scores:
      - Val402 sweep: `runs/E0245_ave_p0_sweep_official_val_av_clipdiff_mlp_autoshift_ltl_top1med_autoshift_v1_20260204-163436/sweep_summary.json` (best Δ≈+0.00806).
      - Test402 reproduction: `runs/E0246_ave_p0_best_to_test_official_av_clipdiff_mlp_autoshift_20260204-163703/metrics.json` (Δ=+0.00142, p≈0.707; fails).
    - Stage-1 probe sweeps (val-only, not promoted): `runs/E0243_ave_p0_sweep_official_val_av_clip_mlp_cls_target_ltl_top1med_v1_20260204-162702/sweep_summary.json` and `runs/E0247_ave_p0_sweep_official_val_av_clipdiff_mlp_cls_target_ltl_top1med_v1_20260204-164046/sweep_summary.json`.
  - Evidence (full; strong-NMS anchor selection (nms_strong) does not transfer and regresses on test402):
    - Val402 sweep: `runs/E0248_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_nmsstrong_v1_20260204-170658/sweep_summary.json` (best Δ≈+0.00723).
    - Test402 reproduction: `runs/E0249_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-171109/metrics.json` (Δ=+0.00883, p≈8.999e-04; regresses vs E0224).
  - Evidence (diagnostic; fbank_stats + CLIPdiff scalar learned anchors fail):
    - Val402 sweep: `runs/E0250_ave_p0_sweep_official_val_av_clipdiff_fbank_mlp_ltl_top1med_v1_20260204-172631/sweep_summary.json` (best Δ≈+0.00058).
    - Test402 reproduction: `runs/E0251_ave_p0_best_to_test_official_av_clipdiff_fbank_mlp_20260204-173034/metrics.json` (Δ=-0.00149, p≈0.676).
  - Evidence (diagnostic; conditional drop-far anchor2 improves val but regresses on test402):
    - Val402 sweep: `runs/E0252_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_dropfar_v1_20260204-173949/sweep_summary.json` (best Δ≈+0.01305).
    - Test402 reproduction: `runs/E0253_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-174232/metrics.json` (Δ=+0.00781, p≈0.00385; regresses vs E0224).
  - Evidence (full; energy_v3 sweep does not find a stronger config than energy_v2):
    - Val401 sweep: `runs/E0021_ave_p0_sweep_official_val_energy_v3_20260203-194306/sweep_summary.json` (best=`energyv3_ref_shift1_std1p0`, Δ=+0.01344, p=0.00175).
    - Test402 reproduction: `runs/E0022_ave_p0_best_to_test_official_energy_v3_20260203-195707/metrics.json` (anchored=0.7188 vs uniform=0.7086, Δ=+0.01017, p=0.00466).
  - Evidence (diagnostic; top-3 val configs do not transfer better than the best):
    - Test402 (val rank #2): `runs/E0022b_energyv3_shift1_std0p6_test402_20260203-195743/metrics.json` (Δ=+0.00512, p=0.144).
    - Test402 (val rank #3): `runs/E0022c_energyv3_shift0_std1p0_test402_20260203-195754/metrics.json` (Δ=+0.00388, p=0.349).
  - Evidence (diagnostic; longer training does not help this gap): `runs/E0024_energy_ref_test402_epochs20_20260203-194640/metrics.json` (Δ=+0.00281, p=0.587).
  - Evidence (diagnostic; increasing K and using score-based base allocation does not beat best): `runs/E0025_energy_k5_maxHigh1_scoreAlloc_test402_20260203-200327/metrics.json` (Δ=+0.00876, p=0.0106).
  - Evidence (full; AST-based anchors do **not** transfer and can significantly regress): `runs/E0015_ave_p0_best_to_test_official_ast_20260203-172848/metrics.json` (anchored=0.7003 vs uniform=0.7123, Δ=-0.0120, p=0.024; fallback≈0.169). Diagnosis: `runs/E0016_ave_p0_diagnose_20260203-173704/diagnose.json` (adjacent 2-anchor cases are most harmful).
  - Evidence (diagnostic; clipdiff-based autoshift does not beat energy): `runs/E0201_full_energy_autoshift_clipdiff_test402_20260204-032327/oracle_vs_predicted.json` (Δ=+0.00687) and `runs/E0201_full_energy_autoshift_clipdiff_pos_test402_20260204-040122/oracle_vs_predicted.json` (Δ=+0.00254).
  - Evidence (diagnostic; full-CLIP Stage-1 anchors do not help):
    - Val402 sweep: `runs/E0207_ave_p0_sweep_official_val_av_clip_mlp_cls_20260204-095132/sweep_summary.json` (best Δ≈+0.00308).
    - Test402 reproduction: `runs/E0208_ave_p0_best_to_test_official_av_clip_mlp_cls_20260204-095509/metrics.json` (Δ=+0.00281, p=0.328).
    - Val402 sweep: `runs/E0207_ave_p0_sweep_official_val_av_clip_mlp_cls_target_20260204-095814/sweep_summary.json` (best Δ≈+0.00648, p≈0.100).
    - Test402 reproduction: `runs/E0208_ave_p0_best_to_test_official_av_clip_mlp_cls_target_20260204-100202/metrics.json` (Δ=-0.00597, p=0.131).
  - Evidence (diagnostic; retuning av_clipdiff_tcn with ltl_std_v1 overfits val but regresses on test):
    - Val402 sweep: `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_tcn_20260204-100517/sweep_summary.json` (best Δ≈+0.01247, p≈0.0435).
    - Test402 reproduction: `runs/E0208_ave_p0_best_to_test_official_av_clipdiff_tcn_20260204-100855/metrics.json` (Δ=+0.00540, p=0.161).
  - Evidence (diagnostic; clipdiff-vector MLP anchors do not help): `runs/E0207_ave_p0_sweep_official_val_av_clipdiff_vec_mlp_20260204-101416/sweep_summary.json` (best Δ≈+0.00349, p≈0.066).
  - Evidence (diagnostic; adaptive_v3 keep-adjacent + base allocation regresses): Val402 sweep `runs/E0284_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_keepadj_basealloc_v1_20260204-224414/sweep_summary.json` (best=`ltltop1med_keepadj_distance`, Δ≈+0.00515, p≈0.286) and test402 reproduction `runs/E0285_ave_p0_best_to_test_official_av_clipdiff_mlp_20260204-224708/metrics.json` (Δ=+0.00729, p≈0.1009).
  - Evidence (diagnostic; budget-band Stage-2 planner does not improve C0003):
    - Val402 sweep (SEEDS=0..2): `runs/E0303_ave_p0_sweep_official_val_av_clipdiff_mlp_ltl_top1med_band_v1_20260205-033915/sweep_summary.json` (best=`ltltop1medband_thr0p7_shift1`, Δ≈+0.01205, p≈0.0685).
    - Test402 reproduction (SEEDS=0..9): `runs/E0304_ave_p0_best_to_test_official_av_clipdiff_mlp_20260205-035830/metrics.json` (Δ=+0.00816, p≈0.0441; regresses vs E0224).
    - Direct diagnostic (thr0.6, shift1; SEEDS=0..9): `runs/E0305_ave_p0_best_to_test_official_av_clipdiff_mlp_banddiag_thr0p6_shift1_20260205-040513/metrics.json` (Δ=+0.00356, p≈0.230; regresses vs E0224). Conclusion: band-budget planning (as implemented) is not a viable “拉大” direction.

- [ ] C0004: On official AVE test402, audio_concat_anchored_top2 improves over audio_concat_uniform (>= +1.0%, p<0.05; SEEDS=0..9).
  - Evidence required: `metrics.json` under the best sampling config, showing fusion gains beyond uniform fusion baseline.
  - Experiments: E0013,E0017,E0020,E0023
  - Evidence (full; does **not** meet the target): `runs/E0013_ave_fusion_confirm_official_test_20260203-150226/metrics.json` (audio_concat_anchored=0.7213 vs audio_concat_uniform=0.7162, Δ=+0.0051, p=0.367).
  - Evidence (full; energy_v2 config regresses fusion): `runs/E0020_ave_fusion_confirm_official_test_energy_v2_20260203-190804/metrics.json` (audio_concat_anchored=0.7195 vs audio_concat_uniform=0.7214, Δ=-0.0020, p=0.598).

- [ ] C0005: On EPIC-SOUNDS video-level multi-label recognition, audio-anchored selection improves mAP on val (SEEDS>=3).
  - Evidence required: `metrics.json` with mAP/macro-F1 and a clear fixed budget definition (`max_steps × base_res`), plus baselines.
  - Experiments: E0100
  - Artifacts: `runs/E0100_*/metrics.json`

- [ ] C0006: Oracle anchors provide an upper bound that shows stable Acc–Tok Pareto improvements across a pre-registered budget grid on AVE.
  - Evidence required: `oracle_ceiling.json` + Pareto plot (with CI) showing Oracle dominates Uniform/Random at ≥1 budget point (and is non-worse elsewhere).
  - Experiments: E0010
  - Artifacts: `runs/E0010_*/oracle_ceiling.json`, `runs/E0010_*/pareto.*`
  - Evidence (oracle ceiling sweep; fixed budget, strong upper bound): val402 `runs/E0010_oracle_ceiling_official_val_20260203-144421/oracle_ceiling.json` (best=`160_224_352_temporal_k5`, oracle=0.7931 vs uniform=0.7311, Δ=+0.0620, p=8.9e-05) and test402 `runs/E0010_oracle_ceiling_official_test_20260203-143455/oracle_ceiling.json` (best=`160_224_352_temporal_k5`, oracle=0.7663 vs uniform=0.7126, Δ=+0.0536, p=8.9e-06). Note: this is not yet a multi-budget Pareto grid; use it as the mechanism upper bound.

- [ ] C0007: Predicted anchors stay within a small gap of Oracle anchors on the same budget grid (deployable stage-1).
  - Evidence required: A report showing mean(Oracle–Pred) ≤ ε across budgets, plus Predicted still beats best baseline with p<0.05 on ≥1 budget.
  - Experiments: E0201
  - Artifacts: `runs/E0201_*/oracle_vs_predicted.json`
  - Evidence (full; fixed budget; test402): `runs/E0201_full_energy_20260203-210017/oracle_vs_predicted.json` (oracle_minus_predicted=0.03124; anchored=0.7188 vs uniform=0.7086, p=0.00466). `runs/E0201_full_energy_stride_max_20260203-210017/oracle_vs_predicted.json` (oracle_minus_predicted=0.03254). `runs/E0201_oracle_vs_predicted_av_fused_scale3p5_full_20260203-221906/oracle_vs_predicted.json` (after fixing confidence-gate scale mismatch; anchored=0.7190 vs uniform=0.7086, p=0.00995; oracle_minus_predicted≈0.03097; fallback_used_frac≈0.739). `runs/E0201_oracle_vs_predicted_av_clipdiff_mlp_20260204-213240/oracle_vs_predicted.json` (oracle_minus_predicted=0.03383; predicted Δ=+0.00759, p=0.0945).

- [ ] C0008: Evidence Alignment (Cov@τ) correlates with downstream accuracy and diagnoses failure cases.
  - Evidence required: Cov@τ table and a scatter/correlation report where higher Cov@τ predicts higher anchored gains (report Pearson/Spearman).
  - Experiments: E0202
  - Artifacts: `runs/E0202_*/evidence_alignment.json`
  - Evidence (full; currently weak alignment/correlation on test402): `runs/E0202_evidence_alignment_energy_v2_test_20260203-194355/evidence_alignment.json` (Cov@τ mean≈0.059 for τ∈{0.3,0.5,0.7}; corr pearson≈0.080, spearman≈-0.003).

- [ ] C0009: Listen-then-Look degrades gracefully under shift/noise/silence, and α provides a computable accuracy lower bound.
  - Evidence required: Degradation heatmaps/curves over `{shift_s, snr_db, silence_ratio, alpha}` showing monotonic trends and no catastrophic drops below the α-baseline.
  - Experiments: E0203
  - Artifacts: `runs/E0203_*/degradation_suite.json`, `runs/E0203_*/degradation_plots/*`
  - Evidence (stage-1 recall only; alpha lower bound pending): `runs/E0203_full_energy_20260203-210331/degradation_suite.json`, `runs/E0203_full_energy_stride_max_20260203-210414/degradation_suite.json`, `runs/E0203_full_av_fused_20260203-210458/degradation_suite.json` (av_fused improves mean Recall@K,Δ2 but hurts strict Δ0), `runs/E0203_degradation_av_clipdiff_mlp_20260204-215831/degradation_suite.json` (mean Recall@K,Δ0≈0.212; Δ2≈0.624).
